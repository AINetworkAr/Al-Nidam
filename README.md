# دورة تصميم النظم

مرحبًا، أهلاً بك في الدورة. آمل أن توفر لك هذه الدورة تجربة تعلم رائعة.

_يمكنك أيضًا الحصول على هذه الدورة على موقعي الإلكتروني [هنا](https://karanpratapsingh.com/courses/system-design) وكذلك ككتاب إلكتروني على [leanpub](https://leanpub.com/systemdesign). يُرجى تقييم الدورة بنجمة واحدة كتحفيز إذا كانت مفيدة لك!_



# جدول المحتويات

- **مقدمة**

  - [ما هو تصميم النظم؟](#what-is-system-design)

- **الفصل الأول**

  - [بروتوكول الإنترنت (IP)](#ip)
  - [نموذج OSI](#osi-model)
  - [بروتوكولات TCP و UDP](#tcp-and-udp)
  - [نظام اسم المجال (DNS)](#domain-name-system-dns)
  - [توازن الحمل (Load Balancing)](#load-balancing)
  - [التجميع (Clustering)](#clustering)
  - [التخزين المؤقت (Caching)](#caching)
  - [شبكة توزيع المحتوى (CDN)](#content-delivery-network-cdn)
  - [البروكسي (Proxy)](#proxy)
  - [التوفر (Availability)](#availability)
  - [التوسعية (Scalability)](#scalability)
  - [التخزين (Storage)](#storage)

- **الفصل الثاني**

  - [قواعد البيانات ونظام إدارة قواعد البيانات (DBMS)](#databases-and-dbms)
  - [قواعد البيانات ذات اللغة الهيكلية (SQL)](#sql-databases)
  - [قواعد البيانات غير اللغة الهيكلية (NoSQL)](#nosql-databases)
  - [قواعد البيانات ذات اللغة الهيكلية مقابل قواعد البيانات غير اللغة الهيكلية](#sql-vs-nosql-databases)
  - [تكرار قاعدة البيانات (Database Replication)](#database-replication)
  - [الفهارس (Indexes)](#indexes)
  - [التطبيع والتجانس (Normalization and Denormalization)](#normalization-and-denormalization)
  - [نماذج الاتساق ACID و BASE](#acid-and-base-consistency-models)
  - [نظرية CAP](#cap-theorem)
  - [نظرية PACELC](#pacelc-theorem)
  - [المعاملات (Transactions)](#transactions)
  - [المعاملات الموزعة (Distributed Transactions)](#distributed-transactions)
  - [التجزئة (Sharding)](#sharding)
  - [التجزئة الهاشية المتسقة (Consistent Hashing)](#consistent-hashing)
  - [التوحيد القاعدي (Database Federation)](#database-federation)

- **الفصل الثالث**

  - [الهندسة المتعددة الطبقات (N-tier architecture)](#n-tier-architecture)
  - [وسطاء الرسائل (Message Brokers)](#message-brokers)
  - [قوائم الرسائل (Message Queues)](#message-queues)
  - [النشر والاشتراك (Publish-Subscribe)](#publish-subscribe)
  - [حافلة الخدمات المؤسسية (ESB)](#enterprise-service-bus-esb)
  - [الأحجام الضخمة والخدمات المصغرة (Monoliths and Microservices)](#monoliths-and-microservices)
  - [هندسة المعمارية المستندة إلى الأحداث (EDA)](#event-driven-architecture-eda)
  - [تتبع الأحداث (Event Sourcing)](#event-sourcing)
  - [فصل المسؤولية بين الأوامر والاستعلامات (CQRS)](#command-and-query-responsibility-segregation-cqrs)
  - [بوابة واجهة برمجة التطبيقات (API Gateway)](#api-gateway)
  - [REST وGraphQL وgRPC](#rest-graphql-grpc)
  - [الاستطلاع الطويل والمقابس الشبكية وأحداث الخادم المُرسَل (SSE)](#long-polling-websockets-server-sent-events-sse)

- **الفصل الرابع**

  - [التشفير الجغرافي وأشجار الرباعيات (Geohashing and Quadtrees)](#geohashing-and-quadtrees)
  - [المفتاح الكهربائي (Circuit breaker)](#circuit-breaker)
  - [تحديد المعدل (Rate Limiting)](#rate-limiting)
  - [اكتشاف الخدمات (Service Discovery)](#service-discovery)
  - [SLA و SLO و SLI](#sla-slo-sli)
  - [استعادة الكوارث (Disaster recovery)](#disaster-recovery)
  - [الآلات الافتراضية (VMs) والحاويات (Containers)](#virtual-machines-vms-and-containers)
  - [OAuth 2.0 وOpenID Connect (OIDC)](#oauth-20-and-openid-connect-oidc)
  - [تسجيل الدخول الموحد (SSO)](#single-sign-on-sso)
  - [SSL وTLS وmTLS](#ssl-tls-mtls)

- **الفصل الخامس**

  - [مقابلات تصميم النظم](#system-design-interviews)
  - [مُختصر عناوين URL](#url-shortener)
  - [تطبيق واتساب](#whatsapp)
  - [تطبيق تويتر](#twitter)
  - [خدمة نتفليكس](#netflix)
  - [خدمة أوبر](#uber)

- **الملحق**

  - [الخطوات التالية](#next-steps)
  - [المراجع](#references)


# ما هو تصميم النظم؟

قبل أن نبدأ هذه الدورة، دعنا نتحدث عن مفهوم تصميم النظم بشكل عام.

تصميم النظم هو عملية تحديد الهيكلية والواجهات والبيانات لنظام يلبي المتطلبات المحددة. يهدف تصميم النظم إلى تلبية احتياجات الأعمال أو المؤسسة من خلال نظم متماسكة وفعالة. يتطلب هذا التصميم نهجاً منهجياً لبناء وهندسة الأنظمة. يتطلب تصميم نظام جيد أن نفكر في كل شيء، بدءًا من البنية التحتية وصولاً إلى كيفية تخزين البيانات.

## لماذا يُعتبر تصميم النظم مهمًا جدًا؟

يساعد تصميم النظم في تحديد حلاً يلبي متطلبات الأعمال. إنه واحد من أولى القرارات التي يمكننا اتخاذها عند بناء نظام. في كثير من الأحيان، من الضروري التفكير على المستوى العالي نظراً لأن هذه القرارات صعبة التصحيح في وقت لاحق. كما يجعل من السهل استنتاج وإدارة التغييرات المعمارية مع تطور النظام.


# عنوان IP

عنوان IP هو عنوان فريد يحدد جهازًا على الإنترنت أو شبكة محلية. تعني الحروف IP "بروتوكول الإنترنت"، وهو مجموعة من القواعد التي تحكم تنسيق البيانات المرسلة عبر الإنترنت أو الشبكة المحلية.

بشكل أساسي، تعتبر عناوين IP المُعرف الذي يسمح بإرسال المعلومات بين الأجهزة على الشبكة. إنها تحتوي على معلومات الموقع وتجعل الأجهزة متاحة للتواصل. يحتاج الإنترنت إلى وسيلة للتمييز بين أجهزة الكمبيوتر المختلفة والموجهات والمواقع الإلكترونية. توفر عناوين IP طريقة للقيام بذلك وتشكل جزءًا أساسيًا من كيفية عمل الإنترنت.

## الإصدارات

الآن، دعنا نتعرف على الإصدارات المختلفة لعناوين IP:

### IPv4

بروتوكول الإنترنت الأصلي هو IPv4 الذي يستخدم تدوينًا رقميًا بالنقاط العشرية بطول 32 بت يسمح فقط بحوالي 4 مليار عنوان IP. في البداية، كان كافيًا تمامًا، ولكن مع نمو انتشار الإنترنت، احتجنا إلى شيء أفضل.

_مثال: `102.22.192.181`_

### IPv6

IPv6 هو بروتوكول جديد تم تقديمه في عام 1998. بدأ نشره في منتصف العقد الثاني من القرن الحادي والعشرين ونظرًا لازدياد مستخدمي الإنترنت بشكل هائل، فإنه لا يزال قائمًا حتى الآن.

يستخدم هذا البروتوكول الجديد تدوينًا بالنص الست عشري الألفا رقمي بطول 128 بت. وهذا يعني أن IPv6 يمكنه توفير حوالي ~340e+36 عنوان IP. هذا أكثر من كافٍ لتلبية الطلب المتزايد لسنوات قادمة.

_مثال: `2001:0db8:85a3:0000:0000:8a2e:0370:7334`_

## أنواع العناوين

لنتناول أنواع عناوين IP:

### عامة (Public)

عنوان IP العام هو العنوان الذي يتم ربط عنوان رئيسي واحد به لشبكتك بأكملها. في هذا النوع من عناوين IP، يكون لدى كل الأجهزة المتصلة نفس عنوان IP.

_مثال: عنوان IP الذي يتم توفيره لجهاز التوجيه الخاص بك من قِبل مزود خدمة الإنترنت._

### خاصة (Private)

عنوان IP الخاص هو رقم IP فريد يتم تعيينه لكل جهاز يتصل بشبكة الإنترنت الخاصة بك، والتي تشمل أجهزة مثل الكمبيوترات والأجهزة اللوحية والهواتف الذكية، والتي تُستخدم في منزلك.

_مثال: عناوين IP التي ينشئها جهاز التوجيه المنزلي لأجهزتك._

### ثابتة (Static)

عنوان IP الثابت لا يتغير وهو عنوان تم إنشاؤه يدويًا بدلاً من تكليفه تلقائياً. عادةً ما تكون هذه العناوين أكثر تكلفة ولكنها أكثر موثوقية.

_مثال: عادةً ما تُستخدم للأمور المهمة مثل خدمات تحديد الموقع الجغرافي الموثوقة، الوصول عن بُعد، استضافة الخادم، إلخ._

### ديناميكية (Dynamic)

يتغير عنوان IP الديناميكي من وقت لآخر وليس دائمًا نفسه. يتم تكليفه من قبل خادم بروتوكول تكوين المضيف الديناميكي (DHCP). عناوين IP

 الديناميكية هي النوع الأكثر شيوعًا لعناوين بروتوكول الإنترنت. إنها أرخص للنشر وتسمح لنا باستخدام عناوين IP مرة أخرى في الشبكة حسب الحاجة.

_مثال: عادةً ما تُستخدم بشكل أكثر شيوعًا للأجهزة الاستهلاكية والاستخدام الشخصي._

# نموذج OSI

نموذج OSI هو نموذج منطقي ومفهومي يحدد اتصالات الشبكة المستخدمة في الأنظمة المفتوحة للتواصل والتفاعل مع الأنظمة الأخرى. يحدد نموذج النظام المفتوح (نموذج OSI) أيضًا شبكة منطقية ويصف بفعالية نقل حزم الكمبيوتر باستخدام طبقات متعددة من البروتوكولات.

يمكن اعتبار نموذج OSI لغة عالمية لشبكات الكمبيوتر. يستند إلى مفهوم تقسيم نظام الاتصال إلى سبع طبقات مجردة، يتم تراكم كل طبقة منها فوق الطبقة السابقة.

## لماذا يهم نموذج OSI؟

نموذج النظام المفتوح (OSI) قد حدد المصطلحات الشائعة المستخدمة في مناقشات الشبكات والوثائق. يسمح لنا ذلك بتفكيك عملية الاتصال المعقدة وتقييم مكوناتها.

على الرغم من أن هذا النموذج لا يُطبق مباشرة في شبكات TCP/IP الأكثر شيوعًا اليوم، إلا أنه ما زال يمكننا من فعل الكثير من الأشياء، مثل:

- جعل عملية إصلاح الأخطاء أسهل والتعرف على التهديدات عبر جميع الطبقات.
- تشجيع مصنعي الأجهزة على إنشاء منتجات شبكية يمكنها التواصل مع بعضها البعض عبر الشبكة.
- ضروري لتطوير عقلية أمان متقدمة.
- تقسيم وظيفة معقدة إلى مكونات أبسط.

## الطبقات

يمكن تعريف الطبقات السبع المجردة لنموذج OSI على النحو التالي، من الأعلى إلى الأسفل:

![osi-model](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/osi-model/osi-model.png)

### التطبيق (Application)

هذه هي الطبقة الوحيدة التي تتفاعل مباشرة مع بيانات المستخدم. تعتمد تطبيقات البرامج مثل متصفحات الويب وعملاء البريد الإلكتروني على طبقة التطبيق لبدء الاتصال. ولكن ينبغي أن يكون من الواضح أن تطبيقات البرامج العميل ليست جزءًا من طبقة التطبيق، بل تقوم طبقة التطبيق بالمسؤولية عن البروتوكولات وتلاعب البيانات التي يعتمد عليها البرنامج لتقديم بيانات معنوية للمستخدم. تتضمن بروتوكولات طبقة التطبيق HTTP وكذلك SMTP.

### العرض (Presentation)

طبقة العرض تُسمى أيضًا طبقة الترجمة. تُستخرج البيانات من طبقة التطبيق هنا ويتم تعديلها حسب التنسيق المطلوب لنقلها عبر الشبكة. تتضمن وظائف طبقة العرض الترجمة والتشفير/فك التشفير والضغط.

### الجلسة (Session)

هذه هي الطبقة المسؤولة عن فتح وإغلاق الاتصال بين الجهازين. الوقت الذي يستغرقه الاتصال منذ فتحه حتى إغلاقه يُعرف بالجلسة. تضمن طبقة الجلسة أن تظل الجلسة مفتوحة بما فيه الكفاية لنقل جميع البيانات المتبادلة، ثم تغلق الجلسة على الفور لتجنب إهدار الموارد. تزامن طبقة الجلسة أيضًا نقل البيانات مع نقاط التحقق.

### النقل (Transport)

طبقة النقل (المعروفة أيضًا بالطبقة 4) مسؤولة عن الاتصال من نهاية إلى أخرى بين الجهازين. يشمل ذلك أخذ البيانات من طبقة الجلسة وتجزئتها إلى قطع تسمى الشرائح ق

بل إرسالها إلى طبقة الشبكة (الطبقة 3). كما أنها مسؤولة عن إعادة تجميع الشرائح على الجهاز الاستقبالي إلى بيانات يمكن لطبقة الجلسة استهلاكها.

### الشبكة (Network)

طبقة الشبكة مسؤولة عن تس faciliti faciliting نقل البيانات بين شبكتين مختلفتين. تقوم طبقة الشبكة بتجزئة الشرائح من طبقة النقل إلى وحدات أصغر، تُسمى الحزم، على الجهاز الإرسالي، وإعادة تجميع هذه الحزم على الجهاز الاستقبالي. تبحث طبقة الشبكة أيضًا عن أفضل مسار مادي للبيانات للوصول إلى وجهتها، وهذا ما يُعرف بالتوجيه. إذا كان الجهازين المتصلين على نفس الشبكة، فإن طبقة الشبكة غير ضرورية.

### الرابط البيانات (Data Link)

طبقة الرابط البيانات مشابهة جدًا لطبقة الشبكة، باستثناء أن طبقة الرابط البيانات تس faciliti faciliting نقل البيانات بين جهازين على نفس الشبكة. تأخذ طبقة الرابط البيانات الحزم من طبقة الشبكة وتقسمها إلى أجزاء أصغر تُسمى الإطارات.

### الطبقة المادية (Physical)

تشمل هذه الطبقة المعدات المادية المشاركة في نقل البيانات، مثل الكابلات والمفاتيح (السويتشات). هذه أيضًا الطبقة التي يتم فيها تحويل البيانات إلى تسلسل بتي، وهو سلسلة من الأصفار والواحدات. يجب أن تتفق طبقة المادية في كلا الجهازين على اتفاق إشارة بحيث يمكن تمييز الأصفار عن الواحدات على كلا الجهازين.
# TCP و UDP

## TCP

بروتوكول التحكم في النقل (TCP) هو بروتوكول موجه للاتصالات، مما يعني أنه بمجرد تأسيس الاتصال، يمكن نقل البيانات في كلا الاتجاهين. يحتوي TCP على أنظمة مدمجة لفحص الأخطاء وضمان توصيل البيانات في نفس الترتيب الذي تم إرسالها، مما يجعله البروتوكول المثالي لنقل المعلومات مثل الصور الثابتة، وملفات البيانات، وصفحات الويب.

![tcp](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/tcp-and-udp/tcp.png)

ولكن على الرغم من أن TCP موثوق تلقائيًا، فإن آليات ردود الفعل الخاصة به تؤدي أيضًا إلى زيادة العبء التشغيلي، مما يترجم إلى استخدام أكبر لعرض النطاق الترددي المتاح على الشبكة.

## UDP

بروتوكول مستخدم الحزم (UDP) هو بروتوكول بسيط أكثر وغير متصل بالشبكة حيث لا تُطلب خدمات فحص الأخطاء واستعادة البيانات. مع UDP، لا يوجد عبء لفتح اتصال، والحفاظ على اتصال، أو إنهاء اتصال. يتم إرسال البيانات باستمرار إلى المستلم، سواء كان قد استلمها أم لا.

![udp](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/tcp-and-udp/udp.png)

يفضل بشكل كبير في حالات الاتصالات في الوقت الحقيقي مثل البث أو النقل المتعدد الاتجاهات. ينبغي أن نستخدم UDP على TCP عندما نحتاج إلى أدنى تأخير ويكون فقدان البيانات أسوأ من فقدان البيانات.

## TCP مقابل UDP

TCP هو بروتوكول موجه للاتصال، بينما UDP هو بروتوكول غير متصل بالشبكة. الفرق الرئيسي بين TCP و UDP هو السرعة، حيث يكون TCP أبطأ نسبيًا من UDP. بشكل عام، يعتبر UDP بروتوكولًا أسرع وأبسط وأكثر كفاءة، ولكن يمكن فقط إعادة نقل الحزم المفقودة باستخدام TCP.

يوفر TCP تسليم البيانات بترتيب من المستخدم إلى الخادم (والعكس بالعكس)، بينما لا تُكرّس UDP للاتصالات من طرف إلى طرف، ولا يفحص جاهزية المستقبل.

| الميزة              | TCP                                            | UDP                              |
| -------------------- | --------------------------------------------- | -------------------------------- |
| الاتصال             | يتطلب اتصال مؤسس                             | بروتوكول بدون اتصال            |
| توصيل مضمون        | يمكن ضمان توصيل البيانات                  | لا يمكن ضمان توصيل البيان

ات   |
| إعادة النقل        | يمكن إعادة نقل الحزم المفقودة             | لا توجد إعادة نقل للحزم المفقودة |
| السرعة              | أبطأ من UDP                                  | أسرع من TCP                    |
| البث المتعدد       | لا يدعم البث المتعدد                        | يدعم البث المتعدد              |
| حالات الاستخدام    | HTTPS، HTTP، SMTP، POP، FTP، وغيرها         | بث الفيديو، DNS، VoIP، وغيرها  |

# نظام أسماء النطاقات (DNS)

في وقت سابق تعلمنا عن عناوين IP التي تمكّن كل جهاز من الاتصال بالأجهزة الأخرى. ولكن كما نعلم، يفضل البشر التعامل مع الأسماء بدلاً من الأرقام. فمن الأسهل تذكر اسم مثل `google.com` بدلاً من شيء مثل `122.250.192.232`.

وهذا يجلبنا إلى نظام أسماء النطاقات (DNS) وهو نظام تسمية هرمي ومركزي يُستخدم لتحويل أسماء النطاقات التي يمكن قراءتها بواسطة الإنسان إلى عناوين IP.

## كيفية عمل DNS

يتضمن بحث DNS الخطوات التالية الثمانية:

1. يقوم العميل بكتابة [example.com](http://example.com) في متصفح الويب، ويتم نقل الاستعلام عبر الإنترنت ويتم استقباله من قبل حل المسمى DNS.
2. يقوم حل المسمى DNS بالاستعلام بشكل متكرر إلى خادم جذر DNS.
3. يقوم خادم الجذر بالرد على حل المسمى بمعلومات حول خادم نطاق أعلى (TLD).
4. يقوم حل المسمى ثم بإجراء طلب لـ TLD `.com`.
5. يقوم خادم TLD بالرد بعنوان IP لخادم أسماء النطاق، [example.com](http://example.com).
6. في النهاية، يرسل حل المسمى DNS طلبًا إلى خادم أسماء النطاق.
7. يتم إرجاع عنوان IP لـ [example.com](http://example.com) ثم يتم إرساله إلى حل المسمى DNS من قبل خادم أسماء النطاق.
8. يقوم حل المسمى DNS ثم بالرد على متصفح الويب بعنوان IP للنطاق المطلوب أصلاً.

بمجرد تحديد عنوان IP، يجب أن يكون العميل قادرًا على طلب المحتوى من العنوان IP الذي تم تحديده. على سبيل المثال، يمكن أن يعيد العنوان IP المحدد صفحة ويب ليتم عرضها في المتصفح.

## أنواع الخوادم

الآن، دعونا نلقي نظرة على أربعة مجموعات رئيسية من الخوادم التي تشكل بنية DNS.

### حل المسمى DNS

حل المسمى DNS (المعروف أيضًا باسم حل المسمى المتكرر DNS) هو أول محطة في استعلام DNS. يعمل حل المسمى المتكرر كوسيط بين عميل وخادم أسماء DNS. بعد استقبال استعلام DNS من عميل الويب، يرد حل المسمى المتكرر بالبيانات المخبأة أو يرسل طلبًا إلى خادم جذر DNS، تليه طلب آخر إلى خادم TLD، ومن ثم طلب آخر إلى خادم أسماء مخول به. بعد استقبال استجابة من خادم الأسماء المخول به تحتوي على عنوان IP المطلوب، يرسل حل المسمى المتكرر بالاستجابة إلى العميل.

### خادم جذر DNS

يقبل خادم جذر استعلامًا من حل المسمى المتكرر يتضمن اسم نطاق، ويقوم خادم الجذر بالرد على حل المسمى المتكرر بتوجيهه إلى خادم TLD، بناءً على امتداد ذلك النطاق (`.com`، `.net`، `.org`، إلخ). يتم الإشراف على خوادم الجذر من قبل جمعية غير هادفة للربح تُسمى [Internet Corporation for Assigned Names and Numbers (ICANN)](https://www.icann.org).

هناك 13 خادم جذر لأسماء DNS يعرفها كل حل المسمى المتكرر. يُلاحظ أنه على الرغم من وجود 13 خادمًا جذريًا، فإن ذلك لا يعني أن هناك فقط 13 جهازًا في نظام خوادم الجذر. هناك 13 نوعًا من خوادم الجذر، لكن هناك عدة نسخ من كل واحد في جميع أنحاء العالم، تستخدم توجيه [An

ycast](https://en.wikipedia.org/wiki/Anycast) لتوفير استجابة سريعة.

### خادم TLD

يحتفظ خادم TLD بالمعلومات لجميع أسماء النطاق التي تشترك في امتداد نطاق مشترك، مثل `.com`، `.net`، أو أي امتداد آخر يأتي بعد النقطة الأخيرة في عنوان URL.

تتم معالجة خوادم TLD بواسطة [هيئة الأرقام المخصصة للإنترنت (IANA)](https://www.iana.org)، والتي تعد فرعًا لـ [ICANN](https://www.icann.org). تقسم IANA خوادم TLD إلى مجموعتين رئيسيتين:

- **النطاقات العامة على مستوى أعلى**: وهذه النطاقات مثل `.com`، `.org`، `.net`، `.edu`، و `.gov`.
- **نطاقات رمز البلد العلوية**: وتشمل أي نطاقات تخص دولة معينة أو ولاية. أمثلة على ذلك `.uk`، `.us`، `.ru`، و `.jp`.

### خادم أسماء DNS المخول به

يكون خادم أسماء النطاق المخول به عادة آخر خطوة لحل المسمى المتكرر في رحلة للحصول على عنوان IP. يحتوي خادم أسماء النطاق المخول به على معلومات محددة لاسم النطاق الذي يخدمه (مثل [google.com](http://google.com)) ويمكنه توفير عنوان IP لهذا الخادم الموجود في سجل DNS A، أو إذا كان للنطاق سجل CNAME (اسم مستعار)، فسيقوم بتوجيه حل المسمى المتكرر بنطاق اسم مستعار آخر، وفي هذه النقطة يتعين على حل المسمى المتكرر إجراء بحث جديد بالكامل للحصول على سجل من خادم أسماء النطاق المخول به (عادة سجل A يحتوي على عنوان IP). إذا لم يتم العثور على النطاق، يُرجع رسالة NXDOMAIN.

## أنواع الاستعلامات

هناك ثلاثة أنواع من الاستعلامات في نظام DNS:

### الاستعلام المتكرر

في الاستعلام المتكرر، يتطلب عميل DNS أن يستجيب له خادم DNS (عادةً حل المسمى المتكرر) بإما سجل الموارد المطلوب أو رسالة خطأ إذا لم يتمكن حل المسمى المتكرر من العثور على السجل.

### الاستعلام التكراري

في الاستعلام التكراري، يقدم عميل DNS اسم مضيف، ويقوم حل المسمى DNS بإرجاع أفضل إجابة يمكنها. إذا كان حل المسمى المتكرر لديه سجلات DNS ذات الصلة في ذاكرته المخبأة، فيتم إرجاعها. إذا لم يكن الأمر كذلك، فإنه يحيل عميل DNS إلى خادم جذري أو خادم أسماء مخول به آخر الذي يكون أقرب إلى المنطقة المطلوبة لـ DNS. يجب على عميل DNS إعادة الاستعلام

 مباشرةً ضد خادم DNS الذي أحيل إليه.

### الاستعلام غير المتكرر

الاستعلام غير المتكرر هو استعلام يعرف حل المسمى المتكرر بالفعل عن الإجابة. إما أنه يعود بسجل DNS على الفور لأنه يحتوي بالفعل على السجل في ذاكرته المحلية، أو يستعلم خادم أسماء DNS المخول به الذي يحمل المسؤولية عن السجل، مما يعني أنه يحمل بالتأكيد العنوان IP الصحيح لتلك الاسم.

## أنواع السجلات

سجلات DNS (أو ملفات النطاق) هي تعليمات توجد في خوادم أسماء النطاق المخول بها وتوفر معلومات حول نطاق بما في ذلك عنوان IP المرتبط بتلك النطاق وكيفية التعامل مع طلبات تلك النطاق.

تتألف هذه السجلات من سلسلة من الملفات النصية المكتوبة بما يُعرف باسم "نحو DNS". يعتبر نحو DNS مجرد سلسلة من الأحرف المستخدمة كأوامر تخبر خادم DNS بما يجب عليه القيام به. يحتوي جميع سجلات DNS أيضًا على "TTL"، والذي يعني الوقت المتبقي على صلاحية السجل. عند تخزين السجل في الذاكرة المؤقتة، يتم تخزين قيمة TTL المصاحبة له أيضًا. يستمر الخادم في تحديث قيمة TTL للسجل المخزن في الذاكرة المؤقتة، ويقوم بالعد التنازلي كل ثانية. عندما يصل إلى الصفر، يتم حذف السجل أو إزالته من الذاكرة المؤقتة. في تلك النقطة، إذا تم استلام استعلام لذلك السجل، يتعين على خادم DNS بدء عملية الحل.

## DNS المعكوس

بحث DNS المعكوس هو استعلام DNS لاسم النطاق المرتبط بعنوان IP المحدد. يعمل هذا عكس البحث عن استخدام بحث DNS المعكوس بشكل أكثر استخدامًا المعروف باسم بحث DNS المستعرض، حيث يتم استعلام النظام DNS لإرجاع عنوان IP. يستخدم عملية تحليل العنوان IP المعكوس سجلات PTR. إذا لم يكن لدى الخادم سجل PTR، فلن يتمكن من حل البحث المعكوس.

يُستخدم بحث العودة بشكل شائع بواسطة خوادم البريد الإلكتروني. تفحص خوادم البريد الإلكتروني وترى ما إذا كانت رسالة البريد الإلكتروني قد أتت من خادم صالح قبل إدخالها إلى شبكتها. قد ترفض العديد من خوادم البريد الإلكتروني رسائل من أي خادم لا يدعم بحث ال

عودة أو من خادم غير محتمل للغاية.

ملحوظة: قد لا يتم اعتماد بحث DNS المعكوس عالميًا لأنه ليس ضروريًا للوظائف الطبيعية للإنترنت.

## أمثلة

هذه بعض الحلول لإدارة DNS المُستخدمة على نطاق واسع:

- [Route53](https://aws.amazon.com/route53)
- [Cloudflare DNS](https://www.cloudflare.com/dns)
- [Google Cloud DNS](https://cloud.google.com/dns)
- [Azure DNS](https://azure.microsoft.com/en-in/services/dns)
- [NS1](https://ns1.com/products/managed-dns)

# توزيع الحمل

توزيع الحمل يسمح لنا بتوزيع حركة المرور الشبكية الواردة عبر مصادر متعددة لضمان التوافر العالي والموثوقية عن طريق إرسال الطلبات فقط إلى المصادر التي تكون متصلة بالشبكة وجاهزة للعمل. يوفر هذا المرونة في إضافة أو إزالة المصادر حسب الطلب.

![توزيع الحمل](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/load-balancing/load-balancer.png)

للحصول على مزيد من التوسعية والاحتياطية، يمكننا تطبيق توزيع الحمل على كل طبقة في نظامنا:

![طبقات توزيع الحمل](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/load-balancing/load-balancer-layers.png)

## لكن لماذا؟

يجب أن تكون المواقع الحديثة عالية الحركة قادرة على تلبية مئات الآلاف، إن لم يكن الملايين، من الطلبات المتزامنة من المستخدمين. لتحقيق التوسع الفعال لتلبية هذه الأحمال العالية، يتطلب المعتمد عليه في الحوسبة الحديثة إضافة مزيد من الخوادم.

يمكن أن يكون توزيع الحمل أمام الخوادم وتوجيه طلبات العملاء عبر جميع الخوادم القادرة على تلبية هذه الطلبات بطريقة تزيد من سرعة واستخدام القدرات. يضمن هذا ألا يتم استغلال خادم واحد بشكل مفرط، مما قد يؤدي إلى تدهور الأداء. إذا تعطل خادم واحد، يقوم توزيع الحمل بإعادة توجيه حركة المرور إلى الخوادم المتاحة. عند إضافة خادم جديد إلى مجموعة الخوادم، يقوم توزيع الحمل تلقائيًا ببدء إرسال الطلبات إليه.

## توزيع الأعباء العمل

هذه هي الوظيفة الأساسية التي يقدمها توزيع الحمل ولها العديد من التغييرات الشائعة:

- **بناءً على المضيف**: يوزع الطلبات بناءً على اسم المضيف المطلوب.
- **بناءً على المسار**: يستخدم العنوان الكامل لعنوان URL لتوزيع الطلبات بدلاً من المضيف فقط.
- **بناءً على المحتوى**: يفحص محتوى الرسالة للطلب. يتيح ذلك التوزيع بناءً على المحتوى مثل قيمة معلمة معينة.

## الطبقات

بشكل عام، يعمل توزيع الحمل على أحد المستويين التاليين:

### الطبقة الشبكية

هذا هو توزيع الحمل الذي يعمل على مستوى الشبكة ويعرف أيضًا باسم المستوى 4. يقوم بالتو

جيه بناءً على معلومات الشبكة مثل عناوين IP ولا يمكنه القيام بتوجيه بناءً على المحتوى. عادة ما تكون هذه الأجهزة مخصصة لتوزيع الحمل وتستطيع العمل بسرعة عالية.

### الطبقة التطبيقية

هذا هو توزيع الحمل الذي يعمل على مستوى التطبيق ويعرف أيضًا باسم المستوى 7. يمكن لتوزيع الحمل قراءة الطلبات بأكملها والقيام بتوزيع بناءً على المحتوى. يتيح ذلك إدارة الحمل بناءً على فهم كامل لحركة المرور.

## الأنواع

لنلقي نظرة على أنواع مختلفة من توزيع الحمل:

### البرمجيات

غالبًا ما تكون الحملات البرمجية أسهل في التنفيذ مقارنة بالإصدارات الأجهزة. كما أنها تميل إلى أن تكون أكثر كفاءة من حيث التكلفة ومرونة، وتُستخدم بالتعاون مع بيئات تطوير البرمجيات. يمنحنا النهج البرمجي مرونة تكوين موازن الحمل وفقًا لاحتياجات بيئتنا الخاصة. وقد يكون هذا التحسين في المرونة على حساب الحاجة للقيام بمزيد من العمل لإعداد توازن الحمل. بالمقارنة مع الإصدارات الأجهزة التي توفر نهجًا أكثر تقييدًا، تمنحنا الأنظمة البرمجية حرية أكبر لإجراء التغييرات والترقيات.

تُستخدم الحملات البرمجية على نطاق واسع وتتوفر إما كحلول قابلة للتثبيت تتطلب التكوين والإدارة، أو كخدمة سحابية مُدارة.

### الأجهزة

كما يوحي الاسم، يعتمد توزيع الحمل على الأجهزة الفعلية في الموقع لتوزيع حركة التطبيق والشبكة. يمكن أن تتعامل هذه الأجهزة مع حجم كبير من حركة المرور ولكنها غالبًا ما تحمل تكلفة باهظة ومحدودة إلى حد ما من حيث المرونة.

تشتمل أجهزة توزيع الحمل على برامج محددة تتطلب صيانة وتحديثات عند صدور الإصدارات الجديدة والتصحيحات الأمنية.

### DNS

توزيع الحمل في نظام أسماء النطاقات (DNS) يتضمن تكوين نطاق في نظام أسماء النطاقات بحيث تتم توزيع طلبات العملاء عبر مجموعة من خوادم الخادم.

مع الأسف، يعاني توزيع الحمل في نظام أسماء النطاقات من مشكلات تقلل من موثوقيته وكفاءته. الأمر الأكثر أهمية هو أن نظام أسماء النطاقات لا يتحقق من تعطل الخوادم أو الشبكات أو الأخطاء. دائمًا ما يعيد نفس مجموعة عناوين IP لنطاق حتى إذا كانت الخوادم غير متصلة بالشبكة أو لا يمكن الوصول إليها.

## خوارزميات التوجيه

الآن، دعنا نناقش بعض خوارزميات التوجيه الشائعة المستخدمة:

- **Round-robin**: يتم توزيع الطلبات ع

لى خوادم التطبيق بالتناوب.
- **Weighted Round-robin**: يعتمد على تقنية Round-robin البسيطة ويأخذ في اعتبار خصائص الخادم المختلفة مثل قدرة الحساب ومعالجة حركة المرور باستخدام أوزان يمكن تعيينها عن طريق سجلات DNS من قبل المسؤول.
- **Least Connections**: يتم إرسال طلب جديد إلى الخادم الذي يحتوي على أقل عدد من الاتصالات الحالية إلى العملاء. يتم احتساب القدرة الحسابية النسبية لكل خادم عند تحديد الخادم الذي يحتوي على أقل عدد من الاتصالات.
- **Least Response Time**: يرسل الطلبات إلى الخادم الذي تم اختياره باستخدام معادلة تجمع بين أسرع وقت استجابة وأقل عدد من الاتصالات النشطة.
- **Least Bandwidth**: يقيس حركة المرور بالميجابت في الثانية (ميغابت في الثانية) ويقوم بإرسال طلبات العملاء إلى الخادم الذي يحتوي على أدنى ميجابت في الثانية من حركة المرور.
- **Hashing**: يوزع الطلبات بناءً على مفتاح نحدده مثل عنوان IP الخاص بالعميل أو عنوان URL للطلب.

## المزايا

تلعب توزيع الحمل أيضًا دورًا رئيسيًا في منع التوقف، وتشمل المزايا الأخرى لتوزيع الحمل ما يلي:

- التوسعية
- الاحتياطية
- المرونة
- الكفاءة

## توزيع الأحمال المكررة

كما يمكن أن نتوقع، فإن توزيع الحمل نفسه يمكن أن يكون نقطة فردية للفشل. للتغلب على ذلك، يمكن استخدام خادم آخر أو عدد "N" من خوادم التوزيع في وضع عنقودي.

وإذا كان هناك اكتشاف للفشل وفشل الخادم التوزيع "النشط"، يمكن لخادم آخر "السلبي" أن يتولى السيطرة مما يجعل نظامنا أكثر قدرة على تحمل الأخطاء.

## المميزات

فيما يلي بعض الميزات المطلوبة بشكل شائع لخوادم التوزيع:

- **التوسع التلقائي**: تشغيل وإيقاف الموارد استجابةً لظروف الطلب.
- **جلسات لاصقة**: القدرة على تعيين نفس المستخدم أو الجهاز إلى نفس المصدر للحفاظ على حالة الجلسة على المصدر.
- **فحص الصحة**: القدرة على تحديد ما إذا كان مصدر ما غير متصل أو يعمل بشكل سيئ لإزالته من مجموعة توزيع الحمل.
- **الاتصالات الثابتة**: السماح للخادم بفتح اتصال ثابت مع العميل مثل WebSocket.
- **التشفير**: التعامل مع الاتصالات المشفرة مثل TLS و SSL.
- **الشهادات**: تقديم شهادات للعميل ومصادقة شهادات العميل.
- **ضغط البيانات**: ضغط الاستجابات.
- **التخزين المؤقت**: قد يقدم خادم توزيع الحمل القدرة على تخزين مؤقت للاستجابات.
- **تسجيل الأحداث**: تسجيل بيانات الطلب والاستجابة يمكن أن يكون مسارًا تدقيقًا هامًا أو مصدرًا لبيانات التحليل.
- **تتبع الطلبات**: تعيين معرف فريد لكل طلب لأغراض التسجيل والمراقبة وإصلاح الأخطاء.
- **إعادة التوجيه**: القدرة على إعادة توجيه طلب وارد بناءً على عوامل مثل المسار المطلوب.
- **استجابة ثابتة**: إرجاع استجابة ثابتة للطلب مثل رسالة خطأ.

## أمثلة

فيما يلي بعض حلول توزيع الح

مل المستخدمة على نطاق واسع في الصناعة:

- [Amazon Elastic Load Balancing](https://aws.amazon.com/elasticloadbalancing)
- [Azure Load Balancing](https://azure.microsoft.com/en-in/services/load-balancer)
- [GCP Load Balancing](https://cloud.google.com/load-balancing)
- [DigitalOcean Load Balancer](https://www.digitalocean.com/products/load-balancer)
- [Nginx](https://www.nginx.com)
- [HAProxy](http://www.haproxy.org)



# التجميع (التَّكْتُل)

في المستوى العالي، تكون المجموعة الحاسوبية مجموعة من جهازين أو أكثر، أو عقدتين، تعمل متوازية لتحقيق هدف مشترك. يسمح ذلك بتوزيع الأعباء التي تتألف من عدد كبير من المهام الفردية التي يمكن توازنها بين العقد في التجمُّع. ونتيجةً لذلك، يمكن لهذه المهام استغلال الذاكرة المشتركة وقوة المعالجة لكل جهاز لزيادة الأداء العام.

لبناء تجميع حاسوبي، يجب أن يكون العقد الفردي متصل بشبكة لتمكين التواصل بين العقد. يمكن بعد ذلك استخدام البرامج لربط العقد معًا وتشكيل التجميع. قد يحتوي التجميع على جهاز تخزين مشترك و/أو تخزين محلي في كل عقد.

![cluster](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/clustering/cluster.png)

عادةً، يُعين عقدة واحدة على الأقل كعقدة قائدة وتعمل كنقطة الدخول إلى التجمُّع. قد تكون العقدة القائدة مسؤولة عن تفويض العمل الوارد إلى العقد الآخر وإذا لزم الأمر، تجميع النتائج وإرجاع الاستجابة إلى المستخدم.

في الأفضل، يعمل التجميع كما لو أنه نظام واحد. يجب على المستخدم الوصول إلى التجمُّع ألا يحتاج إلى معرفة ما إذا كان النظام عبارة عن تجمُّع أم جهاز فردي. علاوة على ذلك، يجب أن يتم تصميم التجمُّع لتقليل التأخير ومنع التكدس في التواصل بين العقد.

## أنواع التجمُّع

يمكن عمومًا تصنيف التجميعات الحاسوبية إلى ثلاثة أنواع:

1. **مرتفعة الاستعداد (فشل تلقائي)**
2. **توزيع الحمل**
3. **الحوسبة العالية الأداء**

## التكوينات

تتكون أكثر التكوينات المستخدمة بشكل شائع للتجميعات عالية الاستعداد (HA) من نمطين هما: "نشط-نشط" و "نشط-سلبي".

### "نشط-نشط"

![active-active](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/clustering/active-active.png)

عادةً، يتألف التجميع "نشط-نشط" من على الأقل عقدين، يعمل كلاهما بنفس نوع الخدمة بنفس الوقت. الغرض الرئيسي من تجميع "نشط-نشط" هو تحقيق توازن الحمولة. يقوم جهاز توزيع الحمولة بتوزيع الأعباء عبر جميع العقد لمنع أي عقدة فردية من أن تتحمل حمولة زائدة. نظرًا لتوافر المزيد من العقد للخدمة، سيكون هناك أيضًا تحسين في الإنتاجية وأوقات الاستجابة.

### "نشط-سلبي"

![active-passive](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/clustering/active-passive.png)

مثل تكوين التجميع "نشط-نشط"، يتكون تجميع "نشط-سلبي" أيضًا من على الأقل عقدين. ومع ذلك، كما يوحي الاسم "نشط-سلبي"، لن تكون جميع العقد نشطة. على سبيل المثال، في حالة وجود عقدين، إذا كان العقد الأول نشطًا بالفعل، فإن العقد الثاني يجب أن يكون سلبيًا أو في وضع الاستعداد.

## المزايا

أربعة مزايا رئيسية للتجمُّع الحاسوبي هي:

- التوفر العالي
- التوسعية
- الأداء
- التكل

فة الفعالة

## توازن الحمل مقابل التجميع

تشترك توازن الحمل في بعض الخصائص المشتركة مع التجميع، ولكنهما عمليات مختلفة. يوفر التجميع الاستعدادية ويزيد من القدرة والتوافر. السيرفرات في التجمُّع يدركون بعضهم البعض ويعملون معًا نحو هدف مشترك. ومع ذلك، في حالة توازن الحمل، لا تدرك السيرفرات بعضها البعض. بدلاً من ذلك، يتفاعلون مع الطلبات التي يتلقونها من جهاز توزيع الحمل.

يمكننا استخدام توازن الحمل بالاشتراك مع التجمُّع، لكنه أيضًا قابل للتطبيق في الحالات التي تنطوي على السيرفرات المستقلة التي تشترك في هدف مشترك مثل تشغيل موقع ويب أو تطبيق تجاري أو خدمة ويب أو مورد آخر من موردي تكنولوجيا المعلومات.

## التحديات

أكثر التحديات وضوحًا التي يقدمها التجمُّع هي زيادة تعقيد التثبيت والصيانة. يجب تثبيت نظام التشغيل والتطبيق وتبعياته على كل عقدة بشكل منفصل وتحديثها بانتظام.

يصبح هذا أكثر تعقيدًا إذا كانت العقد في التجميع غير متجانسة. يجب أيضًا مراقبة استخدام الموارد لكل عقدة عن كثب، ويجب أن يتم تجميع السجلات لضمان أن البرامج تتصرف بشكل صحيح.

بالإضافة إلى ذلك، يصبح إدارة التخزين أكثر صعوبة، ويجب أن يمنع جهاز التخزين المشترك من كتابة العقد بعضها البعض ويجب الاحتفاظ بمخازن البيانات الموزعة متزامنة.

## أمثلة

يُستخدم التجمُّع بشكل شائع في الصناعة، وغالبًا ما تُقدم العديد من التقنيات وضع التجمُّع بأنواع مختلفة. على سبيل المثال:

- الحاويات (مثل [Kubernetes](https://kubernetes.io)، [Amazon ECS](https://aws.amazon.com/ecs))
- قواعد البيانات (مثل [Cassandra](https://cassandra.apache.org/_/index.html)، [MongoDB](https://www.mongodb.com))
- التخزين المؤقت (مثل [Redis](https://redis.io/docs/manual/scaling))

# التخزين المؤقت (Caching)

_"هناك فقط شيئين صعبين في علم الحاسوب: إبطال التخزين المؤقت وتسمية الأشياء." - فيل كارلتون_

![التخزين المؤقت](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/caching/caching.png)

الهدف الأساسي للتخزين المؤقت هو زيادة أداء استرداد البيانات عن طريق تقليل الحاجة للوصول إلى الطبقة البطيئة الأساسية للتخزين. يتم التضحية بالقدرة من أجل السرعة، حيث يخزن التخزين المؤقت عادةً مجموعة من البيانات بشكل مؤقت، بالمقارنة مع قواعد البيانات التي يكون عادةً بياناتها كاملة ودائمة.

يستغل التخزين المؤقت مبدأ قرب المرجعية _"البيانات التي طلبت مؤخرًا من المرجح أن يتم طلبها مرة أخرى"._

## التخزين المؤقت والذاكرة

مثل ذاكرة الحاسوب، يعتبر التخزين المؤقت ذاكرة سريعة ومدمجة تقوم بتخزين البيانات في تسلسل من المستويات، حيث يبدأ المستوى الأول (L1) ويتقدم تدريجيًا إلى المستوى التالي وهكذا. تحمل هذه المستويات التسميات L1، L2، L3، وهكذا. يتم أيضًا كتابة التخزين المؤقت عند الطلب، مثل عند وجود تحديث ويجب حفظ محتوى جديد في التخزين المؤقت لاستبدال المحتوى القديم الذي تم حفظه.

بغض النظر عما إذا كان التخزين المؤقت يتم قراءته أو كتابته، يتم ذلك بشكل تدريجي على شكل كتلة. كل كتلة تحمل علامة (tag) تشمل الموقع الذي تم تخزين البيانات فيه بالتخزين المؤقت. عندما يتم طلب البيانات من التخزين المؤقت، يتم البحث عن البيانات من خلال العلامات للعثور على المحتوى المطلوب في المستوى الأول (L1) من الذاكرة. إذا لم يتم العثور على البيانات الصحيحة، يتم إجراء بحث إضافي في المستوى الثاني (L2).

إذا لم يتم العثور على البيانات هناك، يتم مواصلة البحث في المستوى الثالث (L3)، ثم المستوى الرابع (L4)، وهكذا حتى يتم العثور عليها وقرائتها وتحميله

ا. إذا لم يتم العثور على البيانات في التخزين المؤقت على الإطلاق، يتم كتابتها فيه لاستردادها بسرعة في المرة القادمة.

## الاصطدام والفاقد في التخزين المؤقت

### الاصطدام (Cache hit)

يصف الاصطدام الحالة عندما يتم تقديم المحتوى بنجاح من التخزين المؤقت. تتم البحث في العلامات في الذاكرة بسرعة، وعندما يتم العثور على البيانات وقرائتها، يعتبر ذلك اصطدامًا ناجحًا.

**التخزين المؤقت البارد، الدافئ، والساخن**

يمكن وصف الاصطدام بأنه بارد، دافئ، أو ساخن. في كل حالة من هذه الحالات، يتم وصف سرعة قراءة البيانات.

التخزين المؤقت الساخن يحدث عندما يتم قراءة البيانات من الذاكرة بأسرع معدل ممكن. يحدث هذا عند استرداد البيانات من المستوى الأول (L1).

التخزين المؤقت البارد هو أبطأ معدل ممكن لقراءة البيانات، لكنه ما زال ناجحًا، لأن البيانات تم العثور عليها في المستوى الأدنى من التسلسل الهرمي مثل المستوى الثالث (L3) أو أدنى.

التخزين المؤقت الدافئ يستخدم لوصف البيانات التي تم العثور عليها في المستوى الثاني (L2) أو الثالث (L3). إنه ليس بسرعة التخزين المؤقت الساخن، لكنه أسرع من التخزين المؤقت البارد. عمومًا، يتم استخدام مصطلح التخزين المؤقت الدافئ للتعبير عن بطءه واقترابه من التخزين المؤقت البارد.

### الفاقد (Cache miss)

يشير الفاقد إلى حالة عدم العثور على البيانات عند البحث في الذاكرة. عندما يحدث هذا، يتم نقل المحتوى وكتابته في التخزين المؤقت.

## إبطال التخزين المؤقت

إبطال التخزين المؤقت هو عملية تعلن فيها نظام الحاسوب إدخالات التخزين المؤقت كغير صالحة ويقوم بإزالتها أو استبدالها. إذا تم تعديل البيانات، يجب إبطالها في التخزين المؤقت، فإذا لم يتم ذلك، فقد يتسبب ذلك في تواتر غير متناسق في سلوك التطبيق. هناك ثلاثة أنواع من أنظمة التخزين المؤقت:

### التخزين المؤقت المتجاوب بالكتابة (Write-through cache)

![التخزين المؤقت المتجاوب بالكتابة](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/caching/write-through-cache.png)

يتم كتابة البيانات في التخزين المؤقت وفي قاعدة البيانات المقابلة في وقت واحد.

**المزايا**: استرداد سريع، استقامة البيانات الكاملة بين التخزين المؤقت والتخزين الدائم.

**العيوب**: وقت الانتظار الأعلى لعمليات الكتابة.

### التخزين المؤقت المتجاوب بالتجاوز (Write-around cache)

![التخزين المؤقت المتجاوب بالتجاوز](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/caching/write-around-cache.png)

تذهب الكتابة مباشرة إلى قاعدة البيانات أو التخزين الدائم، متجاوزةً التخزين المؤقت.

**المزايا**: يمكن أن يؤدي ذلك إلى تقليل الانتظار.

**العيوب**: يزيد من احتمال فقدان التخزين المؤقت بسبب قراءة المعلومات من قاعدة البيانات في حالة فقدان التخزين المؤقت. بالتالي، قد يؤدي ذلك إلى زيادة عدد الفاقدين في التخزين المؤقت، مما يؤدي إلى زيادة زمن الانتظار لعمليات القراءة في التطبيقات التي تقوم بالكتابة وإعادة قراءة المعلومات بسرعة. القراءة تحدث من التخزين الخلفي الأبطأ وتعاني من ارتفاع زمن الانتظار.

### التخزين المؤقت المتأخر في الكتابة (Write-back cache)

![التخزين المؤقت المتأخر في الكتابة](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/caching/write-back-cache.png)

يتم كتابة البيانات فقط في طبقة التخزين المؤقت ويتم تأكيد الكتابة بمجرد اكتمال الكتابة في التخزين المؤقت. يتم مزامنة هذه الكتابة في وقت لاحق مع قاعدة البيانات.

**المزايا**: يؤدي إلى تقليل وقت الانتظار وزيادة الإنتاجية لتطبيقات الكتابة المكثفة.

**العيوب**: هناك خطر فقدان البيانات في حالة تعطل التخزين المؤقت. يمكن تحسين هذا من خلال الحصول على موافقة عن كتابة واحدة من أكثر من نسخة في التخزين المؤقت.

## سياسات الطرد من التخزين المؤقت

فيما يلي بعض أشهر سياسات الطرد من التخزين المؤقت:

- **الأولوية للأولوية للأولوية للأولوية (FIFO)**: يقوم التخزين المؤقت بطرد البلوك الذي تم الوصول إليه أولاً بدون اعتبار لكيفية وكم مرة تم الوصول إليه قبل ذلك.
- **الأولوية للأخير للأولوية للأخير (LIFO)**: يقوم التخزين المؤقت بطرد البلوك الذي تم الوصول إليه مؤخرًا بشكل أولوي دون اعتبار لكيفية وكم مرة تم الوصول إليه قبل ذلك.
- **المستخدم الأقل للأولوية للأخير (LRU)**: يقوم بطرد العناصر التي تم استخدامها بشكل أقل في البداية.
- **المستخدم الأكثر للأولوية للأخير (MRU)**: يقوم بطرد العناصر التي تم استخدامها بشكل أكثر من LRU.
- **الأقل استخدامًا للأولوية للأخير (LFU)**: يحسب مدى استخدام العنصر. يتم طرد تلك التي تم استخدامها بشكل أقل في البداية.
- **الاستبدال العشوائي (RR)**: يختار عنصر مرشح بشكل عشوائي ويقوم بطرده لإفساح المساحة عند الحاجة.

## التخزين المؤقت الموزع

![التخزين المؤقت الموزع](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/caching/distributed-cache.png)

التخزين المؤقت الموزع هو نظام يجمع بين ذاكرة الوصول العشوائي (RAM) لعدة أجهزة حاسوب متصلة في شبكة واحدة في مخزن بيانات مؤقت واحد مستخدمًا للوصول السريع إلى البيانات. بينما يكون معظم التخزينات المؤقتة تقليديًا في جهاز خادم واحد أو جزء من الأجهزة، يمكن للتخزين المؤقت الموزع أن ينمو ليتجاوز حدود الذاكرة لجهاز كمبيوتر واحد عن طريق ربط عدة أجهزة معًا.

## التخزين المؤقت العالمي

![التخزين المؤقت العالمي](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/caching/global-cache.png)

كما يوحي الاسم، سنمتلك تخزين مؤقت مشترك واحد سيستخدمه جميع عقد التطبيق. عندما لا يتم العثور على البيانات المطلوبة في التخزين المؤقت العالمي، فمسؤولية التخزين المؤقت هو العثور على الجزء المفقود من البيانات من مخزن البيانات الأساسي.

## الحالات الاستخدامية

يمكن أن يكون للتخزين المؤقت العديد من الحالات الاستخدامية في العالم الحقيقي مثل:

- التخزين المؤقت لقاعدة البيانات
- شبكة تسليم المحتوى (CDN)
- التخزين المؤقت لنظام اسم النطاق (DNS)
- التخزين المؤقت لواجهة برمجة التطبيق (API)

**متى لا يجب استخدام التخزين المؤقت؟**

لنلق نظرة أيضًا على بعض السيناريوهات التي يجب ألا نستخدم فيها التخزين المؤقت:

- التخزين المؤقت لا يكون مفيدًا عندما يستغرق الوصول إلى التخزين المؤقت بنفس الوقت الذي يستغرقه الوصول إلى مخزن البيانات الأساسي.
- التخزين المؤقت لا يعمل بشكل جيد عندما تكون الطلبات تتكرر بشكل منخفض (أكبر فوض

وية)، لأن أداء التخزين المؤقت يعتمد على أنماط الوصول إلى الذاكرة المتكررة.
- التخزين المؤقت لا يكون مفيدًا عندما يتغير البيانات بشكل متكرر، حيث يتجاوز الإصدار المخزن مؤقتًا ويجب الوصول إلى مخزن البيانات الأساسي في كل مرة.

_من المهم أن نلاحظ أن التخزين المؤقت لا يجب أن يُستخدم كتخزين دائم للبيانات. فهي تُنفذ عادةً في الذاكرة العشوائية لأنها أسرع، وبالتالي يجب أن تُعتبر غير دائمة._

## المزايا

فيما يلي بعض المزايا للتخزين المؤقت:

- يحسن الأداء
- يقلل من التأخير
- يخفف العبء على قاعدة البيانات
- يقلل من تكلفة الشبكة
- يزيد من قدرة القراءة

## أمثلة

وفيما يلي بعض التقنيات المستخدمة عادة للتخزين المؤقت:

- [Redis](https://redis.io)
- [Memcached](https://memcached.org)
- [Amazon Elasticache](https://aws.amazon.com/elasticache)
- [Aerospike](https://aerospike.com)



# شبكة توزيع المحتوى (CDN)

شبكة توزيع المحتوى (CDN) هي مجموعة من الخوادم الموزعة جغرافيًا تعمل معًا لتوفير تسليم سريع للمحتوى على الإنترنت. عمومًا، يتم تقديم الملفات الثابتة مثل HTML/CSS/JS والصور ومقاطع الفيديو من CDN.

![cdn-map](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/content-delivery-network/cdn-map.png)

## لماذا استخدام CDN؟

تزيد شبكة توزيع المحتوى (CDN) من توافر المحتوى والتكرارية مع تقليل تكاليف النطاق الترددي وتحسين الأمان. يمكن أن يحسن تقديم المحتوى من خلال CDNs الأداء بشكل كبير حيث يحصل المستخدمون على المحتوى من مراكز البيانات القريبة منهم ولا يتعين على خوادمنا تلبية الطلبات التي يقوم CDN بتحقيقها.

## كيفية عمل CDN؟

![cdn](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/content-delivery-network/cdn.png)

في CDN، يحتوي الخادم الأصلي على النسخ الأصلية من المحتوى بينما تكون خوادم الحافة (الحافة) كثيرة وموزعة في مواقع مختلفة حول العالم.

لتقليل المسافة بين الزائرين وخادم موقع الويب، تقوم CDN بتخزين نسخة مخزنة من محتواها في عدة مواقع جغرافية معروفة باسم مواقع الحافة. تحتوي كل موقع حافة على العديد من خوادم التخزين المسؤولة عن تقديم المحتوى للزوار ضمن نطاقها.

بمجرد أن يتم تخزين المحتوى الثابت على جميع خوادم CDN لموقع معين، سيتم تقديم جميع طلبات زوار الموقع اللاحقة للمحتوى الثابت من هذه الخوادم الحافة بدلاً من الأصل، وبالتالي يتم تقليل العبء على الأصل وتحسين القدرة على التوسع.

على سبيل المثال، عندما يطلب شخص ما في المملكة المتحدة موقعنا الذي قد يتم استضافته في الولايات المتحدة، سيتم تقديمه من أقرب موقع حافة مثل موقع لندن. وهذا أسرع بكثير من طلب الزائر للخادم الأصلي والذي سيزيد من وقت الاستجابة.

## الأنواع

تنقسم CDN عمومًا إلى نوعين:

### CDNs الدفع

تتلقى CDNs الدفع محتوى جديد عند حدوث تغييرات على الخادم. نحن نتحمل مسؤولية توفير المحتوى، وتحميله مباشرة إلى CDN، وإعادة كتابة عناوين URL للإشارة إلى CDN. يمكننا تكوين متى ينتهي مفعول المحتوى ومتى يتم تحديثه. يتم تحميل المحتوى فقط عندما يكون جديدًا أو تم تغييره، مما يقلل من حركة المرور ولكن يزيد من التخزين.

تعمل مواقع ذات حركة مرور قليلة أو المواقع التي لا يتم تحديث محتواها كثيرًا بشكل جيد مع CDNs الدفع. يتم وضع المحتوى على CDNs مرة واحدة، بدلاً من إعادة سحبه بفترات منتظمة.

### CDNs الاستحضار

في حالة CDNs الاستحضار، يتم تحديث الذاكرة المؤقتة استنادًا إلى الطلب. عندما يرسل العميل طلبًا يتطلب استحضار الأصول الثابتة من CDN إذا كانت لديها، فإنه سيقوم بجلب الأصول المحدثة حديثًا من الخادم الأصلي وملء ذاكرته المؤقتة بهذا الأصل الجديد، ثم يرسل هذ

ا الأصل المؤقت الجديد للمستخدم.

خلافًا لـ CDNs الدفع، يتم ذلك بأقل قدر من الصيانة لأن تحديثات الذاكرة المؤقتة على خوادم CDN تتم استنادًا إلى طلبات من العميل إلى الخادم الأصلي. يعمل مع CDNs الاستحضار المواقع ذات حركة مرور كبيرة بشكل جيد، حيث يتم توزيع الحركة بشكل أكثر توازناً مع الحفاظ على المحتوى المطلوب مؤخرًا على الـ CDN.

## العيوب

كما نعلم، الأشياء الجيدة تأتي بتكاليف إضافية، لذلك دعونا نناقش بعض العيوب لـ CDNs:

- **تكاليف إضافية**: قد يكون استخدام CDN مكلفًا، خاصة بالنسبة للخدمات التي تتمتع بحركة مرور عالية.
- **قيود**: قامت بعض المنظمات والدول بحظر نطاقات أو عناوين IP لـ CDNs الشهيرة.
- **الموقع**: إذا كان معظم جمهورنا موجود في بلد لا تحتوي فيه CDN على خوادم، فقد يتعين على البيانات على موقعنا عبور مسافة أكبر مما هو الحال بدون استخدام أي CDN.

## أمثلة

فيما يلي بعض CDNs المستخدمة على نطاق واسع:

- [Amazon CloudFront](https://aws.amazon.com/cloudfront)
- [Google Cloud CDN](https://cloud.google.com/cdn)
- [Cloudflare CDN](https://www.cloudflare.com/cdn)
- [Fastly](https://www.fastly.com/products/cdn)


# البروكسي (Proxy)

يعد البروكسي (Proxy) خادمًا وسيطًا بين العميل وخادم الأصل. يتلقى طلبات من العملاء ويحولها إلى خوادم الأصل. عادةً ما يُستخدم البروكسي لتصفية الطلبات وتسجيل الطلبات أو أحيانًا تحويل الطلبات (بإضافة/إزالة العناوين الرأسية، التشفير/فك التشفير، أو الضغط).

## الأنواع

هناك نوعان من البروكسي:

### بروكسي إلى الأمام (Forward Proxy)

البروكسي إلى الأمام، المعروف أيضًا باسم بروكسي أو خادم بروكسي أو بروكسي ويب، هو خادم يجلس أمام مجموعة من أجهزة العميل. عندما تقوم تلك الأجهزة بطلبات للمواقع والخدمات على الإنترنت، يقوم خادم البروكسي بالتقاط هذه الطلبات ثم التواصل مع خوادم الويب نيابةً عن تلك العملاء، كوسيط.

![forward-proxy](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/proxy/forward-proxy.png)

**الفوائد**

إليك بعض فوائد بروكسي إلى الأمام:

- حجب الوصول إلى محتوى معين
- السماح بالوصول إلى محتوى مقيد جغرافيًا
- توفير الاختفاء
- تجنب قيود التصفح الأخرى

على الرغم من أن البروكسيات توفر فوائد الاختفاء، إلا أنها يمكنها متابعة معلوماتنا الشخصية. إعداد وصيانة خادم بروكسي يمكن أن يكون مكلفًا ويتطلب تكوينات.

### بروكسي عكسي (Reverse Proxy)

البروكسي العكسي هو خادم يجلس أمام خادم ويب واحد أو أكثر، ويعترض طلبات العملاء. عندما يرسل العملاء طلبات لخادم الأصل لموقع ويب، تُعترض هذه الطلبات من قبل خادم البروكسي العكسي.

الفرق بين بروكسي إلى الأمام وبروكسي عكسي طفيف ولكنه مهم. طريقة بسيطة للتلخيص هي أن البروكسي إلى الأمام يجلس أمام عميل ويضمن أنه لا يتصل أي خادم أصلي أبدًا مباشرةً مع تلك العميل بالتحديد. من ناحية أخرى، يجلس البروكسي العكسي أمام خادم أصلي ويضمن أن أي عميل لا يتصل أبدًا مباشرةً مع ذلك الخادم الأصلي.

![reverse-proxy](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/proxy/reverse-proxy.png)

إدخال البروكسي العكسي يؤدي إلى زيادة التعقيد. يعتبر البروكسي العكسي الفردي نقطة فشل فردية، وتكوين عدة بروكسيات عكسية (مثل الحوجة) يزيد من التعقيد أكثر.

**الفوائد**

إليك بعض فوائد استخدام بروكسي عكسي:

- تحسين الأمان
- التخزين المؤقت
- التشفير SSL
- توازن الحمولة
- القدرة على التوسع والمرونة

## توازن الحمولة مقابل البروكسي العكسي

انتظر، أليس البروكسي العكسي مشابهًا لتوازن الحمولة؟ حسنًا، ليس كذلك، حيث يكون توازن الحمولة مفيدًا عندما يكون لدينا عدة خوادم. غالبًا ما يوجه موزعو الحمولة حركة المرور إلى مجموعة من الخوادم التي تؤدي نفس الوظيفة، بينما يمكن أن يكون البروكسي العكسي مفيدًا حتى مع خادم واحد فقط أو خادم تطبيق واحد. يمكن أن يعمل البر

وكسي العكسي أيضًا كموزع للحمولة ولكن ليس العكس. 

## أمثلة

فيما يلي بعض تقنيات البروكسي المستخدمة على نطاق واسع:

- [Nginx](https://www.nginx.com)
- [HAProxy](http://www.haproxy.org)
- [Traefik](https://doc.traefik.io/traefik)
- [Envoy](https://www.envoyproxy.io)

# التوفُّر (Availability)

التوفر هو الوقت الذي يظل فيه النظام قائمًا لأداء وظيفته المطلوبة في فترة زمنية محددة. إنها مقياس بسيط لنسبة الوقت الذي يظل فيه النظام أو الخدمة أو الجهاز قائمًا تحت الظروف العادية.

## تسميات التوفُّر بالأرقام

غالبًا ما يتم تقدير التوفُّر بنسبة الوقت الفعال (أو الوقت الخامل) كنسبة من الوقت الذي تكون فيه الخدمة متوفرة. وعادةً ما يُقاس بعدد الأرقام التسعة.

$$
التوفُّر = \frac{وقت العمل}{(وقت العمل + وقت التعطُّل)}
$$

إذا كان التوفُّر متوفر بنسبة 99.00%، يُقال إنه يمتلك "توفُّر متواجد لمدة 2 تسعة"، وإذا كان 99.9%، يُسمى "3 تسعات"، وهكذا.

| التوفُّر (بالنسبة المئوية) | وقت التعطُّل (سنويًا) | وقت التعطُّل (شهريًا) | وقت التعطُّل (أسبوعيًا) |
| ------------------------ | ------------------ | ----------------- | ------------------ |
| 90% (تسعة واحدة)       | 36.53 يوم         | 72 ساعة          | 16.8 ساعة         |
| 99% (تسعتان)           | 3.65 يوم          | 7.20 ساعة        | 1.68 ساعة         |
| 99.9% (ثلاث تسعات)     | 8.77 ساعة         | 43.8 دقيقة       | 10.1 دقائق        |
| 99.99% (أربع تسعات)    | 52.6 دقيقة        | 4.32 دقيقة       | 1.01 دقيقة        |
| 99.999% (خمس تسعات)    | 5.25 دقيقة        | 25.9 ثانية       | 6.05 ثواني        |
| 99.9999% (ست تسعات)    | 31.56 ثانية       | 2.59 ثواني       | 604.8 ميلّي ثانية |
| 99.99999% (سبع تسعات)  | 3.15 ثانية        | 263 ميلّي ثانية | 60.5 ميلّي ثانية |
| 99.999999% (ثمان تسعات) | 315.6 ميلّي ثانية | 26.3 ميلّي ثانية | 6 ميلّي ثانية     |
| 99.9999999% (تسع تسعات) | 31.6 ميلّي ثانية  | 2.6 ميلّي ثانية  | 0.6 ميلّي ثانية   |

## التوفُّر التتابعي مقابل التوفُّر الموازي

إذا كانت الخدمة تتكون من مكونات متعددة عرضة للفشل، فإن التوفُّر الكلي للخدمة يعتمد على ما إذا كانت المكونات في تتابع أو موازية.

### التتابع

يقل التوفُّر الكلي عندما تكون مكونتان في تتابع.

$$
التوفُّر \space (الكلي) = التوفُّر \space (Foo) * التوفُّر \space (Bar)
$$

على سبيل المثال، إذا كان لدى `Foo` و `Bar` كل منهما توفُّر بنسبة 99.9%، فإن توفُّرهما الإجمالي في

 التتابع سيكون 99.8%.

### الموازاة

يزداد التوفُّر الكلي عندما تكون مكونتان في الموازاة.

$$
التوفُّر \space (الكلي) = 1 - (1 - التوفُّر \space (Foo)) * (1 - التوفُّر \space (Bar))
$$

على سبيل المثال، إذا كان لدى `Foo` و `Bar` كل منهما توفُّر بنسبة 99.9%، فإن توفُّرهما الإجمالي في الموازاة سيكون 99.9999%.

## التوفُّر مقابل الاعتمادية

إذا كان النظام موثوقًا به، فهو متوفّر. ومع ذلك، إذا كان متوفّرًا، فليس بالضرورة أنه موثوقٌ به. بعبارة أخرى، يُسهم الاعتمادية العالية في التوفُّر العالي، ولكن من الممكن تحقيق التوفُّر العالي حتى مع نظام غير موثوق.

## التوفُّر العالي مقابل القدرة على التحمّل

كلا التوفُّر العالي والقدرة على التحمُّل ينطبقان على الأساليب التي توفّر مستويات عالية من الوقت الفعال. ومع ذلك، تختلف وسيلة تحقيق الهدف.

يتميّز النظام القادر على التحمّل بعدم انقطاع الخدمة، لكنه يتطلب تكلفة أعلى بشكل كبير، بينما يكون النظام ذو التوفُّر العالي لديه انقطاعات خدمة طفيفة. يتطلب التحمُّل توفُّرًا كاملاً للأجهزة، بحيث إذا فشل النظام الرئيسي، بدون فقدان في الوقت الفعال، يجب على نظام آخر أن يتولى المهمة.

# التوسعية (Scalability)

التوسعية هي مقياس لمدى استجابة النظام للتغييرات عن طريق إضافة أو إزالة الموارد لتلبية المطالب.

![scalability](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/scalability/scalability.png)

لنناقش أنواع مختلفة من التوسعية:

## التوسعية الرأسية

التوسعية الرأسية (المعروفة أيضًا بالتوسع الصعودي) توسع قدرة النظام عن طريق إضافة مزيد من الطاقة إلى الجهاز الحالي. بعبارة أخرى، يُشار بالتوسعية الرأسية إلى تحسين قدرة التطبيق عن طريق زيادة سعة الأجهزة.

### المزايا

- سهولة التنفيذ
- أسهل للإدارة
- استقرار البيانات

### العيوب

- خطر توقف طويل للنظام
- أصعب للترقية
- قد يكون نقطة فشل واحدة

## التوسعية الأفقية

التوسعية الأفقية (المعروفة أيضًا بالتوسع التوازي) توسع نطاق النظام عن طريق إضافة المزيد من الأجهزة. يعمل ذلك على تحسين أداء الخادم عن طريق إضافة مزيد من النسخ إلى مجموعة الخوادم الحالية، مما يتيح توزيع الأحمال بشكل أكثر تكافؤًا.

### المزايا

- زيادة التكرار
- تحسين التحمُّل للأخطاء
- مرونة وكفاءة
- أسهل للترقية

### العيوب

- زيادة التعقيد
- عدم اتساق البيانات
- زيادة الضغط على الخدمات النازلة


# التخزين (Storage)

التخزين هو آلية تمكّن النظام من الاحتفاظ بالبيانات، إما بشكل مؤقت أو دائم. عادةً ما يتم تجاوز هذا الموضوع في سياق تصميم النظام، ولكن من المهم أن نمتلك فهمًا أساسيًا لبعض أنواع التقنيات الشائعة للتخزين التي يمكن أن تساعدنا في ضبط مكونات التخزين. لنناقش بعض المفاهيم المهمة للتخزين:

## مجموعات RAID

مجموعات RAID (Redundant Array of Independent Disks) هي طريقة لتخزين نفس البيانات على الأقراص الصلبة أو محركات الأقراص الصلبة الثابتة (SSD) المتعددة لحماية البيانات في حالة فشل محرك الأقراص.

هناك مستويات RAID مختلفة، ولكن ليس جميعها لهدف توفير الاحتياط. دعنا نناقش بعض مستويات RAID المستخدمة بشكل شائع:

- **RAID 0**: يُعرف أيضًا بـ "التشطيب"، يتم تجزئة البيانات بالتساوي عبر جميع الأقراص في المجموعة.
- **RAID 1**: يُعرف أيضًا بـ "التماثل"، يحتوي ما لا يقل عن قرصين على نسخة دقيقة لمجموعة من البيانات. إذا فشل أحد الأقراص، فسيستمر الآخرون في العمل.
- **RAID 5**: التشطيب مع الزائدة. يتطلب استخدام ما لا يقل عن 3 أقراص، يتم تجزئة البيانات عبر عدة أقراص مثل RAID 0، لكنه يحتوي أيضًا على زائدة موزعة عبر الأقراص.
- **RAID 6**: التشطيب مع زائدة مزدوجة. يشبه RAID 6 RAID 5، لكن بيانات الزائدة يتم كتابتها على قرصين.
- **RAID 10**: يجمع بين التشطيب مع التماثل من RAID 0 و RAID 1. يوفر الأمان عن طريق تكرار جميع البيانات على الأقراص الثانوية بينما يتم استخدام التشطيب عبر كل مجموعة من الأقراص لتسريع نقل البيانات.

### المقارنة

دعنا نقارن كل مستويات RAID المختلفة:

| المميزات         | RAID 0     | RAID 1     | RAID 5     | RAID 6       | RAID 10    |
| ------------------ | --------- | --------- | --------- | ------------ | ---------- |
| الوصف             | تشطيب    | تماثل      | تشطيب مع زائدة | تشطيب مع زائدة مزدوجة | تشطيب وتماثل  |
| الأقراص الدنيا    | 2         | 2         | 3         | 4            | 4          |
| أداء القراءة     | عالي    | عالي    | عالي    | عالي      | عالي      |
| أداء الكتابة     | عالي    | متوسط    | عالي    | عالي      | متوسط    |
| التكلفة           | منخفضة | عالية   | منخفضة | منخفضة      | عالية   |
| الاحتياط          | لا يوجد | فشل أحد الأقراص | فشل أحد الأقراص | فشل قرصين | حتى فشل واحد في كل مجموعة فرعية |
| استخدام السعة    | 100٪    | 50٪     | 67٪-94٪ | 50٪-80٪     | 50٪       |

## الأجلة

الأجلة هي كمية ثابتة من التخزين على قرص أو شريط. غالبًا ما يُستخدم مصطلح "الأجلة" كمرادف للتخزين نفسه، ولكن يُمكن أن يحتوي قرص واحد على أكثر من وحدة أجلة أو يمكن لوحدة أجلة أن تمتد عبر أكثر من قرص واحد.

## التخزين السلسلي

التخزين السلسلي هو حلاً لتخزين البيانات على شكل ملفات وتقديمها ل

لمستخدمين النهائيين على هيئة هيكل أدلة هرمي. الميزة الرئيسية هي توفير حلاً يسهل استخدامه لتخزين الملفات واستردادها. لتحديد ملف في التخزين السلسلي، يتطلب الأمر المسار الكامل للملف. إنه اقتصادي ومنظم بسهولة وعادةً ما يُوجد على محركات الأقراص الثابتة، وهذا يعني أنها تظهر بنفس الشكل تمامًا للمستخدم وعلى القرص الثابت.

مثال: [Amazon EFS](https://aws.amazon.com/efs)، [Azure Files](https://azure.microsoft.com/en-in/services/storage/files)، [Google Cloud Filestore](https://cloud.google.com/filestore)، إلخ.

## التخزين القطعي

التخزين القطعي يقسم البيانات إلى قطع (مجموعات) ويخزنها كأجزاء منفصلة. يتم منح كل قطعة من البيانات مُعرفًا فريدًا، مما يتيح لنظام التخزين وضع القطع الأصغر من البيانات في الموقع الأكثر ملاءمة.

يقوم التخزين القطعي أيضًا بفصل البيانات عن بيئات المستخدم، مما يتيح لهذه البيانات أن تُنتشر عبر بيئات متعددة. ينشئ هذا مسارات متعددة للبيانات ويتيح للمستخدم استردادها بسرعة. عندما يطلب المستخدم أو التطبيق البيانات من نظام التخزين القطعي، يقوم النظام التخزيني الأساسي بإعادة تجميع قطع البيانات وتقديم البيانات للمستخدم أو التطبيق.

مثال: [Amazon EBS](https://aws.amazon.com/ebs).

## التخزين بالكائنات

التخزين بالكائنات، المعروف أيضًا باسم التخزين القائم على الكائنات، يقسم ملفات البيانات إلى أجزاء تُسمى بالكائنات. ثم يقوم بتخزين هذه الكائنات في مستودع واحد، والذي يمكن أن ينتشر عبر أنظمة متعددة متصلة بالشبكة.

مثال: [Amazon S3](https://aws.amazon.com/s3)، [Azure Blob Storage](https://azure.microsoft.com/en-in/services/storage/blobs)، [Google Cloud Storage](https://cloud.google.com/storage)، إلخ.

## NAS

NAS (Network Attached Storage) هو جهاز تخزين متصل بالشبكة يسمح بتخزين البيانات واستردادها من موقع مركزي للمستخدمين المخول لهم الوصول عبر الشبكة. يتمتع أجهزة NAS بالمرونة، مما يعني أنه عند الحاجة إلى تخزين إضافي، يمكننا إضافته إلى ما لدينا. إنه أسرع وأقل تكلفة، ويوفر جميع فوائد السحابة العامة في الموقع، مما يمنحنا التحكم الكامل.

## HDFS

نظام الملفات الموزع Hadoop (HDFS) هو نظام ملفات موزع مصمم للعمل على الأجهزة الرخيصة. HDFS متين للغاية وتم تصميمه ليُنشَّر على أجهزة منخفضة التكلفة. يوفر HDFS وصولًا عالي الإنتاجية إلى بيانات التطبيق وهو مناسب للتطبيقات التي تحتوي على مجموعات بيانات كبيرة. يتشابه HDFS إلى حد كبير مع أنظمة الملفات الموزعة الحالية.

تم تصميم HDFS لتخزين الملفات الكبيرة جدًا عبر أجهزة في مجموعة كبيرة. يتم تخزين كل ملف كمتسلسلة من الكتل، وكل كتلة في المل

ف باستثناء الكتلة الأخيرة تكون نفس الحجم. يتم تكرار كتل الملف للحصول على تحمل الأخطاء.

## قواعد البيانات وأنظمة إدارة قواعد البيانات

## ما هي قاعدة البيانات؟

قاعدة البيانات هي مجموعة من المعلومات المنظمة والمهيكلة، والتي يتم تخزينها عادة بشكل إلكتروني في نظام كمبيوتري. قاعدة البيانات غالبًا ما يتم التحكم فيها بواسطة نظام إدارة قواعد البيانات (DBMS). يُشار إلى المعلومات ونظام إدارة قواعد البيانات، جنبًا إلى جنب مع التطبيقات المرتبطة بهم، باسم نظام قاعدة البيانات، وعادةً يُختصر إلى مصطلح "قاعدة بيانات" فقط.

## ما هو نظام إدارة قواعد البيانات (DBMS)؟

تتطلب قاعدة البيانات عادة برنامجًا شاملًا للبرمجيات المعروف باسم نظام إدارة قواعد البيانات (DBMS). يعمل نظام إدارة قواعد البيانات كواجهة بين قاعدة البيانات والمستخدمين النهائيين أو البرامج، مما يتيح للمستخدمين استرداد البيانات وتحديثها وإدارتها وتحسين تنظيمها. يوفر نظام إدارة قواعد البيانات أيضًا الإشراف والتحكم في قواعد البيانات، مما يتيح العديد من العمليات الإدارية مثل مراقبة الأداء والضبط والنسخ الاحتياطي والاسترداد.

## المكونات

إليك بعض المكونات الشائعة التي توجد في قواعد البيانات المختلفة:

### مخطط (Schema)

يكمن دور المخطط في تعريف شكل هيكل البيانات، وتحديد أنواع البيانات التي يمكن وضعها في أي مكان. يمكن تنفيذ المخططات بصرامة عبر قاعدة البيانات بأكملها، أو بصورة فضفاضة على جزء من قاعدة البيانات، أو قد لا تكون موجودة على الإطلاق.

### جدول (Table)

يحتوي كل جدول على عدة أعمدة تمامًا مثل جدول في جدول بيانات الجداول. يمكن أن يحتوي الجدول على أقل من عمودين وما يصل إلى مائة عمود أو أكثر، اعتمادًا على نوع المعلومات التي يتم وضعها في الجدول.

### عمود (Column)

يحتوي العمود على مجموعة من قيم البيانات من نوع محدد، قيمة واحدة لكل صف في قاعدة البيانات. يمكن أن يحتوي العمود على قيم نصية أو أرقام أو قيم معينة أو الطوابق الزمنية وما إلى ذلك.

### صف (Row)

تُسجل البيانات في جدول في صفوف. يمكن أن يحتوي الجدول على آلاف أو ملايين الصفوف التي تحمل معلومات محددة.

## أنواع

فيما يلي أنواع مختلفة من قواعد البيانات:

- **[SQL](https://karanpratapsingh.com/courses/system-design/sql-databases)**
- **[NoSQL](https://karanpratapsingh.com/courses/system-design/nosql-databases)**
  - المستند (Document)
  - المفتاح-القيمة (Key-value)
  - الرسم البياني (Graph)
  - السلاسل الزمن

ية (Timeseries)
  - العمود الواسع (Wide column)
  - متعدد النماذج (Multi-model)

قواعد البيانات SQL وNoSQL هي مواضيع واسعة وسيتم مناقشتها بشكل منفصل في [قواعد بيانات SQL](https://karanpratapsingh.com/courses/system-design/sql-databases) و[قواعد بيانات NoSQL](https://karanpratapsingh.com/courses/system-design/nosql-databases). تعرف كيف تقارن بينهما في [قواعد بيانات SQL مقابل NoSQL](https://karanpratapsingh.com/courses/system-design/sql-vs-nosql-databases).

## التحديات

بعض التحديات الشائعة التي تواجه أثناء تشغيل قواعد البيانات بمقياس كبير:

- **استيعاب زيادات كبيرة في حجم البيانات**: انفجار البيانات القادمة من الحساسات والأجهزة المتصلة وعشرات المصادر الأخرى.
- **ضمان أمان البيانات**: انتشار اختراقات البيانات في كل مكان هذه الأيام، من المهم أكثر من أي وقت مضى ضمان أمان البيانات ولكن يمكن الوصول إليها بسهولة من قبل المستخدمين.
- **التحاق بالطلب**: تحتاج الشركات إلى الوصول إلى بياناتها في الوقت الحقيقي لدعم صنع القرار في الوقت المناسب ولاستغلال الفرص الجديدة.
- **إدارة وصيانة قاعدة البيانات والبنية التحتية**: بينما تصبح قواعد البيانات أكثر تعقيدًا وتزداد حجوم البيانات، تواجه الشركات تكاليف توظيف مواهب إضافية لإدارة قواعد البيانات الخاصة بها.
- **إزالة الحدود عن قابلية التوسع**: تحتاج الأعمال إلى النمو إذا أرادت أن تبقى على قيد الحياة، ويجب أن تكبر إدارة البيانات معها. لكن من الصعب جدًا التنبؤ بكمية الطاقة التي ستحتاجها الشركة، خاصةً مع قواعد البيانات على الأجهزة الموجودة في الموقع.
- **ضمان متطلبات إقامة البيانات أو سيادة البيانات أو التأخير**: تواجه بعض المنظمات حالات استخدام يكون فيها العمل أفضل عند التشغيل في المواقع. في تلك الحالات، يعتبر الأنظمة المهندسة التي تم تكوينها مسبقًا وتحسينها مسبقًا لتشغيل قاعدة البيانات هي الخيار الأمثل.


# قواعد بيانات SQL

قاعدة بيانات SQL (أو العلاقية) هي مجموعة من عناصر البيانات ذات العلاقات المحددة مسبقًا بينها. يتم تنظيم هذه العناصر كمجموعة من الجداول بأعمدة وصفوف. تُستخدم الجداول لاحتواء المعلومات حول الكائنات التي سيتم تمثيلها في قاعدة البيانات. تحمل كل عمود في الجدول نوعًا معينًا من البيانات ويُخزّن الحقل القيمة الفعلية للسمة. تُمثل الصفوف في الجدول مجموعة من القيم المتعلقة بكائن أو كيان واحد.

يمكن تمييز كل صف في الجدول بمعرّف فريد يُسمى مفتاح رئيسي (Primary Key)، ويمكن جعل صفوف بين جداول متعددة ذات علاقة باستخدام مفاتيح أجنبية (Foreign Keys). يمكن الوصول إلى هذه البيانات بعدة طرق مختلفة دون إعادة تنظيم جداول قاعدة البيانات نفسها. تتبع قواعد قواعد بيانات SQL عادة نموذج الاتساق [ACID](https://karanpratapsingh.com/courses/system-design/acid-and-base-consistency-models#acid).

## العروض المادية

العرض المادي هو مجموعة بيانات محسوبة مسبقًا مُشتقة من مواصفات الاستعلام وتُخزن للاستخدام لاحقًا. نظرًا لأن البيانات محسوبة مسبقًا، فإن استعلام العرض المادي أسرع من تنفيذ استعلام ضد جدول البيانات الأساسي للعرض. يمكن أن تكون هذه الفروق في الأداء ذات أهمية بالغة عند تشغيل استعلام بشكل متكرر أو عندما يكون الاستعلام معقدًا بما يكفي.

يتيح أيضًا العرض المادي تجزئة البيانات ويحسن أداء الاستعلامات المعقدة التي تعمل على مجموعات بيانات كبيرة مما يقلل من حمولات الشبكة. هناك استخدامات أخرى للعروض المادية، ولكنها تستخدم في الغالب للأداء والتكرار.

## مشكلة استعلام N+1

تحدث مشكلة الاستعلام N+1 عندما يقوم طبقة الوصول إلى البيانات بتنفيذ N تعليمة SQL إضافية لاسترداد نفس البيانات التي يمكن استردادها عند تنفيذ استعلام SQL الأساسي. كلما ازدادت قيمة N، زادت عدد التعليمات التي سيتم تنفيذها، وأكبر تأثير على الأداء.

يُرى هذا الأمر بشكل شائع في GraphQL وأدوات ORM (Object-Relational Mapping) ويمكن معالجته بتحسين استعلام SQL أو باستخدام مُحمّل البيانات (dataloader) الذي يجمع الطلبات المتتالية ويجعل طلب بيانات واحد تحت الغطاء.

## المزايا

دعنا نلقي نظرة على بعض المزايا في استخدام قواعد البيانات العلاقية:

- بسيطة ودقيقة
- سهولة الوصول
- استقرار البيانات
- مرونة

## العيوب

فيما يلي عيوب قواعد البيانات العلاقية:

- مكلفة الصيانة
- تطور المخطط الصعب
- تأثيرات الأداء (الانضمام، التجانس، وما إلى ذلك)
- صعوبة التوسع بسبب القابلية الأفقية الضعيفة

## أمثلة

فيما يلي بعض قواعد البيانات العلاقية المستخدمة بشكل شائع:

- [PostgreSQL](https://www.postgresql.org)
- [MySQL](https://www.mysql.com)
- [MariaDB](https://mariadb.org)
- [Amazon Aurora](https://aws.amazon.com/rds/aurora)


# قواعد البيانات NoSQL

NoSQL هي فئة واسعة تشمل أي قاعدة بيانات لا تستخدم SQL كلغة رئيسية للوصول إلى البيانات. تسمى هذه الأنواع من قواعد البيانات أحيانًا بقواعد البيانات غير العلاقية. على عكس قواعد البيانات العلاقية، لا يجب أن تتوافق البيانات في قاعدة بيانات NoSQL مع مخطط محدد مسبقًا. تتبع قواعد البيانات NoSQL عادة نموذج الاتساق [BASE](https://karanpratapsingh.com/courses/system-design/acid-and-base-consistency-models#base).

فيما يلي أنواع مختلفة من قواعد البيانات NoSQL:

### قاعدة الوثائق

قاعدة بيانات الوثائق (المعروفة أيضًا باسم قاعدة بيانات موجهة الوثائق أو مخزن الوثائق) هي قاعدة بيانات تخزن المعلومات في وثائق. إنها قواعد بيانات عامة الاستخدام تخدم مجموعة متنوعة من الحالات الاستخدامية لكل من التطبيقات التحليلية والمعاملاتية.

**المزايا**

- بديهية ومرنة
- سهولة التوسع الأفقي
- عدم وجود مخطط

**العيوب**

- عدم وجود مخطط
- غير علاقي

**أمثلة**

- [MongoDB](https://www.mongodb.com)
- [Amazon DocumentDB](https://aws.amazon.com/documentdb)
- [CouchDB](https://couchdb.apache.org)

### قيمة المفتاح

إحدى أبسط أنواع قواعد البيانات NoSQL، حيث تحفظ قواعد البيانات قيم البيانات كمجموعة من أزواج المفتاح والقيمة التي تتكون من عنصري بيانات لكل منهما. يُشار أحيانًا إلى هذا النوع أيضًا بمتجر المفاتيح والقيمة.

**المزايا**

- بسيطة وأداءها عالي
- قابلية توسعية عالية لحجم المرور الكبير
- إدارة الجلسة
- البحث المحسّن

**العيوب**

- CRUD الأساسي
- لا يمكن تصفية القيم
- نقص القدرة على فهرسة وفحص البيانات
- غير محسّنة للاستعلامات المعقدة

**أمثلة**

- [Redis](https://redis.io)
- [Memcached](https://memcached.org)
- [Amazon DynamoDB](https://aws.amazon.com/dynamodb)
- [Aerospike](https://aerospike.com)

### قاعدة البيانات الرسمية

قاعدة بيانات الرسمية هي قاعدة بيانات NoSQL تستخدم هياكل رسمية للاستعلامات الدلالية مع العقد والحواف والخصائص لتمثيل وتخزين البيانات بدلاً من الجداول أو الوثائق.

تربط الرسم البيانات في المتجر بمجموعة من العقد والحواف، حيث تمثل الحواف العلاقات بين العقد. تسمح العلاقات بربط البيانات في المتجر معًا مباشرة وفي كثير من الحالات يمكن استردادها بعملية واحدة.

**المزايا**

- سرعة الاستعلام
- ليونة ومرونة
- تمثيل بيانات صريح

**العيوب**

- معقدة
- لا يوجد لغة استعلام موحدة

**حالات الاستخدام**

- اكتشاف الاحتيال
- محركات التوصية
- الشبكات الاجتماعية
- رسم الشبكات

**أمثلة**

- [Neo4j](https://neo4j.com)
- [ArangoDB](https://www.arangodb.com)
- [Amazon Neptune](https://aws.amazon.com/neptune)
- [JanusGraph](https://janusgraph.org)


### قاعدة بيانات السلاسل الزمنية

قاعدة بيانات السلاسل الزمنية هي قاعدة بيانات مُحسّنة للبيانات المُختَمَرة بالوقت، أو ما يُعرف بالسلاسل الزمنية.

**المزايا**

- الإدخال والاسترجاع السريع
- تخزين البيانات بكفاءة

**حالات الاستخدام**

- بيانات الإنترنت of Things (IoT)
- تحليل المقاييس
- رصد التطبيقات
- فهم الاتجاهات المالية

**أمثلة**

- [InfluxDB](https://www.influxdata.com)
- [Apache Druid](https://druid.apache.org)

### الأعمدة الواسعة

قواعد البيانات الأعمدة الواسعة، المعروفة أيضًا باسم متاجر الأعمدة الواسعة، هي عديمة التخطيط. يتم تخزين البيانات في أُسُر الأعمدة بدلاً من الصفوف والأعمدة.

**المزايا**

- قابلة للتوسع بشكل كبير، يمكنها التعامل مع بيتابايت من البيانات
- مثالية لتطبيقات بيانات الكبير الحية

**العيوب**

- مكلفة
- زمن الكتابة المتزايد

**حالات الاستخدام**

- تحليل الأعمال
- تخزين البيانات على أساس السمات

**أمثلة**

- [BigTable](https://cloud.google.com/bigtable)
- [Apache Cassandra](https://cassandra.apache.org)
- [ScyllaDB](https://www.scylladb.com)

### قاعدة البيانات متعددة النماذج

تجمع قواعد البيانات متعددة النماذج بين نماذج قواعد البيانات المختلفة (مثل العلاقية، الرسمية، قيمة المفتاح، الوثيقة، إلخ) في واجهة موحدة واحدة. يعني ذلك أنها يمكن أن تستوعب أنواع بيانات مختلفة وفهارس واستعلامات، وتخزين البيانات في أكثر من نموذج واحد.

**المزايا**

- المرونة
- مناسبة للمشاريع المعقدة
- توحيد البيانات

**العيوب**

- معقدة
- أقل نضجًا

**أمثلة**

- [ArangoDB](https://www.arangodb.com)
- [Azure Cosmos DB](https://azure.microsoft.com/en-in/services/cosmos-db)
- [Couchbase](https://www.couchbase.com)

# قواعد بيانات SQL مقابل قواعد بيانات NoSQL

في عالم قواعد البيانات، هناك نوعان رئيسيان من الحلول، وهما قواعد بيانات SQL (العلاقية) وقواعد بيانات NoSQL (غير العلاقية). تختلف كل منهما في الطريقة التي بُني بها، ونوع المعلومات التي يخزنها، وكيفية تخزينها. تتميز قواعد البيانات العلاقية بأنها مُنظَّمة ولها مخططات محددة مسبقًا، بينما تكون قواعد بيانات NoSQL غير منظمة وموزعة ولديها مخطط ديناميكي.

## الاختلافات على المستوى العالي

فيما يلي بعض الاختلافات على المستوى العالي بين قواعد البيانات SQL وقواعد البيانات NoSQL:

### التخزين

تخزن قواعد البيانات SQL البيانات في جداول، حيث يُمثل كل صف كيانًا ويُمثل كل عمود نقطة بيانات عن ذلك الكيان.

تحتوي قواعد بيانات NoSQL على نماذج تخزين بيانات مختلفة مثل مفتاح-قيمة، الرسم، الوثيقة، وما إلى ذلك.

### المخطط

في قواعد البيانات SQL، يتوافق كل سجل مع مخطط ثابت، مما يعني أنه يجب أن يتم تحديد الأعمدة واختيارها قبل إدخال البيانات ويجب أن يحتوي كل صف على بيانات لكل عمود. يمكن تعديل المخطط لاحقًا، ولكن ذلك ينطوي على تعديل قاعدة البيانات باستخدام عمليات الترحيل.

أما في قواعد بيانات NoSQL، فالمخططات ديناميكية. يمكن إضافة الحقول على الطاير، ولا يجب أن يحتوي كل سجل (أو ما يعادله) على بيانات لكل حقل.

### الاستعلام

تستخدم قواعد بيانات SQL لغة الاستعلام المهيكلة (SQL) لتعريف وتلاعب البيانات، وهي قوية جدًا.

في قاعدة بيانات NoSQL، تتركز الاستعلامات على مجموعة من الوثائق. تختلف قواعد البيانات المختلفة في بناء جملة الاستعلام.

### التوسعية

في معظم الحالات الشائعة، تكون قواعد بيانات SQL قابلة للتوسع بشكل رأسي، مما قد يكلف الكثير من المال. يمكن توسيع قاعدة بيانات علاقية عبر خوادم متعددة، لكن هذه عملية تحدية وتستغرق الكثير من الوقت.

من ناحية أخرى، ت

كون قواعد بيانات NoSQL قابلة للتوسع بشكل أفقي، مما يعني أنه يمكننا إضافة المزيد من الخوادم بسهولة إلى بنية قاعدة بيانات NoSQL لمعالجة حركة المرور الكبيرة. يمكن لأي جهاز أو حاسوب سحابي رخيص أن يستضيف قواعد بيانات NoSQL، مما يجعلها أكثر كفاءة من حيث التكلفة من التوسع الرأسي. كما توزع العديد من تقنيات NoSQL البيانات تلقائياً عبر الخوادم.

### الموثوقية

غالبية قواعد البيانات العلاقية متوافقة مع نموذج ACID. لذا، عندما يتعلق الأمر بموثوقية البيانات وضمان أداء العمليات بأمان، تظل قواعد البيانات SQL هي الاختيار الأفضل.

يتنازل معظم حلول NoSQL عن الامتثال لمعيار ACID من أجل الأداء والتوسعية.

## الأسباب

كما هو الحال دائمًا، يجب أن نختار التقنية التي تناسب المتطلبات بشكل أفضل. لذا، دعنا نلقي نظرة على بعض الأسباب لاختيار قاعدة بيانات بناءً على SQL أو NoSQL:

**لقواعد البيانات SQL**

- البيانات المُنظَّمة بمخطط صارم
- البيانات العلاقية
- الحاجة للانضمامات المعقدة
- المعاملات
- استرجاع البيانات بالفهرس سريع جداً

**لقواعد البيانات NoSQL**

- مخطط ديناميكي أو مرن
- البيانات غير العلاقية
- عدم الحاجة للانضمامات المعقدة
- العبء الكبير جداً للبيانات
- الإنتاجية العالية جداً للمداخل والمخارج لكل ثانية (IOPS)


# استنساخ قواعد البيانات

الاستنساخ هو عملية تتضمن مشاركة المعلومات لضمان التوافق بين الموارد المكررة مثل قواعد البيانات المتعددة، بهدف تحسين الموثوقية ومقاومة الأخطاء أو سهولة الوصول.

## استنساخ رئيسي-عبد

يخدم الماستر القراءة والكتابة، ويقوم بتكرار الكتابات إلى واحد أو أكثر من العبيد، التي تخدم فقط القراءة. يمكن للعبيد أيضاً تكرار عبيد إضافيين بتنسيق شبه شجري. إذا تعطل الماستر، يمكن للنظام أن يستمر في العمل في وضع القراءة فقط حتى يتم ترقية عبد ليصبح ماستر أو توفير ماستر جديد.

![استنساخ رئيسي-عبد](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/database-replication/master-slave-replication.png)

### المزايا

- النُسخ الاحتياطي لقاعدة البيانات بتأثير ضئيل على الماستر.
- يمكن للتطبيقات قراءة من العبيد دون التأثير على الماستر.
- يمكن أخذ العبيد دون اتصال عن الخط ومزامنتها مرة أخرى مع الماستر دون أي فترة توقف.

### العيوب

- يؤدي الاستنساخ إلى إضافة مزيد من الأجهزة وتعقيد إضافي.
- توقف الماستر يعني إمكانية فقدان البيانات.
- جميع الكتابات يجب أن تتم أيضًا على الماستر في هندسة الماستر-عبد.
- كلما زاد عدد العبيد للقراءة، زاد عدد الكتابات التي يجب أن تكرر، وهو ما سيزيد من تأخير الاستنساخ.

## استنساخ ماستر-ماستر

يخدم كل من الماسترين القراءة/الكتابة ويتنسقان مع بعضهما. إذا تعطل أحد الماسترين، يمكن للنظام أن يستمر في العمل مع كل من القراءة والكتابة.

![استنساخ ماستر-ماستر](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/database-replication/master-master-replication.png)

### المزايا

- يمكن للتطبيقات قراءة من كلا الماسترين.
- يوزع حمل الكتابة على كلا عقدة ماستر.
- يوفر الفشل الذاتي البسيط والتلقائي والسريع.

### العيوب

- ليس بسيطاً مثل ماستر-عبد من حيث التكوين والنشر.
- إما أن يكون قليلًا في التوافق أو أن يزيد وقت الكتابة بسبب التزامن.
- يتعين حل المشاكل عند إضافة المزيد من عقدات الكتابة ومع زيادة وقت التأخير.

## الاستنساخ المتزامن مقابل الاستنساخ غير المتزامن

الفرق الرئيسي بين الاستنساخ المتزامن والاستنساخ غير المتزامن هو كيفية كتابة البيانات إلى النسخة المكررة. في الاستنساخ المتزامن، يتم كتابة البيانات إلى التخزين الأساسي والنسخة المكررة في نفس الوقت. وبالتالي، يجب أن تظل النسخة الأساسية والنسخة المكررة متزامنتين دائماً.

بالمقابل، يقوم الاستنساخ غير المتزامن بنسخ البيانات إلى النسخة المكررة بعد كتابة البيانات بالفعل إلى التخزين الأساسي. على الرغم من أن عملية الاستنساخ قد تحدث في الوقت الحقيقي، إلا أنه من الأكثر شيوعاً أن تحدث الاستنساخ بناءً على جدول زمني وهو أكثر فعالية من حيث التكلفة.

# الفهارس

الفهارس معروفة جيدًا عندما يتعلق الأمر بقواعد البيانات، حيث تُستخدم لتحسين سرعة عمليات استرداد البيانات من مخزن البيانات. تعمل الفهارس على تحسين القراءات السريعة على حساب زيادة تكاليف التخزين وبطء عمليات الكتابة (نظرًا لأننا يجب أن نكتب البيانات ونحدث الفهرس أيضًا). تُستخدم الفهارس لتحديد موقع البيانات بسرعة دون الحاجة إلى فحص كل صف في جدول قاعدة بيانات. يمكن إنشاء الفهارس باستخدام عمود واحد أو أكثر من جدول قاعدة بيانات، وذلك لتوفير الأساس للبحث العشوائي السريع والوصول الفعال إلى السجلات المرتبة.

![الفهارس](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/indexes/indexes.png)

الفهرس هو هيكل بيانات يمكن أن يُعتبر كجدول فهرس يُشير إلينا إلى المكان الذي توجد فيه البيانات الفعلية. لذا عندما نقوم بإنشاء فهرس على عمود في جدول، نقوم بتخزين ذلك العمود ومؤشر إلى الصف كله في الفهرس. تُستخدم الفهارس أيضًا لإنشاء آراء مختلفة لنفس البيانات. بالنسبة لمجموعات البيانات الكبيرة، هذه طريقة ممتازة لتحديد مرشحات مختلفة أو مخططات الترتيب دون اللجوء إلى إنشاء نسخ إضافية متعددة من البيانات.

إحدى الخصائص التي يمكن أن تكون بها فهارس قاعدة البيانات هي أنها يمكن أن تكون **كثيفة** أو **منقطعة**. يأتي كل من هذه الخصائص مع تجاربه الخاصة. دعنا نلقي نظرة على كيفية عمل كل نوع من الفهارس:

## الفهرس الكثيف

في الفهرس الكثيف، يتم إنشاء سجل فهرس لكل صف في الجدول. يمكن تحديد السجلات مباشرةً حيث يحتوي كل سجل في الفهرس على قيمة مفتاح البحث والمؤشر إلى السجل الفعلي.

![الفهرس الكثيف](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/indexes/dense-index.png)

تتطلب الفهارس الكثيفة صيانة أكثر من الفهارس المنقطعة عند وقت الكتابة. نظرًا لأن كل صف يجب أن يكون لديه إدخال، يجب أن تقوم قاعدة البيانات بإدارة الفهرس عند الإدخال والتحديث والحذف. يتطلب وجود إدخال لكل صف أيضًا أن تستهلك الفهارس الكثيفة المزيد من الذاكرة. تتمثل فائدة الفهرس الكثيف في أنه يمكن العثور على القيم بسرعة مع البحث الثنائي فقط. لا تفرض الفهارس الكثيفة أيضًا أية متطلبات ترتيب على البيانات.

## الفهرس المنقطع

في الفهرس المنقطع، يتم إنشاء سجلات فهرس فقط لبعض السجلات.

![الفهرس المنقطع](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/indexes/sparse-index.png)


الفهارس المنقطعة تتطلب صيانة أقل من الفهارس الكثيفة عند وقت الكتابة حيث تحتوي فقط على مجموعة من القيم. هذا العبء الأخف يعني أن الإدخالات والتحديثات والحذف سيكونون أسرع. بالنظر إلى أنها تحتوي على عدد أقل من الإدخالات أيضًا، فإن ذلك يعني أن الفهرس سيستخدم ذاكرة أقل. يكون البحث عن البيانات أبطأ نظرًا لأنه عادة ما يتبع البحث الثنائي مسحًا عبر الصفحة. تكون الفهارس المنقطعة اختيارية أيضًا عند العمل مع البيانات المرتبة.

# التطوير والتجانس

## المصطلحات

قبل أن نتقدم أكثر، دعنا نلقي نظرة على بعض المصطلحات المستخدمة بشكل شائع في التطوير والتجانس.

### المفاتيح

**المفتاح الأساسي (Primary key)**: عمود أو مجموعة من الأعمدة يمكن استخدامها لتحديد بشكل فريد كل صف في الجدول.

**المفتاح المركب (Composite key)**: مفتاح أساسي يتكون من عدة أعمدة.

**المفتاح العظمى (Super key)**: مجموعة من جميع المفاتيح التي يمكن أن تحدد بشكل فريد جميع الصفوف الموجودة في جدول.

**المفتاح المرشح (Candidate key)**: السمات التي تحدد الصفوف بشكل فريد في جدول.

**المفتاح الخارجي (Foreign key)**: إشارة إلى المفتاح الأساسي لجدول آخر.

**المفتاح البديل (Alternate key)**: المفاتيح التي ليست مفاتيح أساسية يطلق عليها المفاتيح البديلة.

**المفتاح الاستبدالي (Surrogate key)**: قيمة تُنشأ تلقائيًا من قبل النظام تحدد كل إدخال بشكل فريد في جدول عندما لا يمكن لعمود آخر أن يحمل خصائص مفتاح أساسي.

### الاعتماديات

**الاعتمادية الجزئية (Partial dependency)**: تحدث عندما يحدد المفتاح الأساسي بعض السمات الأخرى.

**الاعتمادية الوظيفية (Functional dependency)**: هو العلاقة القائمة بين سمتين، عادة بين المفتاح الأساسي وسمة غير مفتاحية ضمن جدول.

**الاعتمادية الوظيفية الناقلة (Transitive functional dependency)**: تحدث عندما تحدد بعض السمة غير المفتاحية سمة أخرى.

### التشوهات

تحدث تشوهات قاعدة البيانات عندما يكون هناك عيب في قاعدة البيانات ناتج عن تخطيط غير صحيح أو تخزين كل شيء في قاعدة بيانات مستوية. يتم التعامل مع ذلك عمومًا من خلال عملية التطوير والتجانس.

هناك ثلاثة أنواع من تشوهات قاعدة البيانات:

**تشوه الإدخال (Insertion anomaly)**: يحدث عندما لا يمكننا إدخال بعض السمات في قاعدة البيانات بدون وجود سمات أخرى.

**تشوه التحديث (Update anomaly)**: يحدث في حالة وجود استدراج البيانات والتحديث الجزئي. بعبارة أخرى، يتطلب تحديث صحيح لقاعدة البيانات إجراءات أخرى مثل الإضافة أو الحذف أو كليهما.

**تشوه الحذف (Deletion anomaly)**: يحدث ع

ندما يتطلب حذف بعض البيانات حذف بيانات أخرى.

**مثال**

لنأخذ الجدول التالي الذي لم يتم تطويره:

| المعرف  | الاسم   | الدور              | الفريق |
| --- | ------ | ----------------- | ---- |
| 1   | بيتر  | مهندس برمجيات | أ    |
| 2   | براين  | مهندس ديفوبس   | ب    |
| 3   | هايلي | مدير منتجات   | ج    |
| 4   | هايلي | مدير منتجات   | ج    |
| 5   | ستيف  | مهندس واجهة مستخدم | د    |

فلنتخيل أننا قمنا بتوظيف شخص جديد "جون" ولكنهم قد لا يتم تعيينهم إلى فريق على الفور. سيتسبب هذا في "تشوه الإدخال" حيث لا يوجد بعد سمة الفريق.

ثم، لنقل أن هايلي من الفريق ج تمت ترقيتها، لكي نعكس هذا التغيير في قاعدة البيانات، سيكون علينا تحديث 2 صفوف للحفاظ على التوافق وهذا قد يتسبب في "تشوه التحديث".

أخيرًا، نود إزالة الفريق ب ولكن للقيام بذلك يجب علينا أيضًا إزالة معلومات إضافية مثل الاسم والدور، وهذا مثال على "تشوه الحذف".

## التطوير

التطوير هو عملية تنظيم البيانات في قاعدة بيانات. يشمل ذلك إنشاء الجداول وإقامة العلاقات بين تلك الجداول وفقًا للقواعد المصممة لحماية البيانات وجعل قاعدة البيانات أكثر مرونة من خلال القضاء على التكرار والاعتماديات المتضاربة.

### لماذا نحتاج إلى التطوير؟

الهدف من التطوير هو القضاء على تكرار البيانات وضمان تجانس البيانات. تسمح قاعدة البيانات التي تم تطويرها بالتمديد لتوفير أنواع جديدة من البيانات دون تغيير الهيكل الحالي كثيرًا. نتيجة لذلك، تتأثر التطبيقات التي تتفاعل مع قاعدة البيانات بأدنى قدر.

### أشكال التطوير

التطوير هي سلسلة من الإرشادات للتأكد من أن قاعدة البيانات متطورة. دعونا نناقش بعض أشكال التطوير الأساسية:

**1NF**

لكي يكون الجدول في الصيغة الطبيعية الأولى (1NF)، يجب أن يتبع القواعد التالية:

- لا يُسمح بوجود مجموعات متكررة.
- تحديد كل مجموعة من البيانات ذات الصلة بمفتاح أساسي.
- يجب أن يكون لمجموعة البيانات ذات الصلة جدول منفصل.
- لا يُسمح بخلط أنواع البيانات في نفس العمود.

**2NF**

لكي يكون الجدول في الصيغة الطبيعية الثانية (2NF)، يجب أن يتبع القواعد التالية:

- يستوفي الصيغة الطبيعية الأولى (1NF).
- لا يجب أن يكون هناك أي اعتمادية جزئية.

**3NF**

لكي يكون الجدول في الصيغة الطبيعية الثالثة (3NF)، يجب أن يتبع القواعد التالية:

- يستوفي الصيغة الطبيعية الثانية (2NF).
- لا يُسمح بالاعتماديات الوظيفية الناقلة.

**BCNF**

الصيغة الطبيعية لبويس كود (BCNF) هي نسخة أقوى بقليل من الصيغة الطبيعية الثالثة (3NF) تُستخدم لمعالجة بعض أنواع التشوهات التي لا تتعامل معها 3NF كما تم تعريفها أصلاً. في بعض الأحيان يُعرف أيضًا باسم الصيغة الطبيعية 3.5 (3.5NF).

لكي يكون الجدول في ال

صيغة الطبيعية لبويس كود (BCNF)، يجب أن يتبع القواعد التالية:

- يستوفي الصيغة الطبيعية الثالثة (3NF).
- بالنسبة لكل اعتمادية وظيفية X → Y، يجب أن يكون X المفتاح العظمى.

_هناك المزيد من أشكال التطوير مثل 4NF و 5NF و 6NF ولكننا لن نناقشها هنا. تحقق من هذا [الفيديو المذهل](https://www.youtube.com/watch؟v=GFQaEYEc8_8) الذي يدخل في التفاصيل._

في قاعدة بيانات ذات صلة، يُصف العلاقة عادة بأنها "مطورة" إذا كانت تستوفي الصيغة الطبيعية الثالثة. يكون معظم العلاقات الحاصلة على الصيغة الطبيعية الثالثة خالية من تشوهات الإدخال والتحديث والحذف.

كما هو الحال مع العديد من القواعد والمواصفات الرسمية، فإن السيناريوهات الواقعية لا تسمح دائمًا بالامتثال المثالي. إذا قررت خرق أحد القواعد الثلاث الأولى للتطوير، تأكد من أن تطبيقك يتوقع أي مشاكل يمكن أن تحدث، مثل تكرار البيانات والاعتماديات غير المتسقة.

## التجانس

التجانس هو تقنية تحسين قاعدة البيانات تنطوي على إضافة بيانات مكررة في جدول واحد أو أكثر. يمكن أن يساعد هذا في تجنب الانضمامات المكلفة في قاعدة بيانات ذات صلة. يحاول التجانس تحسين أداء القراءة على حساب بعض أداء الكتابة. يتم كتابة نسخ مكررة من البيانات في جداول متعددة لتجنب الانضمامات المكلفة.

بمجرد أن تصبح البيانات منتشرة باستخدام تقنيات مثل التجزئة والتجزئة، يزيد إدارة الانضمامات عبر الشبكة من تعقيدات المزيد. قد يتجنب التجانس الحاجة إلى الانضمامات المعقدة.

_ملاحظة: التجانس لا يعني عكس التطوير._

### المزايا

دعونا نلقي نظرة على بعض المزايا للتجانس:

- تُسرِّع استرداد البيانات.
- يُسهِّل كتابة الاستعلامات.
- تقليل عدد الجداول.
- سهل الإدارة.

### العيوب

فيما يلي بعض العيوب للتجانس:

- يُكلِّف إدخالات وتحديثات.
- زيادة تعقيد تصميم قاعدة البيانات.
- زيادة تكرار البيانات.
- زيادة فرص عدم الاتساق في البيانات.

# ACID وBASE نماذج التجانس

لنتناول نماذج التجانس ACID وBASE.

## ACID

تتمثل كلمة ACID في Atomicity وConsistency وIsolation وDurability. تُستخدم خصائص ACID للحفاظ على سلامة البيانات أثناء معالجة المعاملات.

من أجل الحفاظ على التجانس قبل وبعد المعاملة، يتبع قواعد البيانات العلاقية خصائص ACID. دعنا نفهم هذه المصطلحات:

### Atomicity (الذرية)

جميع العمليات في المعاملة ناجحة أو يتم التراجع عن كل العمليات.

### Consistency (التجانس)

عند الانتهاء من المعاملة، تكون قاعدة البيانات صالحة هيكليًا.

### Isolation (العزلة)

المعاملات لا تتنافس مع بعضها البعض. يُقيد الوصول الصراعي للبيانات من قبل قاعدة البيانات بحيث تبدو المعاملات كأنها تعمل بتسلسل.

### Durability (الدوام)

بمجرد الانتهاء من المعاملة وتمت كتابة الكتابات والتحديثات على القرص، فإنها ستظل في النظام حتى في حالة حدوث فشل في النظام.

## BASE

مع زيادة كمية البيانات ومتطلبات التوفر العالي، تغيرت أيضًا طريقة تصميم قواعد البيانات بشكل كبير. لزيادة القدرة على التوسع وفي نفس الوقت تحقيق التوفر العالي، ننقل المنطق من قاعدة البيانات إلى خوادم منفصلة. بهذه الطريقة، تصبح قاعدة البيانات أكثر استقلالية وتركز على عملية فعلية لتخزين البيانات.

في عالم قواعد البيانات NoSQL، تكون المعاملات ACID أقل شيوعًا حيث قامت بعض قواعد البيانات بتخفيف متطلبات التجانس الفوري، والانتعاش الفوري للبيانات والدقة للحصول على فوائد أخرى، مثل التوسع والمرونة.

خصائص BASE هي أضعف بكثير من ضمانات ACID، لكن ليس هناك تطابق مباشر بنسبة واحدة لواحد بين نماذج التجانس الاثنين. دعنا نفهم هذه المصطلحات:

### Basic Availability (التوفر الأساسي)

تبدو قاعدة البيانات تعمل معظم الوقت.

### Soft-state (الحالة الناعمة)

التخزينات لا يجب أن تكون متسقة للكتابة، ولا يجب أن تكون النسخ المختلفة متسقة تمامًا في كل الأوقات.

### Eventual consistency (التجانس التدريجي)

قد لا تكون البيانات متسقة على الفور ولكن في النهاية، ستصبح متسقة. القراءات في النظام لا تزال ممكنة على الرغم من أنها قد لا تعطي الاستجابة الصحيحة بسبب عدم التسلسل.

## مزايا ACID مقابل BASE

لا يوجد إجابة صحيحة لما إذا كان تطبيقنا يحتاج إلى نموذج تجانس ACID أو BASE. تم تصميم كل من النماذج لتلبية متطلبات مختلفة. عند اختيار قاعدة بيانات، يجب أن نأخذ في الاعتبار خصائص كلتا النموذجين ومتطلبات تطبيقنا.

بفضل التجانس الضعيف لنموذج BASE، يحتاج المطورون إلى أن يكونوا أكثر ذكاء ودقة بشأن البيانات المتسقة إذا اختاروا تخزين BASE لتطبيقهم. من الضروري أن ت

كون ملمًا بسلوك قاعدة البيانات BASE التي اخترتها والعمل ضمن هذه القيود.

من ناحية أخرى، يمكن أن يكون التخطيط حول قيود BASE أحيانًا عيبًا كبيرًا مقارنة ببساطة المعاملات ACID. قاعدة بيانات ACID كاملة التجانس هي الاختيار المثالي لحالات الاستخدام التي يكون فيها موثوقية البيانات والتجانس أمرًا أساسيًا.

# نظرية CAP

تنص نظرية CAP على أن النظام الموزع يمكن أن يقدم فقط اثنين من الصفات الثلاث المطلوبة: التجانس (Consistency)، التوفر (Availability)، وتحمل التجزئة (Partition tolerance).

![نظرية-CAP](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/cap-theorem/cap-theorem.png)

لنلقي نظرة مفصلة على الصفات الثلاث للنظام الموزع المشار إليها في نظرية CAP.

### التجانس (Consistency)

التجانس يعني أن جميع العملاء يرى نفس البيانات في نفس الوقت، بغض النظر عن العقدة التي يتصلون بها. لتحقيق ذلك، يجب عند كتابة البيانات إلى عقدة واحدة، أن يتم توجيهها أو نسخها على الفور عبر جميع العقد في النظام قبل أن تعتبر الكتابة "ناجحة".

### التوفر (Availability)

التوفر يعني أن أي عميل يطلب البيانات يحصل على استجابة، حتى إذا كانت إحدى أو أكثر من العقد متوقفة.

### تحمل التجزئة (Partition tolerance)

تحمل التجزئة يعني أن النظام يستمر في العمل على الرغم من فقدان الرسائل أو فشل جزئي. يمكن للنظام الذي يتحمل التجزئة الاستمرار في العمل حتى في حالة حدوث فشل في الشبكة لا يؤدي إلى فشل الشبكة بأكملها. يتم تكريس البيانات بشكل كاف عبر تجميعات العقد والشبكات للحفاظ على استمرارية النظام عبر الانقطاعات المتقطعة.

## التجارة بين التجانس والتوفر

نحن نعيش في عالم مادي ولا يمكننا ضمان استقرار الشبكة، لذلك يجب على قواعد البيانات الموزعة اختيار تحمل التجزئة (P). هذا يعني التجارة بين التجانس (C) والتوفر (A).

### قاعدة بيانات CA

توفر قاعدة بيانات CA التجانس والتوفر عبر جميع العقد. لا يمكنها فعل ذلك إذا كان هناك تجزء بين أي عقدتين في النظام، وبالتالي لا يمكن تحقيق التحمل من الأخطاء.

**مثال**: [PostgreSQL](https://www.postgresql.org)، [MariaDB](https://mariadb.org).

### قاعدة بيانات CP

توفر قاعدة بيانات CP التجانس وتحمل التجزئة على حساب التوفر. عند حدوث تجزء بين أي عقدتين، يجب على النظام إيقاف العقدة غير المتسقة حتى يتم حل التجزء.

**مثال**: [MongoDB](https://www.mongodb.com)، [Apache HBase](https://hbase.apache.org).

### قاعدة بيانات AP



توفر قاعدة بيانات AP التوفر وتحمل التجزئة على حساب التجانس. عند حدوث تجزء، تظل جميع العقد متاحة ولكن العقد في النهاية الخاطئة قد يعود بإصدار أقدم من البيانات مقارنة بالآخرين. عند حل التجزء، غالبًا ما تقوم قواعد البيانات AP بإعادة مزامنة العقد لإصلاح جميع التناقضات في النظام.

**مثال**: [Apache Cassandra](https://cassandra.apache.org)، [CouchDB](https://couchdb.apache.org).



# نظرية PACELC

نظرية PACELC هي توسيع لنظرية CAP. تنص نظرية CAP على أنه في حالة تجزء الشبكة في نظام موزع، يجب على الشخص الاختيار بين التوفر (A) والتجانس (C).

توسع نظرية PACELC نظرية CAP عن طريق إدخال التأخير (L) كسمة إضافية للنظام الموزع. تنص النظرية على أنه على الرغم من غياب التجزء، يجب على الشخص الاختيار بين التأخير (L) والتجانس (C).

_وصفت نظرية PACELC لأول مرة من قبل [دانيال جي. أبادي](https://scholar.google.com/citations?user=zxeEF2gAAAAJ)._

![نظرية-PACELC](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/pacelc-theorem/pacelc-theorem.png)

تم تطوير نظرية PACELC لمعالجة نقطة ضعف رئيسية في نظرية CAP حيث لا تتيح أي احتمالية للأداء أو التأخير.

على سبيل المثال، وفقًا لنظرية CAP، يمكن اعتبار قاعدة بيانات متاحة إذا كانت الاستعلام يرجع استجابة بعد 30 يومًا. من الواضح أن مثل هذا التأخير سيكون غير مقبول لأي تطبيق في العالم الحقيقي.

# العمليات النقل

العملية النقل هي سلسلة من عمليات قاعدة البيانات التي يتم اعتبارها "وحدة عمل واحدة". تنجح العمليات في العملية النقل بالكامل، أو تفشل تمامًا. بهذه الطريقة، تدعم مفهوم العملية النقل سلامة البيانات عند فشل جزء من النظام. ليست كل قواعد البيانات تختار دعم العمليات النقل ACID، غالبًا لأنهم يفضلون الأولويات الأخرى التي يصعب أو لا يمكن تنفيذها معًا نظريًا.

_عادة، تدعم قواعد البيانات العلائقية العمليات النقل ACID، ولا تدعم قواعد البيانات غير العلائقية (هناك استثناءات)._

## الحالات

يمكن أن تكون العملية النقل في قاعدة البيانات في إحدى الحالات التالية:

![حالات-العملية-النقل](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/transactions/transaction-states.png)

### نشط

في هذه الحالة، يتم تنفيذ العملية النقل. هذه هي الحالة الأولية لكل عملية نقل.

### تم الاستكمال جزئيًا

عند تنفيذ العملية النهائية للعملية النقل، يكون في حالة استكمال جزئي.

### تم الاستكمال

إذا نفذت العملية النقل جميع عملياتها بنجاح، يكون في حالة استكمال. يتم تأكيد جميع تأثيراتها بشكل دائم على نظام قاعدة البيانات.

### فشل

تكون العملية النقل في حالة فشل إذا فشل أي من الفحوصات التي أجرتها نظام استرداد قاعدة البيانات. لا يمكن للعملية النقل التي فشلت الاستمرار في التقدم.

### ملغى

إذا فشل أي من الفحوصات ووصلت العملية النقل إلى حالة فشل، يقوم مدير الاسترداد بإلغاء جميع عمليات الكتابة على قا

عدة البيانات ليعيد قاعدة البيانات إلى حالتها الأصلية قبل تنفيذ العملية النقل. تُلغى العمليات النقل في هذه الحالة.

يمكن لوحدة استرداد قاعدة البيانات اختيار إحدى العمليتين بعد إلغاء العملية النقل:

- إعادة تشغيل العملية النقل.
- إنهاء العملية النقل.

### انتهى

إذا لم يكن هناك أي تراجع أو جاءت العملية النقل من الحالة المستكملة، فإن النظام متسق وجاهز لعملية نقل جديدة وتم إنهاء العملية القديمة.

# المعاملات الموزعة

المعاملة الموزعة هي مجموعة من العمليات على البيانات التي يتم تنفيذها عبر قواعد بيانات اثنين أو أكثر. عادةً ما يتم تنسيقها عبر عقدات منفصلة متصلة بشبكة، ولكن قد تشمل أيضًا قواعد بيانات متعددة على خادم واحد.

## لماذا نحتاج إلى المعاملات الموزعة؟

على عكس المعاملة ACID على قاعدة بيانات واحدة، تتضمن المعاملة الموزعة تعديل البيانات على قواعد بيانات متعددة. وبناءً عليه، يعد معالجة المعاملات الموزعة أكثر تعقيدًا، لأن قاعدة البيانات يجب أن تنسق الالتزام أو التراجع عن التغييرات في المعاملة كوحدة مكتملة ذاتية.

بعبارة أخرى، يجب أن تقوم كل العقدات بالتأكيد على الالتزام أو العودة إلى الخلف وإلغاء المعاملة بالكامل. وهذا هو السبب في أننا بحاجة إلى المعاملات الموزعة.

الآن، دعنا نلقي نظرة على بعض الحلول الشائعة للمعاملات الموزعة:

## الالتزام المرحلي ذو المرحلتين

![two-phase-commit](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/distributed-transactions/two-phase-commit.png)

بروتوكول الالتزام المرحلي ذو المرحلتين (2PC) هو خوارزمية موزعة تنسق جميع العمليات التي تشارك في المعاملة الموزعة حول ما إذا كان يجب الالتزام أو إلغاء (التراجع) المعاملة.

تحقق هذه الخوارزمية هدفها حتى في العديد من حالات فشل النظام المؤقت وبالتالي يُستخدم على نطاق واسع. ومع ذلك، فإنها ليست مقاومة لجميع تكوينات الفشل الممكنة، وفي حالات نادرة، يلزم التدخل اليدوي لتصحيح النتيجة.

هذا البروتوكول يتطلب عقدة مُنسِّقة، والتي تنسق وتراقب بالأساس المعاملة عبر عقدات مختلفة. يحاول المُنسِّق إنشاء توافق بين مجموعة من العمليات في مرحلتين، ومن هنا يأتي الاسم.

### المراحل

يتكون الالتزام المرحلي ذو المرحلتين من المراحل التالية:

**مرحلة التحضير**

تنطوي مرحلة التحضير على تجميع عقدة المنسق الرأي المتفق عليه من كل عقدات المشاركة. سيتم إلغاء المعاملة ما لم تكن كل العقدات قد ردت أنها "مستعدة".

**مرحلة الالتزام**

إذا كان جميع المشاركين يُجيبون على المُنسِّق أنهم "مستعدون"، فإن المُنسِّق يُطلب من جميع العقدات الالتزام بالمعاملة. إذا حدث فشل، فإن المعاملة ستُراجع.

### المشاكل

قد تحدث المشاكل التالية في بروتوكول الالتزام المرحلي ذو المرحلتين:

- ماذا لو حدث فشل في إ

حدى العقدات؟
- ماذا لو فشل المُنسِّق نفسه؟
- إنها بروتوكول معوق.

## الالتزام المرحلي ذو المرحلة الثلاثة

![three-phase-commit](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/distributed-transactions/three-phase-commit.png)

الالتزام المرحلي ذو المرحلة الثلاثة (3PC) هو تمديد للالتزام المرحلي ذو المرحلتين حيث يتم تجزئة مرحلة الالتزام إلى مرحلتين. يساعد هذا في حل مشكلة الحجب التي تحدث في بروتوكول الالتزام المرحلي ذو المرحلتين.

### المراحل

يتكون الالتزام المرحلي ذو المرحلة الثلاثة من المراحل التالية:

**مرحلة التحضير**

هذه المرحلة هي نفسها كمرحلة الالتزام المرحلي ذو المرحلتين.

**مرحلة الالتزام الجزئي**

يُصدر المنسِّق رسالة الالتزام الجزئي ويجب على جميع العقدات المشاركة التأكيد عليها. إذا فشلت العقدة في استلام هذه الرسالة في الوقت المناسب، فإن المعاملة ستُراجع.

**مرحلة الالتزام**

تكون هذه الخطوة مشابهة أيضًا لبروتوكول الالتزام المرحلي ذو المرحلتين.

### لماذا تُفيد مرحلة الالتزام الجزئي؟

تحقق مرحلة الالتزام الجزئي من النقاط التالية:

- إذا تم العثور على عقدات المشاركة في هذه المرحلة، فهذا يعني أن كل المشاركين قد أكملوا المرحلة الأولى. تكون إكمال مرحلة التحضير مضمونًا.
- يمكن لكل مرحلة الانتهاء الزمني وتجنب الانتظار غير المحدود.

## السيجا

![sagas](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/distributed-transactions/sagas.png)

السيجا هو تسلسل من المعاملات المحلية. يُحدث كل معاملة محلية قاعدة البيانات وينشر رسالة أو حدثًا لتشغيل المعاملة المحلية التالية في السيجا. إذا فشلت المعاملة المحلية لأنها تخالف قاعدة أعمال معينة، فإن السيجا تنفذ سلسلة من المعاملات التعويضية التي تُلغي التغييرات التي تم إجراؤها بواسطة المعاملات المحلية السابقة.

### التنسيق

هناك نهجان شائعان للتنفيذ:

- **الكوروغرافيا**: تنشر كل معاملة محلية أحداث المجال التي تشغل المعاملات المحلية في خدمات أخرى.
- **الأوركسترا**: يخبر الساقن المشاركين بالمعاملات المحلية التي يجب تنفيذها.

### المشاكل

- النمط السيجا صعب جدا للتصحيح.
- هناك خطر من التبعية الدورية بين مشاركي السيجا.
- يفرض عدم وجود عزل بيانات المشارك يتسبب في تحديات متانة.
- الاختبار صعب لأنه يجب أن تكون كل الخدمات تعمل لمحاكاة المعاملة.

# التجزئة (Sharding)

قبل أن نتحدث عن التجزئة (Sharding)، دعنا نتحدث عن تجزئة البيانات:

## تجزئة البيانات

تجزئة البيانات هي تقنية لتقسيم قاعدة بيانات إلى أجزاء أصغر. إنه عملية تقسيم قاعدة بيانات أو جدول عبر عدة أجهزة لتحسين قابلية الإدارة والأداء وتوفر القاعدة البياناتية.

### الأساليب

هناك العديد من الطرق المختلفة التي يمكن استخدامها لتقرير كيفية تجزئة قاعدة بيانات التطبيق إلى قواعد بيانات أصغر متعددة. فيما يلي اثنتان من أكثر الطرق شيوعًا التي تستخدمها التطبيقات ذات الحجم الكبير:

**التجزئة الأفقية (أو التجزئة)**

في هذا الاستراتيجية، نقوم بتجزئة بيانات الجدول أفقيًا استنادًا إلى نطاق القيم المحددة بواسطة _مفتاح التجزئة_. يُشار أيضًا إلى هذا بـ **_تجزئة قاعدة البيانات_**.

**التجزئة العمودية**

في التجزئة العمودية، نقوم بتجزئة البيانات عموديًا استنادًا إلى الأعمدة. نقوم بتقسيم الجداول إلى جداول صغيرة نسبيًا تحتوي على عناصر قليلة، وتكون كل جزء موجودًا في قسم منفصل.

في هذا البرنامج التعليمي، سنركز بشكل خاص على التجزئة.

## ما هي التجزئة؟

التجزئة هو نمط له علاقة بـ _التجزئة الأفقية_، وهو الممارسة الخاصة بفصل صفوف جدول واحد إلى جداول متعددة مختلفة، تُعرف باسم الأقسام أو التجزئات. كل تجزئة لديها نفس البنية والأعمدة، ولكنها تحتوي أيضًا على مجموعة فرعية من البيانات المشتركة. وبالمثل، البيانات الموجودة في كل تجزئة فريدة ومستقلة عن البيانات الموجودة في التجزئات الأخرى.

![sharding](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/sharding/sharding.png)

التبرير للتجزئة هو أنه بعد نقطة معينة، فإنه أرخص وأكثر جدوى لتوسيع القاعدة بأكملها عن طريق إضافة المزيد من الأجهزة بدلاً من التوسع عموديًا عن طريق إضافة خوادم قوية. يمكن تنفيذ التجزئة على مستوى التطبيق أو مستوى قاعدة البيانات.

## معايير التجزئة

هناك عدد كبير من المعايير المتاحة لتجزئة البيانات. بعض المعايير الأكثر شيوعًا المستخدمة هي:

### استنادًا إلى القيمة المجموعة

تقوم هذه الاستراتيجية بتقسيم الصفوف إلى أجزاء مختلفة بناءً على خوارزمية التجزئة بدلاً من تجميع صفوف قاعدة البيانات بناءً على الفهارس المتواصلة.

يعتبر عيب هذه الطريقة أنه يصبح من الصعب تكلفة إضافة / إزالة خوادم قاعدة البيانات ديناميكيًا.

### استنادًا إلى القائمة

في التجزئة القائمة، ي

تم تعريف كل جزء واختياره بناءً على القائمة من القيم في عمود بدلاً من مجموعة من النطاقات المتواصلة للقيم.

### استنادًا إلى النطاق

يقوم تجزئة النطاق بتعيين البيانات إلى عدة أجزاء استنادًا إلى نطاقات من قيم المفتاح التجزئة. بعبارة أخرى، نقوم بتجزئة الجدول بحيث يحتوي كل جزء على صفوف ضمن نطاق معين محدد بمفتاح التجزئة.

يجب أن تكون النطاقات متتالية ولكن غير تداخلية، حيث يحدد كل نطاق الحد الأدنى والحد الأعلى غير المتضمن لجزء. يتم إضافة قيم مفتاح التجزئة المساوية أو أعلى من الحد الأعلى للنطاق إلى الجزء التالي.

### التجزئة المركبة

كما يوحي الاسم، تقوم التجزئة المركبة بتجزئة البيانات بناءً على اثنين أو أكثر من تقنيات التجزئة. هنا نقوم بتجزئة البيانات باستخدام تقنية واحدة أولاً، ثم يتم تجزئة كل جزء إلى أجزاء فرعية باستخدام نفس الطريقة أو طريقة أخرى.

## المزايا

لكن لماذا نحتاج إلى التجزئة؟ هنا بعض المزايا:

- **التوافر**: يوفر استقلالية منطقية لقاعدة البيانات المجزأة، مما يضمن توافرًا عاليًا لتطبيقنا. يمكن إدارة الأقسام الفردية بشكل مستقل.
- **قابلية التوسع**: يثبت أنه يزيد من التوسعية عن طريق توزيع البيانات عبر عدة أقسام.
- **الأمان**: يساعد على تحسين أمان النظام من خلال تخزين البيانات الحساسة وغير الحساسة في أقسام مختلفة. يمكن أن يوفر ذلك إدارة وأمانًا أفضل للبيانات الحساسة.
- **أداء الاستعلام**: يحسن أداء النظام. بدلاً من استعلام قاعدة البيانات بأكملها، يجب الآن على النظام الاستعلام عن قسم أصغر فقط.
- **إدارة البيانات**: يقسم الجداول والفهارس إلى وحدات أصغر وأكثر قابلية للإدارة.

## العيوب

- **التعقيد**: يزيد التجزئة من تعقيد النظام بشكل عام.
- **الانضمام عبر التجزئة**: بمجرد أن يتم تجزئة قاعدة بيانات ونشرها عبر العديد من الأجهزة، فإن الانضمامات التي تتعدى التجزئة الأساسية للقاعدة بيانات غالبًا ما لا تكون فعالة من حيث الأداء لأنه يجب استرداد البيانات من العديد من الخوادم.
- **إعادة التوازن**: إذا كان توزيع البيانات غير متجانس أو يوجد الكثير من الحمل على جزء واحد، في مثل هذه الحالات، يجب علينا إعادة توازن أقسامنا بحيث يتم توزيع الط

لبات بالتساوي على قدر الإمكان بين الأقسام.

## متى يجب استخدام التجزئة؟

فيما يلي بعض الأسباب التي قد تجعل التجزئة الاختيار الصحيح:

- استغلال الأجهزة الحالية بدلاً من الأجهزة ذات الأداء العالي.
- الحفاظ على البيانات في مناطق جغرافية مختلفة.
- النمو بسرعة من خلال إضافة مزيد من الأقسام.
- أفضل أداء حيث يكون كل جهاز تحت أقل قدر من الحمل.
- عندما يكون هناك حاجة للمزيد من الاتصالات المتزامنة.


# الهاش المتسق (Consistent Hashing)

دعنا نفهم أولاً المشكلة التي نحاول حلها.

## لماذا نحتاج إلى ذلك؟

في أساليب توزيع البيانات القائمة على الهاش التقليدية، نستخدم دالة الهاش لعمل هاش لمفاتيح التجزئة (مثل معرّف الطلب أو عنوان IP). ثم إذا استخدمنا العملية الباقي عند قسمة عدد المعالجات النهائي (الخادم أو قواعد البيانات). سيكون هذا لنا العقدة التي نريد توجيه طلبنا إليها.

![الهاش البسيط](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/consistent-hashing/simple-hashing.png)

$$
\begin{align*}
& هاش(المفتاح_1) \to موقع_1 \bmod N = العقدة_0 \\
& هاش(المفتاح_2) \to موقع_2 \bmod N = العقدة_1 \\
& هاش(المفتاح_3) \to موقع_3 \bmod N = العقدة_2 \\
& ... \\
& هاش(المفتاح_n) \to موقع_n \bmod N = العقدة_{n-1}
\end{align*}
$$

حيث:

`المفتاح`: معرّف الطلب أو عنوان IP.

`الهاش`: نتيجة دالة الهاش.

`N`: إجمالي عدد العقد.

`العقدة`: العقدة التي سيتم توجيه الطلب إليها.

المشكلة مع هذا النهج هو إذا أضفنا أو أزلنا عقدة، فسوف يتسبب ذلك في تغيير `N`، مما يعني أن استراتيجية التعيين لدينا ستتعطل حيث ستكون نفس الطلبات الآن تتم تعيينها إلى خادم مختلف. وبناءً على ذلك، سيتعين علينا إعادة توزيع الغالبية من الطلبات مما يكون غير كفوء جدًا.

نريد توزيع الطلبات بشكل متساوٍ على العقد المختلفة بحيث يمكننا إضافة أو إزالة العقد بأدنى مجهود. لذلك، نحتاج إلى نظام توزيع لا يعتمد مباشرة على عدد العقد (أو الخوادم) بحيث عند إضافة أو إزالة العقد، يتم تقليل عدد المفاتيح التي يجب إعادة توزيعها إلى أدنى حد.

يحل الهاش المتسق هذه المشكلة القابلية للتوسع الأفقي من خلال ضمان أنه في كل مرة نقوم فيها بالتوسع أو التضاءل، لا يتعين علينا إعادة ترتيب جميع المفاتيح أو لمس جميع الخوادم.

الآن بعد أن فهمنا المشكلة، دعونا نناقش الهاش المتسق بالتفصيل.

## كيف يعمل؟

الهاش المتسق هو نظام هاش موزع يعمل بشكل مستقل عن عدد العقد في جدول الهاش الموزع عن طريق تعيينهم موضعًا على دائرة مجردة أو حلقة هاش. يتيح ذلك توسيع الخوادم والكائنات دون التأثير على النظام الكلي.

![الهاش المتسق](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/consistent-hashing/consistent-hashing.png)

باستخدام الهاش المتسق، سيتطلب إعادة التوزيع فقط `K/N` من البيانات.

$$
R = K/N
$$

حيث:

`R`: البيانات التي ستتطلب إعادة توزيعها.

`K`: عدد مفاتيح التجزئة.

`N`: عدد العقد.

مخرج دالة الهاش هو نطاق يسمى `0...m-1` والذي يمكننا تمثيله على حلقة الهاش. نحن نقوم بعمل هاش للطلبات وتوزيعها على الحلقة اعتمادًا على ناتج الهاش. ب

المثل، نقوم أيضًا بعمل هاش للعقد وتوزيعها على نفس الحلقة أيضًا.

$$
\begin{align*}
& هاش(المفتاح_1) = الموضع_1 \\
& هاش(المفتاح_2) = الموضع_2 \\
& هاش(المفتاح_3) = الموضع_3 \\
& ... \\
& هاش(المفتاح_n) = الموضع_{m-1}
\end{align*}
$$

حيث:

`المفتاح`: معرف الطلب/العقدة أو عنوان IP.

`الموضع`: الموضع على حلقة الهاش.

`m`: إجمالي نطاق حلقة الهاش.

الآن، عندما يأتي الطلب نستطيع ببساطة توجيهه إلى أقرب عقدة باتجاه عقارب الساعة (يمكن أن تكون عكس عقارب الساعة أيضًا). وهذا يعني أنه عند إضافة عقدة جديدة أو إزالتها، يمكننا استخدام العقدة الأقرب ويتعين إعادة توجيه كسرعة جزء من الطلبات فقط.

من الناحية النظرية، يجب أن يوزع الهاش المتسق الحمل بشكل متساوٍ ولكنه لا يحدث في الواقع. عادةً ما يكون توزيع الحمل غير متساوٍ وقد تنتهي الخادمة بالتعامل مع الغالبية من الطلبات لتصبح مركزًا للنظام. يمكننا حل هذه المشكلة عن طريق إضافة عقدة إضافية ولكن ذلك قد يكون مكلفًا.

دعونا نرى كيف يمكننا التعامل مع هذه المشكلات.

## العقدات الافتراضية

من أجل ضمان توزيع الحمل بشكل أكثر تساوٍ، يمكننا إدخال فكرة العقدة الافتراضية، المعروفة أيضًا بـ VNode.

بدلاً من تعيين موضع واحد لعقدة واحدة، يتم تقسيم نطاق الهاش إلى مجموعات أصغر ويتم تعيين كل عقدة فعلية عدة من هذه المجموعات الأصغر. يُعتبر كل هذه النطاقات الفرعية عقدة افتراضية. بالتالي، العقدات الافتراضية هي عمليا عقدات فعلية موضوعة مرات متعددة عبر حلقة الهاش لتقليل التغييرات على نطاق المعين للعقدة.

![العقدات الافتراضية](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/consistent-hashing/virtual-nodes.png)

لهذا، يمكننا استخدام عدد `k` من دوال الهاش.

$$
\begin{align*}
& هاش_1(المفتاح_1) = الموضع_1 \\
& هاش_2(المفتاح_2) = الموضع_2 \\
& هاش_3(المفتاح_3) = الموضع_3 \\
& . . . \\
& هاش_k(المفتاح_n) = الموضع_{m-1}
\end{align*}
$$

حيث:

`المفتاح`: معرف الطلب/العقدة أو عنوان IP.

`k`: عدد دوال الهاش.

`الموضع`: الموضع على حلقة الهاش.

`m`: إجمالي نطاق حلقة الهاش.

مع المساعدة من العقدات الافتراضية، يمكننا توزيع الحمل بشكل أكثر تساوٍ عبر العقدات الفعلية في المجموعة عن طريق تقسيم نطاقات الهاش إلى مجموعات فرعية أصغر. يتسرع عملية إعادة التوازن بعد إضافة أو إزالة العقدة. وهذا أيضًا يساعدنا على تقليل احتمالية نقاط الانفجار.

## التكرار البيانات

لضمان توفير الاتاحة العالية والمتانة، يقوم الهاش المتسق بتكرار كل عنصر بيانات على عدة عقد (N) في النظ

ام حيث قيمة `N` مكافئة لـ_عامل التكرار_.

عامل التكرار هو عدد العقدات التي ستتلقى نسخة من نفس البيانات. في أنظمة الاعتدال النهائي، يتم ذلك بطريقة غير متزامنة.

## المزايا

لنلقي نظرة على بعض المزايا للهاش المتسق:

- يجعل التوسع السريع لأعلى ولأسفل أكثر تنبؤا.
- ييسّر التجزئة والتكرار عبر العقدات.
- يمكن القابلية للتوسع والاتاحة.
- يقلل من نقاط الانفجار.

## العيوب

فيما يلي بعض العيوب للهاش المتسق:

- يزيد من التعقيد.
- الفشل التتابعي.
- موزع الحمل ممكن أن يظل غير متساوٍ.
- يمكن أن يكون إدارة المفاتيح مكلفة عندما يفشل العقد مؤقتًا.

## الأمثلة

لنلقي نظرة على بعض الأمثلة حيث يُستخدم الهاش المتسق:

- تجزئة البيانات في [Apache Cassandra](https://cassandra.apache.org).
- توزيع الحمل عبر مضيفي تخزين متعددين في [Amazon DynamoDB](https://aws.amazon.com/dynamodb).

# التجزئة القاعدة

التجزئة (أو التجزئة الوظيفية) تقسم قواعد البيانات حسب الوظيفة. تعمل هندسة التجزئة على جعل العديد من قواعد البيانات الفعلية المتميزة تظهر كقاعدة بيانات منطقية واحدة للمستخدمين النهائيين.

يتم ربط جميع المكونات في التجزئة بمخططات فيدرالية واحدة أو أكثر تعبر عن التشابه في البيانات في جميع أنحاء التجزئة. تُستخدم هذه المخططات الفدرالية لتحديد المعلومات التي يمكن مشاركتها بواسطة مكونات التجزئة وتوفير أساس مشترك للتواصل بينهم.

![تجزئة القاعدة](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/database-federation/database-federation.png)

توفر التجزئة أيضًا رؤية متماسكة وموحدة للبيانات المستمدة من مصادر متعددة. يمكن أن تتضمن مصادر البيانات للأنظمة المتجزئة قواعد البيانات وأشكالًا مختلفة من البيانات المهيكلة وغير المهيكلة.

## السمات

لنلقِ نظرة على بعض السمات الرئيسية لقاعدة بيانات متجزئة:

- **الشفافية**: تخفي قاعدة البيانات المتجزئة اختلافات المستخدم وتنفيذات مصادر البيانات الأساسية. لذلك لا يحتاج المستخدمون إلى أن يكونوا على دراية بمكان تخزين البيانات.
- **التباين**: قد تختلف مصادر البيانات في العديد من الطرق. يمكن لنظام قاعدة البيانات المتجزئة التعامل مع أجهزة مختلفة وبروتوكولات الشبكة ونماذج البيانات وغيرها.
- **القابلية للتوسعة**: قد يكون هناك حاجة لمصادر جديدة لتلبية احتياجات الأعمال المتغيرة. يجب أن يجعل نظام قاعدة بيانات متجزئة جيد تكوين مصادر جديدة بسهولة.
- **الاستقلالية**: قاعدة بيانات متجزئة لا تغير مصادر البيانات الحالية، وواجهاتها يجب أن تظل كما هي.
- **تكامل البيانات**: يمكن لقاعدة بيانات متجزئة أن تدمج البيانات من بروتوكولات مختلفة وأنظمة إدارة قواعد البيانات وغيرها.

## المزايا

إليك بعض المزايا لقواعد البيانات المتجزئة:

- مشاركة البيانات المرن

ة.
- الاستقلالية بين مكونات قاعدة البيانات.
- الوصول إلى البيانات المتباينة بطريقة موحدة.
- عدم الارتباط القوي بين التطبيقات وقواعد البيانات القديمة.

## العيوب

وفيما يلي بعض العيوب لقواعد البيانات المتجزئة:

- يزيد من تعقيد الأجهزة والتعقيد الإضافي.
- تعقيد دمج البيانات من قاعدتي بيانات.
- الاعتماد على مصادر بيانات مستقلة.
- أداء الاستعلام وقابلية التوسعة.

# بنية الطبقات N-Tier

تقسم بنية الطبقات N-Tier التطبيق إلى طبقات منطقية وأطباق مادية. الطبقات هي طريقة لفصل المسؤوليات وإدارة التبعيات. تحمل كل طبقة مسؤولية محددة. يمكن للطبقة العلوية استخدام الخدمات في الطبقة الأدنى، لكن ليس العكس.

![بنية الطبقات N-Tier](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/n-tier-architecture/n-tier-architecture.png)

تفصل الأطباق بشكل مادي وتعمل على أجهزة منفصلة. يمكن للطبقة أن تستدعي طبقة أخرى مباشرة، أو تستخدم الرسائل اللاحقة. على الرغم من أنه يمكن أن يتم استضافة كل طبقة في طبقة منفصلة، إلا أن ذلك ليس مطلوبًا. قد تتم استضافة عدة طبقات على نفس الطبقة. يحسن فصل الأطباق ماديًا القابلية للتوسع والصلابة ويضيف تأخيرًا من التواصل الشبكي الإضافي.

يمكن أن تكون بنية الطبقات N-Tier من نوعين:

- في بنية الطبقات المغلقة، يمكن للطبقة استدعاء الطبقة التالية مباشرة أدناها فقط.
- في بنية الطبقات المفتوحة، يمكن للطبقة استدعاء أي من الطبقات أدناها.

تحد من بنية الطبقات المغلقة التبعيات بين الطبقات. ومع ذلك، قد يؤدي ذلك إلى إنشاء حركة مرور عبر الشبكة غير ضرورية، إذا قامت طبقة واحدة بنقل الطلبات إلى الطبقة التالية فقط.

## أنواع بنية الطبقات N-Tier

لنلقِ نظرة على بعض أمثلة بنية الطبقات N-Tier:

### بنية الطبقات 3-Tier

تُستخدم بنية 3-Tier على نطاق واسع وتتكون من الطبقات التالية المختلفة:

- **طبقة العرض**: تتعامل مع تفاعلات المستخدم مع التطبيق.
- **طبقة المنطق التجاري**: تقبل البيانات من طبقة التطبيق، وتتحقق من صحتها وفقًا لمنطق الأعمال وتمررها إلى طبقة الوصول إلى البيانات.
- **طبقة الوصول إلى البيانات**: تستقبل البيانات من طبقة المنطق التجاري وتنفذ العمليات اللازمة على قاعدة البيانات.

### بنية الطبقات 2-Tier

في هذه البنية، تعمل طبقة العرض على العميل وتتواصل مع مخزن البيانات. لا توجد طبقة منطق التجارة أو طبقة فورية بين العميل والخادم.

### بنية طبقة واحدة أو 1-Tier

هو النوع الأبسط حيث يكون مكافئًا لتشغيل التطبيق على جهاز كمبيوتر شخصي. يتواجد جميع المكونات اللازمة لتشغيل التطبيق على تطبيق واحد أو خادم واحد.

## المزايا

إليك بعض المزايا لاستخدام بنية الطبقات N-Tier:

- يمكن تحسين التوافر.
- أفضل أمان حيث يمكن للطبقات أن تتصرف كحاجز نار.
- تتيح لنا الطبقات المنفصلة توسيعها حسب الحاجة.
- يحسن الصيانة حيث يم

كن لأشخاص مختلفين إدارة طبقات مختلفة.

## العيوب

وفيما يلي بعض العيوب لبنية الطبقات N-Tier:

- تزيد من تعقيد النظام ككل.
- تزيد من تأخير الشبكة مع زيادة عدد الطبقات.
- مكلفة حيث سيكون لكل طبقة تكلفة أجهزتها الخاصة.
- من الصعب إدارة أمان الشبكة.

# وسطاء الرسائل

وسيط الرسائل هو برنامج يمكن التطبيقات والأنظمة والخدمات من التواصل مع بعضها البعض وتبادل المعلومات. يقوم وسيط الرسائل بذلك من خلال ترجمة الرسائل بين بروتوكولات الرسائل الرسمية. وهذا يتيح للخدمات المتعاونة التحدث مع بعضها البعض مباشرة، حتى إذا كانت مكتوبة بلغات مختلفة أو مُنفَّذَة على منصات مختلفة.

![وسيط الرسائل](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/message-brokers/message-broker.png)

يمكن لوسطاء الرسائل التحقق من صحة الرسائل وتخزينها وتوجيهها وتسليمها إلى الوجهات المناسبة. يعملون كوسطاء بين التطبيقات الأخرى، مما يسمح للمرسلين بإصدار الرسائل دون معرفة مكان المستقبلين، سواء كانوا نشطين أم لا أو عددهم. ويُسهِّل ذلك الفصل بين العمليات والخدمات ضمن الأنظمة.

## النماذج

تقدم وسطاء الرسائل نمطين أساسيين لتوزيع الرسائل أو أنماط الرسائل:

- **[توزيع النقاط إلى النقاط](https://karanpratapsingh.com/courses/system-design/message-queues)**: هذا هو نمط التوزيع المستخدم في طوابير الرسائل مع علاقة واحد-إلى-واحد بين مرسل الرسالة والمستقبل.
- **[توزيع النشر-الاشتراك](https://karanpratapsingh.com/courses/system-design/publish-subscribe)**: في هذا النمط التوزيعي للرسائل، المعروف أيضًا بـ "النشر/الاشتراك"، يقوم منتج كل رسالة بنشرها إلى موضوع، ويشترك عدة مستهلكين للرسائل في المواضيع التي يرغبون في استقبال الرسائل منها.

_سنناقش هذه الأنماط التوزيعية للرسائل بالتفصيل في الدروس التالية._

## وسطاء الرسائل مقابل منصات تدفق الأحداث

يمكن لوسطاء الرسائل دعم نمطين أو أكثر لتوزيع الرسائل، بما في ذلك طوابير الرسائل والنشر/الاشتراك، بينما تقدم منصات تدفق الأحداث نماذج توزيع نشر/الاشتراك فقط. صُممت منصات تدفق الأحداث للاستخدام مع حجم كبير من الرسائل، وهي قابلة للتوسعة بسهولة. يمكنها ترتيب تدفقات السجلات إلى فئات تُسمى "المواضيع" وتخزينها لفترة زمنية محددة. على عكس وسطاء الرسائل، إلا أن منصات تدفق الأحداث لا يمكنها ضمان تسليم الرسائل أو تتبع المستهلكين الذين تلقوا الرسائل.

تقدم منصات تدفق الأحداث مزيدًا من القابلية للتوسعة من وسطاء الرسائل ولكنها تحتوي على مزيد من الميزات التي تضمن القدرة على التحمل من الأخطاء مثل إعادة إرسال الرسائل، بالإضافة إلى إمكانيات توجيه الرسائل وتكوين الطوابير المحدودة.

## وسطاء الرسائل مقابل حافلة خدمات الأعمال (ESB)

[بنية حافلة خدمات الأعمال (ESB)](https://karanpratapsingh.com/courses/system-design/enterprise-service-bus) معقدة ويمكن أن تكون صعبة التكامل ومكلفة التطوير. يُعَدُّ عملية تحديد المشكلات عند حدوث مشاكل في بيئات الإنتاج صعبة، وليس سهلا

ً القيام بالتوسع والتحديث.

بينما تعتبر وسطاء الرسائل بديلًا "خفيف الوزن" لبنية ESB توفر وظائف مماثلة، وهي آلية للاتصال بين الخدمات، وبتكلفة أقل. إنها مناسبة تمامًا للاستخدام في [هندسة بنية الميكروسيرفس](https://karanpratapsingh.com/courses/system-design/monoliths-microservices#microservices) التي أصبحت أكثر انتشارًا مع تراجع شعبية بنية ESB.

## أمثلة

فيما يلي بعض وسطاء الرسائل الشائعة المستخدمة:

- [NATS](https://nats.io)
- [Apache Kafka](https://kafka.apache.org)
- [RabbitMQ](https://www.rabbitmq.com)
- [ActiveMQ](https://activemq.apache.org)

# طوابير الرسائل

طوابير الرسائل هي شكل من أشكال التواصل بين الخدمات يُمكّن التواصل الغير متزامن. تستقبل بشكل غير متزامن الرسائل من المُرسلين وتُرسلها للمستهلكين.

تُستخدم الطوابير لإدارة الطلبات بشكل فعال في أنظمة التوزيع الضخمة. في الأنظمة الصغيرة التي تحمل أحمال معالجة وقواعد بيانات صغيرة، يمكن أن تكون الكتابات سريعة بشكل متوقع. ومع ذلك، في الأنظمة المعقدة والكبيرة يمكن أن تستغرق الكتابات فترة زمنية غير محددة تقريبًا.

![طوابير الرسائل](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/message-queues/message-queue.png)

## كيفية العمل

تُخزن الرسائل في الطابور حتى تُعالَج وتُحذَف. يتم معالجة كل رسالة مرة واحدة فقط بواسطة مستهلك واحد. فيما يلي كيفية عملها:

- ينشر المُرسل وظيفة إلى الطابور، ثم يُعلم المُستخدم بحالة الوظيفة.
- يقوم المُستهلك بالحصول على الوظيفة من الطابور، ومعالجتها، ثم يُعلِن أن الوظيفة مُكتَمَلة.

## المزايا

دعونا نناقش بعض المزايا في استخدام طوابير الرسائل:

- **قابلية التوسع**: تُمكِّن طوابير الرسائل التوسع بالضبط حيث نحتاج إليه. عندما تتزايد أعباء العمل، يمكن للعديد من نسخ التطبيق الخاص بنا أن تضيف كل الطلبات إلى الطابور دون خطر التصادُم.
- **فصل الأجزاء**: تُزيل طوابير الرسائل التبعية بين الأجزاء وتُبسِّط بشكل كبير تنفيذ التطبيقات المفصولة.
- **الأداء**: تُمكِّن طوابير الرسائل التواصل غير المتزامن، مما يعني أن النقاط النهائية التي تنتج وتستهلك الرسائل تتفاعل مع الطابور وليس مع بعضها البعض. يمكن للمنتجين إضافة الطلبات إلى الطابور دون الانتظار لاستكمالها.
- **الموثوقية**: تجعل الطوابير بياناتنا دائمة وتُقَلِّل من الأخطاء التي تحدث عندما تنقطع أجزاء مختلفة من نظامنا عن العمل.

## الميزات

لنناقش الآن بعض الميزات المطلوبة في طوابير الرسائل:

### تسليم بواسطة الدفع أو الجلب

توفر معظم طوابير الرسائل الخيارين لاسترداد الرسائل، وال

دفع والجلب. الجلب يعني الاستعلام المتواصل عن الطابور للحصول على رسائل جديدة. الدفع يعني أن المُستهلك يُعلِم عندما تكون هناك رسالة مُتاحة. يمكن أن نستخدم أيضًا الجلب للسماح للمستلمين بالانتظار لوقت محدد لوصول رسائل جديدة.

### طوابير التسلسل الأول في الدخول أولاً (FIFO)

في هذه الطوابير، يتم معالجة أقدم (أو أول) إدخال، يُطلق عليه أحيانًا اسم "الرأس" من الطابور، أولاً.

### جدولة أو تأجيل التسليم

تدعم طوابير الرسائل العديد منها إعداد وقت تسليم محدد للرسالة. إذا كان لدينا تأجيل مشترك لجميع الرسائل، فيمكننا إعداد طابور تأخير.

### التسليم مرة واحدة على الأقل

قد تخزن طوابير الرسائل عدة نسخ من الرسائل لضمان التوفر العالي، وإعادة إرسال الرسائل في حالة فشل الاتصال أو وجود أخطاء لضمان أنها تُسلَّم مرة واحدة على الأقل.

### التسليم بالضبط مرة واحدة

عندما لا يمكن تحمُّل التكرارات، ستضمن طوابير الرسائل من نوع FIFO (التسلسل الأول في الدخول أولاً) أن يتم توصيل كل رسالة بالضبط مرة واحدة (وفقًا للتسلسل) من خلال تصفية التكرارات تلقائيًا.

### طوابير الرسائل ذات الرسائل الخاطئة

طابور الرسائل ذات الرسائل الخاطئة هو طابور يُرسل له رسائل لا يمكن مُعالجتها بنجاح من طوابير أخرى. يُسهِّل ذلك إرسالها جانبًا للفحص اللاحق دون حجب معالجة الطابور أو إنفاق دورات وحدة المعالجة المركزية على رسالة قد لا يتم استهلاكها بنجاح.

### الترتيب

توفر معظم طوابير الرسائل الترتيب الذي يُضمِن تسليم الرسائل بنفس الترتيب الذي تم إرسالها تقريبًا، وأن يتم تسليم الرسالة على الأقل مرة واحدة.

### رسائل الأقراص السامة

رسائل الأقراص السامة هي رسائل خاصة يمكن استقبالها، لكنها لا يمكن معالجتها. إنها آلية تُستخدم للإشارة إلى المستهلك بإنهاء عمله حتى لا يكون في انتظار مدخلات جديدة بعد الآن، وتشبه إغلاق مقبس في نموذج العميل/الخادم.

### الأمان

تُوثِّق طوابير الرسائل التطبيقات التي تُحاول الوصول إلى الطابور، وهذا يسمح لنا بتشفير الرسائل عبر الشبكة وفي الطابور نفسه.

### طوابير المهام

تتلقَّى طوابير المهام المهام والبيانات المرتبطة بها، تُشغِّلها ثم تسلِّم نتائجها. يمكن أن تدعم جداول المهام الجدولة ويمكن استخدامها لتشغيل المهام المكثفة في الحساب في الخلفية.

## التحكُّم في العكسيَّة

إذا بدأت الطوابير تنمو بشكل كبير، فإن حجم الطابور يمكن أن يصبح أكبر من الذاكرة، مما يؤدي إلى فقدان ذاكرة التخزين المؤقت وقراءات القرص وحتى أداءًا أبطأ. يمكن أن يساعد التحكُّم في العكسيَّة عن طريق تحديد حجم الطابور، وبالتالي الحفاظ على معد

ل الإنتاج العالي وأوقات الاستجابة الجيدة للوظائف الموجودة بالفعل في الطابور. عندما يمتلئ الطابور، يحصل العملاء على رمز حالة انشغال الخادم أو HTTP 503 للمحاولة مرة أخرى في وقت لاحق. يمكن للعملاء إعادة المحاولة في وقت لاحق، ربما باستخدام استراتيجية العكسيَّة التعايضيَّة.

# النشر والاشتراك

بشكل مماثل لطابور الرسائل، يعد النشر والاشتراك أيضًا نوعًا من التواصل بين الخدمات الذي يسهل التواصل الغير متزامن. في نموذج النشر والاشتراك، يتم دفع أي رسالة مُنشَرة على موضوع (توبيك) فورًا إلى جميع المشتركين في هذا الموضوع.

المشتركين في موضوع الرسالة غالبًا ما يؤدون وظائف مختلفة، ويمكن لكل منهم أن يقوم بشيء مختلف بالرسالة بشكل متوازي. المُنشئ لا يحتاج لمعرفة من يستخدم المعلومات التي يتم بثها، والمشتركون لا يحتاجون لمعرفة مصدر الرسالة. هذا النمط من التواصل مختلف قليلاً عن طوابير الرسائل، حيث يعرف المكوِّن الذي يرسل الرسالة غالبًا الوجهة التي يتم إرسالها إليها.

## كيفية العمل

على عكس طوابير الرسائل التي تجمع الرسائل حتى يتم استردادها، تقوم مواضيع الرسائل بنقل الرسائل مع قليل أو بدون انتظار وتدفعها على الفور إلى جميع المشتركين. إليك كيفية العمل:

- يوفر موضوع الرسالة آلية خفيفة الوزن لبث إشعارات الأحداث الغير متزامنة والنقاط النهائية التي تسمح للمكونات البرمجية بالاتصال بالموضوع لإرسال واستقبال هذه الرسائل.
- لبث رسالة، يُدفع مكوِّن يُسمَّى "الناشر" ببساطة رسالة إلى الموضوع.
- سيتلقى جميع المكوِّنات المشتركة في الموضوع (المعروفة باسم "المشتركين") كل رسالة تم بثها.

## المزايا

استكمالًا لذلك، دعنا نتناول المزيد من المزايا في استخدام النشر والاشتراك:

- **توزيع الحمل**: يتيح نمط النشر والاشتراك التوزيع الفوري للإشعارات الأحداثية، وهو مفيد جدًا في التطبيقات التي تحتاج إلى معالجة كميات كبيرة من الأحداث بسرعة. حيث يُمكن للمشتركين تجزئة العمل ومعالجة الإشعارات المتوفرة بالتوازي، مما يزيد من كفاءة المعالجة ويسرع من الاستجابة.
- **التوجيه الديناميكي والاكتشاف التلقائي**: تمكننا نماذج النشر والاشتراك من الاكتشاف التلقائي للخدمات والتواصل معها بشكل أسهل وأكثر طبيعية وأقل عرضة للأخطاء. يمكن للناشر أن ينشر الرسائل على الموضوع بسهولة دون الحاجة إلى معرفة مين يستخدم المعلومات التي يتم بثها. وعندئذٍ، يمكن لأي طرف مهتم أن يشترك بنقطة النهاية الخاصة به إلى الموضوع وبدء تلقي هذه الرسائل. يمكن للمشتركين التغيير والترقية والتضاعف أو الاختفاء، ويقوم النظام بضبط نفسه بشكل ديناميكي وفقًا لذلك.
- **فصل البرمجيات وتوسيعها بشكل مستقل**: يعزل نمط النشر والاشتراك الناشرين والمشتركين ويسمح لهم بالعمل بشكل مستقل عن بعضهم البعض، مما يتيح لنا تطويرهم وتوسيعهم بشكل منفصل. هذا يساعد على الحد من الترابط الزائد بين المكونات ويجعل النظام أكثر مرونة وسهل الصيانة.
- **تبسيط التواصل**: يقلل نمط النشر والاشتراك من التعقيد بشكل عام. عوضًا عن إدارة الاتصالات بين المرسل والمستقبل بشكل مباشر ومنفرد، يُدار التواصل من خلال موضوع الرسالة الواحد الذي يُدير الاشتراكات ويقرر أي رسائل يجب تسليمها إلى أي من المشتركين.

## الميزات

لنتحدث الآن عن بعض الميزات المطلوبة في نمط النشر والاشتراك:

### تسليم الدفع

تقدم رسائل النشر والاشتراك إشعارات الأحداث الغير متزامنة على الفور عند نشر الرسائل إلى موضوع الرسالة. يتم إخطار المشتركين عند توفُّر رسالة.

### بروتوكولات ت

سليم متعددة

في نمط النشر والاشتراك، يمكن لمواضيع الرسائل الاتصال بأنواع متعددة من النقاط النهائية، مثل طوابير الرسائل ووظائف بلا سيرفر وخوادم HTTP وغيرها.

### النشر الشامل

يحدث هذا السيناريو عندما يتم إرسال رسالة إلى موضوع ومن ثم تكرارها ودفعها إلى العديد من النقاط النهائية. يوفر النشر الشامل إشعارات أحداث غير متزامنة والتي تتيح المعالجة المتوازية.

### التصفية

تسمح هذه الميزة للمشترك بإنشاء سياسة تصفية الرسالة بحيث تحصل على الإشعارات التي تهمه فقط، بدلاً من استلام كل رسالة فردية يتم نشرها إلى الموضوع.

### المتانة

يقدم خدمات رسائل النشر والاشتراك عادةً متانة عالية جدًا، وتوصيل مرة واحدة على الأقل، من خلال حفظ نسخ من نفس الرسالة على العديد من الخوادم.

### الأمان

تقوم مواضيع الرسائل بتوثيق التطبيقات التي تحاول نشر المحتوى، وهذا يسمح لنا باستخدام نقاط نهاية مشفرة وتشفير الرسائل أثناء الانتقال عبر الشبكة.

## الأمثلة

فيما يلي بعض التقنيات المستخدمة على نطاق واسع في رسائل النشر والاشتراك:

- [Amazon SNS](https://aws.amazon.com/sns)
- [Google Pub/Sub](https://cloud.google.com/pubsub)

# سيّر الخدمات المؤسسي (ESB)

سيّر الخدمات المؤسسي (ESB) هو نمط معماري يقوم بتنفيذ التكاملات بين التطبيقات من خلال مكون برمجي مركزي. يقوم ESB بتحويل نماذج البيانات، ويتعامل مع الاتصالات، وينفذ توجيه الرسائل، ويحول بين بروتوكولات الاتصال، وقد يدير تركيب طلبات متعددة. يمكن للESB جعل هذه التكاملات والتحويلات متاحة على شكل واجهة خدمة لإعادة الاستخدام من قبل التطبيقات الجديدة.

## المزايا

نظريًا، يقدم ESB المركزي إمكانية توحيد وتبسيط التواصل والرسائل والتكامل بين الخدمات عبر المؤسسة بشكل كبير. وإليك بعض المزايا في استخدام ESB:

- **تحسين إنتاجية المطورين**: يمكّن المطورين من دمج التقنيات الجديدة في جزء واحد من التطبيق دون لمس باقي التطبيق.
- **توسيع أسهل وأكثر فعالية من حيث التكلفة**: يمكن توسيع المكونات بشكل مستقل عن الآخرين.
- **مرونة أكبر**: فشل مكون واحد لا يؤثر على الآخرين، ويمكن لكل خدمة صغيرة أن تلتزم بمتطلبات التوفر الخاصة بها دون المخاطرة بتوفر العناصر الأخرى في النظام.

## العيوب

بينما نجحت نظم ESB في العديد من المؤسسات، أصبحت ESB في العديد من المؤسسات معروضة كعامل قيد. وإليك بعض العيوب في استخدام ESB:

- يمكن أن تؤدي القيام بتغييرات أو تحسينات في التكامل إلى تأثير آخرين يستخدمون نفس التكامل.
- يمكن أن يؤدي فشل نقطة واحدة إلى تعطيل جميع الاتصالات.
- يؤثر التحديثات على ESB عادةً على التكاملات الحالية، وبالتالي يتطلب إجراء اختبارات كبيرة لأداء أي تحديث.
- يتم إدارة ESB بشكل مركزي مما يجعل التعاون بين الفرق التقنية أمرًا تحديًا.
- تعقيد التكوين والصيانة عالي.

## الأمثلة

وفيما يلي بعض تقنيات سيّر الخدمات المؤسسي (ESB) المستخدمة على نطاق واسع:

- [Azure Service Bus](https://azure.microsoft.com/en-in/services/service-bus)
- [IBM App Connect](https://www.ibm.com/in-en/cloud/app-connect)
- [Apache Camel](https://camel.apache.org)
- [Fuse ESB](https://www.redhat.com/en/technologies/jboss-middleware/fuse)

# التمثيلات النمطية والخدمات المتناهية الصغر

## التمثيلات النمطية

التمثيل النمطي هو تطبيق مستقل ومستقل ذاتيًا. يتم بناؤه كوحدة واحدة وهو مسؤول ليس فقط عن مهمة معينة، بل يمكنه أداء كل الخطوات المطلوبة لتلبية احتياج الأعمال.

## المزايا

فيما يلي بعض المزايا للتمثيلات النمطية:

- سهولة التطوير أو التصحيح.
- تواصل سريع وموثوق.
- رصد واختبار سهل.
- دعم عمليات النقل الداخلي (ACID).

## العيوب

بعض العيوب الشائعة للتمثيلات النمطية:

- يصبح الصيانة صعبة عندما ينمو حجم قاعدة الشفرة.
- تطبيق مرتبط تمامًا وصعب التوسع.
- يتطلب الالتزام بتكنولوجيا محددة.
- في كل تحديث، يتم إعادة نشر التطبيق بأكمله.
- يقلل من الموثوقية حيث يمكن لعلة واحدة أن تتسبب في تعطيل النظام بأكمله.
- صعوبة في التوسع أو اعتماد التقنيات الجديدة.

## التمثيلات النمطية القابلة للتجزئة

التمثيل النمطي القابل للتجزئة هو نهج نبني وننفذ من خلاله تطبيقًا واحدًا (هذا هو الجزء "التمثيل النمطي")، ولكننا نبنيه بطريقة تقسم فيها الشفرة إلى وحدات مستقلة لكل الميزات المطلوبة في تطبيقنا.

يقلل هذا النهج من التبعية الناتجة عن وحدة بحيث يمكننا تحسين أو تغيير وحدة دون التأثير على الوحدات الأخرى. عندما يتم القيام به بشكل صحيح، يمكن أن يكون هذا مفيدًا حقًا على المدى الطويل حيث يقلل من التعقيد الناتج عن الحفاظ على التمثيل النمطي عندما ينمو النظام.

## الخدمات المتناهية الصغر

تتألف معمارية الخدمات المتناهية الصغر من مجموعة من الخدمات الصغيرة والمستقلة حيث يكون لكل خدمة مجموعة من القدرات التجارية والمحددة ضمن سياق محدد. يعتبر السياق المحدد تقسيمًا طبيعيًا للمنطق التجاري يوفر حدًا واضحًا داخله يوجد نموذج مجال.

لكل خدمة قا

عدة شفرة منفصلة يمكن إدارتها بواسطة فريق تطوير صغير. يمكن نشر الخدمات بشكل مستقل ويمكن للفريق تحديث خدمة موجودة دون إعادة بناء التطبيق بأكمله ونشره.

تكون الخدمات مسؤولة عن الاحتفاظ ببياناتها الخاصة أو الحالة الخارجية (قاعدة بيانات لكل خدمة). يختلف ذلك عن النموذج التقليدي، حيث يتم التعامل مع الاحتفاظ بالبيانات.

## السمات

يتميز نمط الخدمات المتناهية الصغر بالخصائص التالية:

- **ترابط فضفاض**: يجب أن تكون الخدمات مرتبطة فضفاضة حتى يمكن نشرها وتوجيهها بشكل مستقل. سيؤدي ذلك إلى فك تمركز فرق التطوير وبالتالي يمكنهم تطوير ونشر بسرعة مع حد أدنى من القيود والتبعيات التشغيلية.
- **صغيرة ومركزة**: إنها تتعلق بالنطاق والمسؤوليات وليس بالحجم، يجب أن تكون الخدمة مركزة على مشكلة محددة. ببساطة، "إنها تقوم بشيء واحد وتفعله بشكل جيد". في الواقع، يمكن أن تكون مستقلة عن التطبيق الأساسي.
- **مصممة للأعمال التجارية**: يتم تنظيم معمارية الخدمات المتناهية الصغر عادة حول قدرات وأولويات الأعمال التجارية.
- **المرونة والتحمل**: يجب تصميم الخدمات بطريقة تضمن استمرارية العمل في حالة الفشل أو الأخطاء. في البيئات التي تتم فيها تنفيذ الخدمات بشكل مستقل، تحمل الفشل أمرًا بالغ الأهمية.
- **قابلية الصيانة العالية**: يجب أن تكون الخدمة سهلة الصيانة والاختبار لأن الخدمات التي لا يمكن الصيانة لها ستكتب مرة أخرى.

## المزايا

فيما يلي بعض المزايا لمعمارية الخدمات المتناهية الصغر:

- خدمات فضفاضة الترابط.
- يمكن نشر الخدمات بشكل مستقل.
- مرنة لأكثر من فريق تطوير.
- تحسين تحمل الأخطاء وعزل البيانات.
- تحسين قابلية التوسع حيث يمكن توسيع كل خدمة بشكل مستقل.
- يلغي التزامًا طويل الأمد بتكنولوجيا محددة.

## العيوب

معمارية الخدمات المتناهية الصغر تحمل مجموعة من التحديات الخاصة بها:

- تعقيد النظام الموزع.
- اختبار أكثر صعوبة.
- مكلفة للصيانة (الخوادم الفردية وقواعد البيانات وما إلى ذلك).
- التواصل بين الخدمات له تحدياته الخاصة.
- سلامة واتساق البيانات.
- ازدحام الشبكة وتأخير البيانات.

## أفضل الممارسات

دع

ونا نناقش بعض أفضل الممارسات لمعمارية الخدمات المتناهية الصغر:

- نمذجة الخدمات حول المجال التجاري.
- يجب أن تكون الخدمات فضفاضة الترابط وذات تماسك وظيفي عالي.
- عزل الأخطاء واستخدام استراتيجيات مرونة لمنع تأثير الأخطاء داخل الخدمة من التوسع.
- يجب أن تتواصل الخدمات فقط من خلال واجهات برمجة تطبيق مصممة بشكل جيد. تجنب تسريب تفاصيل التنفيذ.
- يجب أن تكون تخزين البيانات خاصة بالخدمة التي تمتلك البيانات.
- تجنب الارتباط بين الخدمات. يمكن أن تسبب الارتباطات قاعدة بيانات مشتركة وبروتوكولات اتصال صارمة.
- تفكيك كل شيء. تعتبر الفرق الفردية مسؤولة عن تصميم وبناء الخدمات. تجنب مشاركة الشفرة أو نماذج البيانات.
- الفشل السريع باستخدام [مفتاح الكهرباء](https://karanpratapsingh.com/courses/system-design/circuit-breaker) لتحقيق التحمل من الأخطاء.
- التأكد من أن تغييرات واجهة البرمجة التطبيقية متوافقة مع الإصدار السابق.

## الفخاخ

فيما يلي بعض الفخاخ الشائعة لمعمارية الخدمات المتناهية الصغر:

- تحديد حدود الخدمة بناءً على المجال التجاري.
- الاستهانة بمدى صعوبة بناء نظام موزع.
- قاعدة بيانات مشتركة أو تبعيات مشتركة بين الخدمات.
- نقص الالتزام التجاري.
- نقص الملكية الواضحة.
- نقص الهوية.
- محاولة فعل كل شيء [ACID بدلاً من BASE](https://karanpratapsingh.com/courses/system-design/acid-and-base-consistency-models).
- نقص التصميم للتحمل من الأخطاء قد يؤدي إلى حدوث فشل تدريجي.

## الحذر من التمثيل النمطي الموزع

التمثيل النمطي الموزع هو نظام يشبه معمارية الخدمات المتناهية الصغر ولكنه مرتبط تمامًا ضمن نفسه مثل التطبيق الأحادي. يأتي اعتماد معمارية الخدمات المتناهية الصغر مع الكثير من المزايا. ولكن أثناء القيام بذلك، هناك فرص جيدة أننا قد ننتهي بالتمثيل النمطي الموزع.

تكون خدماتنا فقط نمطي موزع إذا تطبق أي من هذه النقاط عليه:

- يتطلب التواصل بين الخد

مات وقت استجابة قليل.
- الخدمات لا تتحمل بسهولة.
- الاعتمادية بين الخدمات.
- مشاركة نفس الموارد مثل قواعد البيانات.
- أنظمة تعتمد على بعضها بقوة.

أحد الأسباب الرئيسية لبناء تطبيق باستخدام معمارية الخدمات المتناهية الصغر هو الحصول على قابلية للتوسعة. لذلك، يجب أن تكون الخدمات فضفاضة الترابط لتمكين كل خدمة من التمتع بالاستقلالية. تنفق معمارية التمثيل النمطي الموزع هذا وتسبب في أن يعتمد معظم المكونات على بعضها البعض، مما يزيد من تعقيد التصميم. 

## معمارية الخدمات المتناهية الصغر مقابل العمارة الموجهة للخدمة (SOA)

قد تكون قد شاهدت مصطلح "معمارية الخدمة الموجهة للخدمة (SOA)" في الإنترنت أحيانًا، وحتى ربما قد يتم استخدامها بشكل متبادل مع الخدمات المتناهية الصغر، ولكنهما مختلفان عن بعضهما البعض، والفرق الرئيسي بين النهجين يتمثل في "النطاق".

تعرف معمارية الخدمات الموجهة للخدمة (SOA) طريقة لجعل مكونات البرنامج قابلة لإعادة الاستخدام من خلال واجهات الخدمة. تستخدم هذه الواجهات معايير الاتصال المشتركة وتركز على تحقيق أقصى قدر من إعادة استخدام الخدمة التطبيقية بينما تكون الخدمات المتناهية الصغر هي مجموعة من وحدات الخدمة الصغيرة المستقلة التي تركز على استقلالية الفريق وفصل الأجزاء.

## لماذا لا تحتاج إلى الخدمات المتناهية الصغر

في النهاية، قد تكون تتساءل، يبدو أن التمثيلات النمطية فكرة سيئة للبدء، لماذا يستخدمها أحد؟

حسنًا، الأمر يعتمد. على الرغم من أن كل نهج له مزاياه وعيوبه الخاصة، يُنصح بالبدء بالتمثيل النمطي عند بناء نظام جديد. إنه أمر مهم أن نفهم أن الخدمات المتناهية الصغر ليست بالضرورة حلاً لكل المشاكل، بدلاً من ذلك، فهي تحل مشكلة تنظيمية. إن معمارية الخدمات المتناهية الصغر هي بشكل رئيسي حول أولوياتك التنظيمية وفريقك بقدر ما هي عن التقنية.

قبل اتخاذ قرار التحول إلى معمارية الخدمات المتناهية الصغر، يجب عليك طرح أسئلة مثل:

- "هل يكون فريق التطوير كبيرًا للعمل بفعالية على قاعدة شفرة مشتركة؟"
- "هل يتم حجب الفرق بسبب الفرق الأخرى؟"
- "هل تقدم الخدمات المتناهية الصغر قيمة تجارية واضحة لنا؟"
- "هل يكون نظامي الأعمال ناضجًا بما يكفي لاستخدام الخدمات المتناهية الصغر؟"
- "هل الهندسة المعمارية الحالية تقيدنا بفوق الرأس الاتصال؟"

إذا لم تتطلب تطبيقك تقسيمه إلى خدمات متناهية الصغر، فليس هناك حاجة لذلك. لا يوجد ضرورة مطلقة لأن يتم تقسيم كل التطبيقات إلى خدمات متناهية الصغر. غالبًا ما نستلهم الإلهام من الشركات مثل نيتفليكس واستخدامها لخدمات متناهية الصغر، ولكن نتجاهل حق

يقة أننا لسنا نيتفليكس. إنهم مرروا بالعديد من التجارب والنماذج قبل أن يحصلوا على حلاً جاهزًا للسوق، وأصبحت هذه الهندسة المعمارية مقبولة بالنسبة لهم عندما حددوا المشكلة التي كانوا يحاولون معالجتها.

لذلك، من المهم فهم بعمق إذا كانت شركتك حقًا تحتاج إلى الخدمات المتناهية الصغر. ما أحاول قوله هو أن الخدمات المتناهية الصغر هي حلاً للقضايا المعقدة وإذا لم تكن لشركتك قضايا معقدة، فلست بحاجة إليها.

# التصميم المعماري المستند إلى الأحداث (EDA)

التصميم المعماري المستند إلى الأحداث (EDA) يتعلق باستخدام الأحداث كوسيلة للتواصل داخل نظام معين. عمومًا، يتم استخدام وسيط رسائل لنشر الأحداث واستهلاكها بشكل غير متزامن. المُنشئ لا يعلم من يستهلك الحدث، والمستهلكون لا يعرفون بعضهم البعض. التصميم المعماري المستند إلى الأحداث هو ببساطة وسيلة لتحقيق ارتباط فضفاض بين الخدمات داخل النظام.

## ما هو الحدث؟

الحدث هو نقطة بيانات تُمثل تغييرات الحالة في النظام. لا يحدد ما يجب أن يحدث وكيفية تعديل النظام، بل يُخطِّر النظام بتغيير حالة معينة. عندما يقوم المستخدم بإجراء إجراء، يُحفِّز حدثًا.

## المكونات

تحتوي التصميمات المعمارية المستندة إلى الأحداث على ثلاثة مكونات رئيسية:

- **منتجو الأحداث**: ينشرون حدثًا للموجه.
- **الموجه الحدث**: يقوم بتصفية الأحداث ودفعها إلى المستهلكين.
- **مستهلكو الأحداث**: يستخدمون الأحداث لتعكس التغييرات في النظام.

![التصميم المعماري المستند إلى الأحداث](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/event-driven-architecture/event-driven-architecture.png)

_ملاحظة: النقاط في الرسم البياني تمثل أحداثًا مختلفة في النظام._

## الأنماط

هناك العديد من الطرق لتنفيذ التصميم المعماري المستند إلى الأحداث، والطريقة التي نستخدمها تعتمد على حالة الاستخدام، ولكن هنا بعض الأمثلة الشائعة:

- [الملحمات](https://karanpratapsingh.com/courses/system-design/distributed-transactions#sagas)
- [النشر والاشتراك](https://karanpratapsingh.com/courses/system-design/publish-subscribe)
- [تخزين الأحداث](https://karanpratapsingh.com/courses/system-design/event-sourcing)
- [القيام بالأوامر وتوزيع مسؤولية الاستعلام (CQRS)](https://karanpratapsingh.com/courses/system-design/command-and-query-responsibility-segregation)

_ملاحظة: يتم مناقشة كل من هذه الأساليب بشكل منفصل._

## المزايا

دعونا نناقش بعض المزايا:

- فصل المنتجين والمستهلكين.
- مُقيم جدًا وموزَّع.
- سهولة إضافة مستهلكين جدد.
- يحسن الرشاقة.

## التحديات

فيما يلي بعض التحديات المتعلقة بالتصميم المعماري المستند إلى الأحداث:

- توصيل مضمون.
- من الصعب التعامل مع الأخطاء.
- أنظمة مستندة إلى الأحداث هي معقدة بشكل عام.
- معالجة الأحداث بدقة مرة واحدة، بترتيبها.

## الحالات الاستخدامية

فيما يلي بعض حالات الاستخدام الشائعة حيث تكون التصاميم المعمارية المستندة إلى الأحداث مفيدة:

- البيانات الوصفية والمقاييس.
- سجلات الخادم والأمان.
- دمج الأنظمة غير المتجانسة.
- النشر على نطاق وتجهيز متوازي.

## الأمثلة

فيما يلي بعض التقنيات المستخدمة على نطاق واسع لتنفيذ التصاميم المعمارية المستندة إلى الأحداث:

- [NATS](https://nats.io)
- [Apache Kafka](https://kafka.apache.org)
- [Amazon EventBridge](https://aws.amazon.com/eventbridge)
- [Amazon SNS](https://aws.amazon.com/sns)
- [Google PubSub](https://cloud.google.com/pubsub)
# التخزين بالأحداث

بدلاً من تخزين الحالة الحالية للبيانات في مجال معين، يمكن استخدام متجر يسجل سلسلة كاملة من الإجراءات التي تم اتخاذها على تلك البيانات. يعمل المتجر كنظام تسجيل ويمكن استخدامه لتجسيد كائنات المجال.

![event-sourcing](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/event-sourcing/event-sourcing.png)

يمكن أن يبسط هذا المفهوم المهام في المجالات المعقدة، من خلال تجنب الحاجة إلى مزامنة نموذج البيانات ومجال الأعمال، مع تحسين الأداء والقابلية للتوسع والاستجابة. يمكن أن يوفر أيضًا الاستقرار للبيانات التي تخضع للمعاملات، والحفاظ على سجلات مراجعة كاملة وتاريخ يمكن أن يمكّن الإجراءات التعويضية.

## التخزين بالأحداث مقابل الهندسة المعمارية المدفوعة بالأحداث

يبدو أن العديد من الأشخاص يخلطون بين التخزين بالأحداث و [الهندسة المعمارية المدفوعة بالأحداث (EDA)](https://karanpratapsingh.com/courses/system-design/event-driven-architecture). الهندسة المعمارية المدفوعة بالأحداث تتعلق باستخدام الأحداث للتواصل بين حدود الخدمة. عمومًا، يتم استغلال وسيط الرسائل لنشر الأحداث واستهلاكها بشكل غير متزامن في حدود أخرى.

بينما التخزين بالأحداث يتعلق باستخدام الأحداث كحالة، وهو نهج مختلف لتخزين البيانات. بدلاً من تخزين الحالة الحالية، سنقوم بدلاً من ذلك بتخزين الأحداث. أيضًا، التخزين بالأحداث هو واحد من الأنماط المختلفة لتنفيذ الهندسة المعمارية المدفوعة بالأحداث.

## المزايا

لنتناقش عن بعض المزايا في استخدام التخزين بالأحداث:

- ممتاز لتقارير البيانات في الوقت الحقيقي.
- رائع للسلامة من الفشل، حيث يمكن إعادة تجسيد البيانات من مخزن الأحداث.
- مرن للغاية، حيث يمكن تخزين أي نوع من الرسائل.
- الطريقة المفضلة لتحقيق وظيفة السجلات التدقيق للأنظمة عالية الامتثال.

## العيوب

هذه هي العيوب التي تتضمنها التخزين بالأحداث:

- يتطلب بنية شبكة فعالة للغاية.
- يتطلب طريقة موثوقة للتحكم في تنسيق الرسائل، مثل سجل النطاق.
- ستحتوي الأحداث المختلفة على حمولات مختلفة.

# Command and Query Responsibility Segregation (CQRS)

Command Query Responsibility Segregation (CQRS) is an architectural pattern that divides a system's actions into commands and queries. It was first described by [Greg Young](https://twitter.com/gregyoung).

In CQRS, a _command_ is an instruction, a directive to perform a specific task. It is an intention to change something and doesn't return a value, only an indication of success or failure. And, a _query_ is a request for information that doesn't change the system's state or cause any side effects.

![command-and-query-responsibility-segregation](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/command-and-query-responsibility-segregation/command-and-query-responsibility-segregation.png)

The core principle of CQRS is the separation of commands and queries. They perform fundamentally different roles within a system, and separating them means that each can be optimized as needed, which distributed systems can really benefit from.

## CQRS with Event Sourcing

The CQRS pattern is often used along with the Event Sourcing pattern. CQRS-based systems use separate read and write data models, each tailored to relevant tasks and often located in physically separate stores.

When used with the Event Sourcing pattern, the store of events is the write model and is the official source of information. The read model of a CQRS-based system provides materialized views of the data, typically as highly denormalized views.

## Advantages

Let's discuss some advantages of CQRS:

- Allows independent scaling of read and write workloads.
- Easier scaling, optimizations, and architectural changes.
- Closer to business logic with loose coupling.
- The application can avoid complex joins when querying.
- Clear boundaries between the system behavior.

## Disadvantages

Below are some disadvantages of CQRS:

- More complex application design.
- Message failures or duplicate messages can occur.
- Dealing with eventual consistency is a challenge.
- Increased system maintenance efforts.

## Use cases

Here are some scenarios where CQRS will be helpful:

- The performance of data reads must be fine-tuned separately from the performance of data writes.
- The system is expected to evolve over time and might contain multiple versions of the model, or where business rules change regularly.
- Integration with other systems, especially in combination with event sourcing, where the temporal failure of one subsystem shouldn't affect the availability of the others.
- Better security to ensure that only the right domain entities are performing writes on the data.

# API Gateway

The API Gateway is an API management tool that sits between a client and a collection of backend services. It is a single entry point into a system that encapsulates the internal system architecture and provides an API that is tailored to each client. It also has other responsibilities such as authentication, monitoring, load balancing, caching, throttling, logging, etc.

![api-gateway](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/api-gateway/api-gateway.png)

## Why do we need an API Gateway?

The granularity of APIs provided by microservices is often different than what a client needs. Microservices typically provide fine-grained APIs, which means that clients need to interact with multiple services. Hence, an API gateway can provide a single entry point for all clients with some additional features and better management.

## Features

Below are some desired features of an API Gateway:

- Authentication and Authorization
- [Service discovery](https://karanpratapsingh.com/courses/system-design/service-discovery)
- [Reverse Proxy](https://karanpratapsingh.com/courses/system-design/proxy#reverse-proxy)
- [Caching](https://karanpratapsingh.com/courses/system-design/caching)
- Security
- Retry and [Circuit breaking](https://karanpratapsingh.com/courses/system-design/circuit-breaker)
- [Load balancing](https://karanpratapsingh.com/courses/system-design/load-balancing)
- Logging, Tracing
- API composition
- [Rate limiting](https://karanpratapsingh.com/courses/system-design/rate-limiting) and throttling
- Versioning
- Routing
- IP whitelisting or blacklisting

## Advantages

Let's look at some advantages of using an API Gateway:

- Encapsulates the internal structure of an API.
- Provides a centralized view of the API.
- Simplifies the client code.
- Monitoring, analytics, tracing, and other such features.

## Disadvantages

Here are some possible disadvantages of an API Gateway:

- Possible single point of failure.
- Might impact performance.
- Can become a bottleneck if not scaled properly.
- Configuration can be challenging.

## Backend For Frontend (BFF) pattern

In the Backend For Frontend (BFF) pattern, we create separate backend services to be consumed by specific frontend applications or interfaces. This pattern is useful when we want to avoid customizing a single backend for multiple interfaces. This pattern was first described by [Sam Newman](https://samnewman.io).

Also, sometimes the output of data returned by the microservices to the front end is not in the exact format or filtered as needed by the front end. To solve this issue, the frontend should have some logic to reformat the data, and therefore, we can use BFF to shift some of this logic to the intermediate layer.

![backend-for-frontend](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/api-gateway/backend-for-frontend.png)

The primary function of the backend for the frontend pattern is to get the required data from the appropriate service, format the data, and sent it to the frontend.

_[GraphQL](https://karanpratapsingh.com/courses/system-design/rest-graphql-grpc#graphql) performs really well as a backend for frontend (BFF)._

### When to use this pattern?

We should consider using a Backend For Frontend (BFF) pattern when:

- A shared or general purpose backend service must be maintained with significant development overhead.
- We want to optimize the backend for the requirements of a specific client.
- Customizations are made to a general-purpose backend to accommodate multiple interfaces.

## Examples

Following are some widely used gateways technologies:

- [Amazon API Gateway](https://aws.amazon.com/api-gateway)
- [Apigee API Gateway](https://cloud.google.com/apigee)
- [Azure API Gateway](https://azure.microsoft.com/en-in/services/api-management)
- [Kong API Gateway](https://konghq.com/kong)

# REST, GraphQL, gRPC

A good API design is always a crucial part of any system. But it is also important to pick the right API technology. So, in this tutorial, we will briefly discuss different API technologies such as REST, GraphQL, and gRPC.

## What's an API?

Before we even get into API technologies, let's first understand what is an API.

API stands for Application Programming Interface. It is a set of definitions and protocols for building and integrating application software. It's sometimes referred to as a contract between an information provider and an information user establishing the content required from the producer and the content required by the consumer.

In other words, if you want to interact with a computer or system to retrieve information or perform a function, an API helps you communicate what you want to that system so it can understand and complete the request.

## REST

A [REST API](https://www.ics.uci.edu/~fielding/pubs/dissertation/rest_arch_style.htm) (also known as RESTful API) is an application programming interface that conforms to the constraints of REST architectural style and allows for interaction with RESTful web services. REST stands for Representational State Transfer and it was first introduced by [Roy Fielding](https://roy.gbiv.com) in the year 2000.

_In REST API, the fundamental unit is a resource._

### Concepts

Let's discuss some concepts of a RESTful API.

**Constraints**

In order for an API to be considered _RESTful_, it has to conform to these architectural constraints:

- **Uniform Interface**: There should be a uniform way of interacting with a given server.
- **Client-Server**: A client-server architecture managed through HTTP.
- **Stateless**: No client context shall be stored on the server between requests.
- **Cacheable**: Every response should include whether the response is cacheable or not and for how much duration responses can be cached at the client-side.
- **Layered system**: An application architecture needs to be composed of multiple layers.
- **Code on demand**: Return executable code to support a part of your application. _(optional)_

**HTTP Verbs**

HTTP defines a set of request methods to indicate the desired action to be performed for a given resource. Although they can also be nouns, these request methods are sometimes referred to as _HTTP verbs_. Each of them implements a different semantic, but some common features are shared by a group of them.

Below are some commonly used HTTP verbs:

- **GET**: Request a representation of the specified resource.
- **HEAD**: Response is identical to a `GET` request, but without the response body.
- **POST**: Submits an entity to the specified resource, often causing a change in state or side effects on the server.
- **PUT**: Replaces all current representations of the target resource with the request payload.
- **DELETE**: Deletes the specified resource.
- **PATCH**: Applies partial modifications to a resource.

**HTTP response codes**

[HTTP response status codes](https://en.wikipedia.org/wiki/List_of_HTTP_status_codes) indicate whether a specific HTTP request has been successfully completed.

There are five classes defined by the standard:

- 1xx - Informational responses.
- 2xx - Successful responses.
- 3xx - Redirection responses.
- 4xx - Client error responses.
- 5xx - Server error responses.

For example, HTTP 200 means that the request was successful.

### Advantages

Let's discuss some advantages of REST API:

- Simple and easy to understand.
- Flexible and portable.
- Good caching support.
- Client and server are decoupled.

### Disadvantages

Let's discuss some disadvantages of REST API:

- Over-fetching of data.
- Sometimes multiple round trips to the server are required.

### Use cases

REST APIs are pretty much used universally and are the default standard for designing APIs. Overall REST APIs are quite flexible and can fit almost all scenarios.

### Example

Here's an example usage of a REST API that operates on a **users** resource.

| URI           | HTTP verb | Description         |
| ------------- | --------- | ------------------- |
| /users        | GET       | Get all users       |
| /users/\{id\} | GET       | Get a user by id    |
| /users        | POST      | Add a new user      |
| /users/\{id\} | PATCH     | Update a user by id |
| /users/\{id\} | DELETE    | Delete a user by id |

_There is so much more to learn when it comes to REST APIs, I will highly recommend looking into [Hypermedia as the Engine of Application State (HATEOAS)](https://en.wikipedia.org/wiki/HATEOAS)._

## GraphQL

[GraphQL](https://graphql.org) is a query language and server-side runtime for APIs that prioritizes giving clients exactly the data they request and no more. It was developed by [Facebook](https://engineering.fb.com) and later open-sourced in 2015.

GraphQL is designed to make APIs fast, flexible, and developer-friendly. Additionally, GraphQL gives API maintainers the flexibility to add or deprecate fields without impacting existing queries. Developers can build APIs with whatever methods they prefer, and the GraphQL specification will ensure they function in predictable ways to clients.

_In GraphQL, the fundamental unit is a query._

### Concepts

Let's briefly discuss some key concepts in GraphQL:

**Schema**

A GraphQL schema describes the functionality clients can utilize once they connect to the GraphQL server.

**Queries**

A query is a request made by the client. It can consist of fields and arguments for the query. The operation type of a query can also be a [mutation](https://graphql.org/learn/queries/#mutations) which provides a way to modify server-side data.

**Resolvers**

Resolver is a collection of functions that generate responses for a GraphQL query. In simple terms, a resolver acts as a GraphQL query handler.

### Advantages

Let's discuss some advantages of GraphQL:

- Eliminates over-fetching of data.
- Strongly defined schema.
- Code generation support.
- Payload optimization.

### Disadvantages

Let's discuss some disadvantages of GraphQL:

- Shifts complexity to server-side.
- Caching becomes hard.
- Versioning is ambiguous.
- N+1 problem.

### Use cases

GraphQL proves to be essential in the following scenarios:

- Reducing app bandwidth usage as we can query multiple resources in a single query.
- Rapid prototyping for complex systems.
- When we are working with a graph-like data model.

### Example

Here's a GraphQL schema that defines a `User` type and a `Query` type.

```graphql
type Query {
  getUser: User
}

type User {
  id: ID
  name: String
  city: String
  state: String
}
```

Using the above schema, the client can request the required fields easily without having to fetch the entire resource or guess what the API might return.

```graphql
{
  getUser {
    id
    name
    city
  }
}
```

This will give the following response to the client.

```json
{
  "getUser": {
    "id": 123,
    "name": "Karan",
    "city": "San Francisco"
  }
}
```

_Learn more about GraphQL at [graphql.org](https://graphql.org)._

## gRPC

[gRPC](https://grpc.io) is a modern open-source high-performance [Remote Procedure Call (RPC)](https://en.wikipedia.org/wiki/Remote_procedure_call) framework that can run in any environment. It can efficiently connect services in and across data centers with pluggable support for load balancing, tracing, health checking, authentication and much more.

### Concepts

Let's discuss some key concepts of gRPC.

**Protocol buffers**

Protocol buffers provide a language and platform-neutral extensible mechanism for serializing structured data in a forward and backward-compatible way. It's like JSON, except it's smaller and faster, and it generates native language bindings.

**Service definition**

Like many RPC systems, gRPC is based on the idea of defining a service and specifying the methods that can be called remotely with their parameters and return types. gRPC uses protocol buffers as the [Interface Definition Language (IDL)](https://en.wikipedia.org/wiki/Interface_description_language) for describing both the service interface and the structure of the payload messages.

### Advantages

Let's discuss some advantages of gRPC:

- Lightweight and efficient.
- High performance.
- Built-in code generation support.
- Bi-directional streaming.

### Disadvantages

Let's discuss some disadvantages of gRPC:

- Relatively new compared to REST and GraphQL.
- Limited browser support.
- Steeper learning curve.
- Not human readable.

### Use cases

Below are some good use cases for gRPC:

- Real-time communication via bi-directional streaming.
- Efficient inter-service communication in microservices.
- Low latency and high throughput communication.
- Polyglot environments.

### Example

Here's a basic example of a gRPC service defined in a `*.proto` file. Using this definition, we can easily code generate the `HelloService` service in the programming language of our choice.

```protobuf
service HelloService {
  rpc SayHello (HelloRequest) returns (HelloResponse);
}

message HelloRequest {
  string greeting = 1;
}

message HelloResponse {
  string reply = 1;
}
```

## REST vs GraphQL vs gRPC

Now that we know how these API designing techniques work, let's compare them based on the following parameters:

- Will it cause tight coupling?
- How _chatty_ (distinct API calls to get needed information) are the APIs?
- What's the performance like?
- How complex is it to integrate?
- How well does the caching work?
- Built-in tooling and code generation?
- What's API discoverability like?
- How easy is it to version APIs?

| Type    | Coupling | Chattiness | Performance | Complexity | Caching | Codegen | Discoverability | Versioning |
| ------- | -------- | ---------- | ----------- | ---------- | ------- | ------- | --------------- | ---------- |
| REST    | Low      | High       | Good        | Medium     | Great   | Bad     | Good            | Easy       |
| GraphQL | Medium   | Low        | Good        | High       | Custom  | Good    | Good            | Custom     |
| gRPC    | High     | Medium     | Great       | Low        | Custom  | Great   | Bad             | Hard       |

### Which API technology is better?

Well, the answer is none of them. There is no silver bullet as each of these technologies has its own advantages and disadvantages. Users only care about using our APIs in a consistent way, so make sure to focus on your domain and requirements when designing your API.

# Long polling, WebSockets, Server-Sent Events (SSE)

Web applications were initially developed around a client-server model, where the web client is always the initiator of transactions like requesting data from the server. Thus, there was no mechanism for the server to independently send, or push, data to the client without the client first making a request. Let's discuss some approaches to overcome this problem.

## Long polling

HTTP Long polling is a technique used to push information to a client as soon as possible from the server. As a result, the server does not have to wait for the client to send a request.

In Long polling, the server does not close the connection once it receives a request from the client. Instead, the server responds only if any new message is available or a timeout threshold is reached.

![long-polling](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/long-polling-websockets-server-sent-events/long-polling.png)

Once the client receives a response, it immediately sends a new request to the server to have a new pending connection to send data to the client, and the operation is repeated. With this approach, the server emulates a real-time server push feature.

### Working

Let's understand how long polling works:

1. The client makes an initial request and waits for a response.
2. The server receives the request and delays sending anything until an update is available.
3. Once an update is available, the response is sent to the client.
4. The client receives the response and makes a new request immediately or after some defined interval to establish a connection again.

### Advantages

Here are some advantages of long polling:

- Easy to implement, good for small-scale projects.
- Nearly universally supported.

### Disadvantages

A major downside of long polling is that it is usually not scalable. Below are some of the other reasons:

- Creates a new connection each time, which can be intensive on the server.
- Reliable message ordering can be an issue for multiple requests.
- Increased latency as the server needs to wait for a new request.

## WebSockets

WebSocket provides full-duplex communication channels over a single TCP connection. It is a persistent connection between a client and a server that both parties can use to start sending data at any time.

The client establishes a WebSocket connection through a process known as the WebSocket handshake. If the process succeeds, then the server and client can exchange data in both directions at any time. The WebSocket protocol enables the communication between a client and a server with lower overheads, facilitating real-time data transfer from and to the server.

![websockets](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/long-polling-websockets-server-sent-events/websockets.png)

This is made possible by providing a standardized way for the server to send content to the client without being asked and allowing for messages to be passed back and forth while keeping the connection open.

### Working

Let's understand how WebSockets work:

1. The client initiates a WebSocket handshake process by sending a request.
2. The request also contains an [HTTP Upgrade](https://en.wikipedia.org/wiki/HTTP/1.1_Upgrade_header) header that allows the request to switch to the WebSocket protocol (`ws://`).
3. The server sends a response to the client, acknowledging the WebSocket handshake request.
4. A WebSocket connection will be opened once the client receives a successful handshake response.
5. Now the client and server can start sending data in both directions allowing real-time communication.
6. The connection is closed once the server or the client decides to close the connection.

### Advantages

Below are some advantages of WebSockets:

- Full-duplex asynchronous messaging.
- Better origin-based security model.
- Lightweight for both client and server.

### Disadvantages

Let's discuss some disadvantages of WebSockets:

- Terminated connections aren't automatically recovered.
- Older browsers don't support WebSockets (becoming less relevant).

## Server-Sent Events (SSE)

Server-Sent Events (SSE) is a way of establishing long-term communication between client and server that enables the server to proactively push data to the client.

![server-sent-events](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/long-polling-websockets-server-sent-events/server-sent-events.png)

It is unidirectional, meaning once the client sends the request it can only receive the responses without the ability to send new requests over the same connection.

### Working

Let's understand how server-sent events work:

1. The client makes a request to the server.
2. The connection between client and server is established and it remains open.
3. The server sends responses or events to the client when new data is available.

### Advantages

- Simple to implement and use for both client and server.
- Supported by most browsers.
- No trouble with firewalls.

### Disadvantages

- Unidirectional nature can be limiting.
- Limitation for the maximum number of open connections.
- Does not support binary data.

# Geohashing and Quadtrees

## Geohashing

Geohashing is a [geocoding](https://en.wikipedia.org/wiki/Address_geocoding) method used to encode geographic coordinates such as latitude and longitude into short alphanumeric strings. It was created by [Gustavo Niemeyer](https://twitter.com/gniemeyer) in 2008.

For example, San Francisco with coordinates `37.7564, -122.4016` can be represented in geohash as `9q8yy9mf`.

### How does Geohashing work?

Geohash is a hierarchical spatial index that uses Base-32 alphabet encoding, the first character in a geohash identifies the initial location as one of the 32 cells. This cell will also contain 32 cells. This means that to represent a point, the world is recursively divided into smaller and smaller cells with each additional bit until the desired precision is attained. The precision factor also determines the size of the cell.

![geohashing](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/geohashing-and-quadtrees/geohashing.png)

Geohashing guarantees that points are spatially closer if their Geohashes share a longer prefix which means the more characters in the string, the more precise the location. For example, geohashes `9q8yy9mf` and `9q8yy9vx` are spatially closer as they share the prefix `9q8yy9`.

Geohashing can also be used to provide a degree of anonymity as we don't need to expose the exact location of the user because depending on the length of the geohash we just know they are somewhere within an area.

The cell sizes of the geohashes of different lengths are as follows:

| Geohash length | Cell width | Cell height |
| -------------- | ---------- | ----------- |
| 1              | 5000 km    | 5000 km     |
| 2              | 1250 km    | 1250 km     |
| 3              | 156 km     | 156 km      |
| 4              | 39.1 km    | 19.5 km     |
| 5              | 4.89 km    | 4.89 km     |
| 6              | 1.22 km    | 0.61 km     |
| 7              | 153 m      | 153 m       |
| 8              | 38.2 m     | 19.1 m      |
| 9              | 4.77 m     | 4.77 m      |
| 10             | 1.19 m     | 0.596 m     |
| 11             | 149 mm     | 149 mm      |
| 12             | 37.2 mm    | 18.6 mm     |

### Use cases

Here are some common use cases for Geohashing:

- It is a simple way to represent and store a location in a database.
- It can also be shared on social media as URLs since it is easier to share, and remember than latitudes and longitudes.
- We can efficiently find the nearest neighbors of a point through very simple string comparisons and efficient searching of indexes.

### Examples

Geohashing is widely used and it is supported by popular databases.

- [MySQL](https://www.mysql.com)
- [Redis](http://redis.io)
- [Amazon DynamoDB](https://aws.amazon.com/dynamodb)
- [Google Cloud Firestore](https://cloud.google.com/firestore)

## Quadtrees

A quadtree is a tree data structure in which each internal node has exactly four children. They are often used to partition a two-dimensional space by recursively subdividing it into four quadrants or regions. Each child or leaf node stores spatial information. Quadtrees are the two-dimensional analog of [Octrees](https://en.wikipedia.org/wiki/Octree) which are used to partition three-dimensional space.

![quadtree](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/geohashing-and-quadtrees/quadtree.png)

### Types of Quadtrees

Quadtrees may be classified according to the type of data they represent, including areas, points, lines, and curves. The following are common types of quadtrees:

- Point quadtrees
- Point-region (PR) quadtrees
- Polygonal map (PM) quadtrees
- Compressed quadtrees
- Edge quadtrees

### Why do we need Quadtrees?

Aren't latitudes and longitudes enough? Why do we need quadtrees? While in theory using latitude and longitude we can determine things such as how close points are to each other using [euclidean distance](https://en.wikipedia.org/wiki/Euclidean_distance), for practical use cases it is simply not scalable because of its CPU-intensive nature with large data sets.

![quadtree-subdivision](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/geohashing-and-quadtrees/quadtree-subdivision.png)

Quadtrees enable us to search points within a two-dimensional range efficiently, where those points are defined as latitude/longitude coordinates or as cartesian (x, y) coordinates. Additionally, we can save further computation by only subdividing a node after a certain threshold. And with the application of mapping algorithms such as the [Hilbert curve](https://en.wikipedia.org/wiki/Hilbert_curve), we can easily improve range query performance.

### Use cases

Below are some common uses of quadtrees:

- Image representation, processing, and compression.
- Spacial indexing and range queries.
- Location-based services like Google Maps, Uber, etc.
- Mesh generation and computer graphics.
- Sparse data storage.

# Circuit breaker

The circuit breaker is a design pattern used to detect failures and encapsulates the logic of preventing a failure from constantly recurring during maintenance, temporary external system failure, or unexpected system difficulties.

![circuit-breaker](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/circuit-breaker/circuit-breaker.png)

The basic idea behind the circuit breaker is very simple. We wrap a protected function call in a circuit breaker object, which monitors for failures. Once the failures reach a certain threshold, the circuit breaker trips, and all further calls to the circuit breaker return with an error, without the protected call being made at all. Usually, we'll also want some kind of monitor alert if the circuit breaker trips.

## Why do we need circuit breaking?

It's common for software systems to make remote calls to software running in different processes, probably on different machines across a network. One of the big differences between in-memory calls and remote calls is that remote calls can fail, or hang without a response until some timeout limit is reached. What's worse is if we have many callers on an unresponsive supplier, then we can run out of critical resources leading to cascading failures across multiple systems.

## States

Let's discuss circuit breaker states:

### Closed

When everything is normal, the circuit breakers remain closed, and all the request passes through to the services as normal. If the number of failures increases beyond the threshold, the circuit breaker trips and goes into an open state.

### Open

In this state circuit breaker returns an error immediately without even invoking the services. The Circuit breakers move into the half-open state after a certain timeout period elapses. Usually, it will have a monitoring system where the timeout will be specified.

### Half-open

In this state, the circuit breaker allows a limited number of requests from the service to pass through and invoke the operation. If the requests are successful, then the circuit breaker will go to the closed state. However, if the requests continue to fail, then it goes back to the open state.

# Rate Limiting

Rate limiting refers to preventing the frequency of an operation from exceeding a defined limit. In large-scale systems, rate limiting is commonly used to protect underlying services and resources. Rate limiting is generally used as a defensive mechanism in distributed systems, so that shared resources can maintain availability. It also protects our APIs from unintended or malicious overuse by limiting the number of requests that can reach our API in a given period of time.

![rate-limiting](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/rate-limiting/rate-limiting.png)

## Why do we need Rate Limiting?

Rate limiting is a very important part of any large-scale system and it can be used to accomplish the following:

- Avoid resource starvation as a result of Denial of Service (DoS) attacks.
- Rate Limiting helps in controlling operational costs by putting a virtual cap on the auto-scaling of resources which if not monitored might lead to exponential bills.
- Rate limiting can be used as defense or mitigation against some common attacks.
- For APIs that process massive amounts of data, rate limiting can be used to control the flow of that data.

## Algorithms

There are various algorithms for API rate limiting, each with its advantages and disadvantages. Let's briefly discuss some of these algorithms:

### Leaky Bucket

Leaky Bucket is an algorithm that provides a simple, intuitive approach to rate limiting via a queue. When registering a request, the system appends it to the end of the queue. Processing for the first item on the queue occurs at a regular interval or first-in, first-out (FIFO). If the queue is full, then additional requests are discarded (or leaked).

### Token Bucket

Here we use a concept of a _bucket_. When a request comes in, a token from the bucket must be taken and processed. The request will be refused if no token is available in the bucket, and the requester will have to try again later. As a result, the token bucket gets refreshed after a certain time period.

### Fixed Window

The system uses a window size of `n` seconds to track the fixed window algorithm rate. Each incoming request increments the counter for the window. It discards the request if the counter exceeds a threshold.

### Sliding Log

Sliding Log rate-limiting involves tracking a time-stamped log for each request. The system stores these logs in a time-sorted hash set or table. It also discards logs with timestamps beyond a threshold. When a new request comes in, we calculate the sum of logs to determine the request rate. If the request would exceed the threshold rate, then it is held.

### Sliding Window

Sliding Window is a hybrid approach that combines the fixed window algorithm's low processing cost and the sliding log's improved boundary conditions. Like the fixed window algorithm, we track a counter for each fixed window. Next, we account for a weighted value of the previous window's request rate based on the current timestamp to smooth out bursts of traffic.

## Rate Limiting in Distributed Systems

Rate Limiting becomes complicated when distributed systems are involved. The two broad problems that come with rate limiting in distributed systems are:

### Inconsistencies

When using a cluster of multiple nodes, we might need to enforce a global rate limit policy. Because if each node were to track its rate limit, a consumer could exceed a global rate limit when sending requests to different nodes. The greater the number of nodes, the more likely the user will exceed the global limit.

The simplest way to solve this problem is to use sticky sessions in our load balancers so that each consumer gets sent to exactly one node but this causes a lack of fault tolerance and scaling problems. Another approach might be to use a centralized data store like [Redis](https://redis.io) but this will increase latency and cause race conditions.

### Race Conditions

This issue happens when we use a naive _"get-then-set"_ approach, in which we retrieve the current rate limit counter, increment it, and then push it back to the datastore. This model's problem is that additional requests can come through in the time it takes to perform a full cycle of read-increment-store, each attempting to store the increment counter with an invalid (lower) counter value. This allows a consumer to send a very large number of requests to bypass the rate limiting controls.

One way to avoid this problem is to use some sort of distributed locking mechanism around the key, preventing any other processes from accessing or writing to the counter. Though the lock will become a significant bottleneck and will not scale well. A better approach might be to use a _"set-then-get"_ approach, allowing us to quickly increment and check counter values without letting the atomic operations get in the way.

# Service Discovery

Service discovery is the detection of services within a computer network. Service Discovery Protocol (SDP) is a networking standard that accomplishes the detection of networks by identifying resources.

## Why do we need Service Discovery?

In a monolithic application, services invoke one another through language-level methods or procedure calls. However, modern microservices-based applications typically run in virtualized or containerized environments where the number of instances of a service and their locations change dynamically. Consequently, we need a mechanism that enables the clients of service to make requests to a dynamically changing set of ephemeral service instances.

## Implementations

There are two main service discovery patterns:

### Client-side discovery

![client-side-service-discovery](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/service-discovery/client-side-service-discovery.png)

In this approach, the client obtains the location of another service by querying a service registry which is responsible for managing and storing the network locations of all the services.

### Server-side discovery

![server-side-service-discovery](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/service-discovery/server-side-service-discovery.png)

In this approach, we use an intermediate component such as a load balancer. The client makes a request to the service via a load balancer which then forwards the request to an available service instance.

## Service Registry

A service registry is basically a database containing the network locations of service instances to which the clients can reach out. A Service Registry must be highly available and up-to-date.

## Service Registration

We also need a way to obtain service information, often known as service registration. Let's look at two possible service registration approaches:

### Self-Registration

When using the self-registration model, a service instance is responsible for registering and de-registering itself in the Service Registry. In addition, if necessary, a service instance sends heartbeat requests to keep its registration alive.

### Third-party Registration

The registry keeps track of changes to running instances by polling the deployment environment or subscribing to events. When it detects a newly available service instance, it records it in its database. The Service Registry also de-registers terminated service instances.

## Service mesh

Service-to-service communication is essential in a distributed application but routing this communication, both within and across application clusters, becomes increasingly complex as the number of services grows. Service mesh enables managed, observable, and secure communication between individual services. It works with a service discovery protocol to detect services. [Istio](https://istio.io/latest/about/service-mesh) and [envoy](https://www.envoyproxy.io) are some of the most commonly used service mesh technologies.

## Examples

Here are some commonly used service discovery infrastructure tools:

- [etcd](https://etcd.io)
- [Consul](https://www.consul.io)
- [Apache Thrift](https://thrift.apache.org)
- [Apache Zookeeper](https://zookeeper.apache.org)

# SLA, SLO, SLI

Let's briefly discuss SLA, SLO, and SLI. These are mostly related to the business and site reliability side of things but good to know nonetheless.

## Why are they important?

SLAs, SLOs, and SLIs allow companies to define, track and monitor the promises made for a service to its users. Together, SLAs, SLOs, and SLIs should help teams generate more user trust in their services with an added emphasis on continuous improvement to incident management and response processes.

## SLA

An SLA, or Service Level Agreement, is an agreement made between a company and its users of a given service. The SLA defines the different promises that the company makes to users regarding specific metrics, such as service availability.

_SLAs are often written by a company's business or legal team._

## SLO

An SLO, or Service Level Objective, is the promise that a company makes to users regarding a specific metric such as incident response or uptime. SLOs exist within an SLA as individual promises contained within the full user agreement. The SLO is the specific goal that the service must meet in order to comply with the SLA. SLOs should always be simple, clearly defined, and easily measured to determine whether or not the objective is being fulfilled.

## SLI

An SLI, or Service Level Indicator, is a key metric used to determine whether or not the SLO is being met. It is the measured value of the metric described within the SLO. In order to remain in compliance with the SLA, the SLI's value must always meet or exceed the value determined by the SLO.

# Disaster recovery

Disaster recovery (DR) is a process of regaining access and functionality of the infrastructure after events like a natural disaster, cyber attack, or even business disruptions.

Disaster recovery relies upon the replication of data and computer processing in an off-premises location not affected by the disaster. When servers go down because of a disaster, a business needs to recover lost data from a second location where the data is backed up. Ideally, an organization can transfer its computer processing to that remote location as well in order to continue operations.

_Disaster Recovery is often not actively discussed during system design interviews but it's important to have some basic understanding of this topic. You can learn more about disaster recovery from [AWS Well-Architected Framework](https://docs.aws.amazon.com/wellarchitected/latest/reliability-pillar/plan-for-disaster-recovery-dr.html)._

## Why is disaster recovery important?

Disaster recovery can have the following benefits:

- Minimize interruption and downtime
- Limit damages
- Fast restoration
- Better customer retention

## Terms

Let's discuss some important terms relevantly for disaster recovery:

![disaster-recovery](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/disaster-recovery/disaster-recovery.png)

### RTO

Recovery Time Objective (RTO) is the maximum acceptable delay between the interruption of service and restoration of service. This determines what is considered an acceptable time window when service is unavailable.

### RPO

Recovery Point Objective (RPO) is the maximum acceptable amount of time since the last data recovery point. This determines what is considered an acceptable loss of data between the last recovery point and the interruption of service.

## Strategies

A variety of disaster recovery (DR) strategies can be part of a disaster recovery plan.

### Back-up

This is the simplest type of disaster recovery and involves storing data off-site or on a removable drive.

### Cold Site

In this type of disaster recovery, an organization sets up basic infrastructure in a second site.

### Hot site

A hot site maintains up-to-date copies of data at all times. Hot sites are time-consuming to set up and more expensive than cold sites, but they dramatically reduce downtime.

# Virtual Machines (VMs) and Containers

Before we discuss virtualization vs containerization, let's learn what are virtual machines (VMs) and Containers.

## Virtual Machines (VM)

A Virtual Machine (VM) is a virtual environment that functions as a virtual computer system with its own CPU, memory, network interface, and storage, created on a physical hardware system. A software called a hypervisor separates the machine's resources from the hardware and provisions them appropriately so they can be used by the VM.

VMs are isolated from the rest of the system, and multiple VMs can exist on a single piece of hardware, like a server. They can be moved between host servers depending on the demand or to use resources more efficiently.

### What is a Hypervisor?

A Hypervisor sometimes called a Virtual Machine Monitor (VMM), isolates the operating system and resources from the virtual machines and enables the creation and management of those VMs. The hypervisor treats resources like CPU, memory, and storage as a pool of resources that can be easily reallocated between existing guests or new virtual machines.

### Why use a Virtual Machine?

Server consolidation is a top reason to use VMs. Most operating system and application deployments only use a small amount of the physical resources available. By virtualizing our servers, we can place many virtual servers onto each physical server to improve hardware utilization. This keeps us from needing to purchase additional physical resources.

A VM provides an environment that is isolated from the rest of a system, so whatever is running inside a VM won't interfere with anything else running on the host hardware. Because VMs are isolated, they are a good option for testing new applications or setting up a production environment. We can also run a single-purpose VM to support a specific use case.

## Containers

A container is a standard unit of software that packages up code and all its dependencies such as specific versions of runtimes and libraries so that the application runs quickly and reliably from one computing environment to another. Containers offer a logical packaging mechanism in which applications can be abstracted from the environment in which they actually run. This decoupling allows container-based applications to be deployed easily and consistently, regardless of the target environment.

### Why do we need containers?

Let's discuss some advantages of using containers:

**Separation of responsibility**

Containerization provides a clear separation of responsibility, as developers focus on application logic and dependencies, while operations teams can focus on deployment and management.

**Workload portability**

Containers can run virtually anywhere, greatly easing development and deployment.

**Application isolation**

Containers virtualize CPU, memory, storage, and network resources at the operating system level, providing developers with a view of the OS logically isolated from other applications.

**Agile development**

Containers allow developers to move much more quickly by avoiding concerns about dependencies and environments.

**Efficient operations**

Containers are lightweight and allow us to use just the computing resources we need.

## Virtualization vs Containerization

![virtualization-vs-containerization](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/virtual-machines-and-containers/virtualization-vs-containerization.png)

In traditional virtualization, a hypervisor virtualizes physical hardware. The result is that each virtual machine contains a guest OS, a virtual copy of the hardware that the OS requires to run, and an application and its associated libraries and dependencies.

Instead of virtualizing the underlying hardware, containers virtualize the operating system so each container contains only the application and its dependencies making them much more lightweight than VMs. Containers also share the OS kernel and use a fraction of the memory VMs require.

# OAuth 2.0 and OpenID Connect (OIDC)

## OAuth 2.0

OAuth 2.0, which stands for Open Authorization, is a standard designed to provide consented access to resources on behalf of the user, without ever sharing the user's credentials. OAuth 2.0 is an authorization protocol and not an authentication protocol, it is designed primarily as a means of granting access to a set of resources, for example, remote APIs or user's data.

### Concepts

The OAuth 2.0 protocol defines the following entities:

- **Resource Owner**: The user or system that owns the protected resources and can grant access to them.
- **Client**: The client is the system that requires access to the protected resources.
- **Authorization Server**: This server receives requests from the Client for Access Tokens and issues them upon successful authentication and consent by the Resource Owner.
- **Resource Server**: A server that protects the user's resources and receives access requests from the Client. It accepts and validates an Access Token from the Client and returns the appropriate resources.
- **Scopes**: They are used to specify exactly the reason for which access to resources may be granted. Acceptable scope values, and which resources they relate to, are dependent on the Resource Server.
- **Access Token**: A piece of data that represents the authorization to access resources on behalf of the end-user.

### How does OAuth 2.0 work?

Let's learn how OAuth 2.0 works:

![oauth2](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/oauth2-and-openid-connect/oauth2.png)

1. The client requests authorization from the Authorization Server, supplying the client id and secret as identification. It also provides the scopes and an endpoint URI to send the Access Token or the Authorization Code.
2. The Authorization Server authenticates the client and verifies that the requested scopes are permitted.
3. The resource owner interacts with the authorization server to grant access.
4. The Authorization Server redirects back to the client with either an Authorization Code or Access Token, depending on the grant type. A Refresh Token may also be returned.
5. With the Access Token, the client can request access to the resource from the Resource Server.

### Disadvantages

Here are the most common disadvantages of OAuth 2.0:

- Lacks built-in security features.
- No standard implementation.
- No common set of scopes.

## OpenID Connect

OAuth 2.0 is designed only for _authorization_, for granting access to data and features from one application to another. OpenID Connect (OIDC) is a thin layer that sits on top of OAuth 2.0 that adds login and profile information about the person who is logged in.

When an Authorization Server supports OIDC, it is sometimes called an identity provider (IdP), since it provides information about the Resource Owner back to the Client. OpenID Connect is relatively new, resulting in lower adoption and industry implementation of best practices compared to OAuth.

### Concepts

The OpenID Connect (OIDC) protocol defines the following entities:

- **Relying Party**: The current application.
- **OpenID Provider**: This is essentially an intermediate service that provides a one-time code to the Relying Party.
- **Token Endpoint**: A web server that accepts the One-Time Code (OTC) and provides an access code that's valid for an hour. The main difference between OIDC and OAuth 2.0 is that the token is provided using JSON Web Token (JWT).
- **UserInfo Endpoint**: The Relying Party communicates with this endpoint, providing a secure token and receiving information about the end-user

Both OAuth 2.0 and OIDC are easy to implement and are JSON based, which is supported by most web and mobile applications. However, the OpenID Connect (OIDC) specification is more strict than that of basic OAuth.

# Single Sign-On (SSO)

Single Sign-On (SSO) is an authentication process in which a user is provided access to multiple applications or websites by using only a single set of login credentials. This prevents the need for the user to log separately into the different applications.

The user credentials and other identifying information are stored and managed by a centralized system called Identity Provider (IdP). The Identity Provider is a trusted system that provides access to other websites and applications.

Single Sign-On (SSO) based authentication systems are commonly used in enterprise environments where employees require access to multiple applications of their organizations.

## Components

Let's discuss some key components of Single Sign-On (SSO).

### Identity Provider (IdP)

User Identity information is stored and managed by a centralized system called Identity Provider (IdP). The Identity Provider authenticates the user and provides access to the service provider.

The identity provider can directly authenticate the user by validating a username and password or by validating an assertion about the user's identity as presented by a separate identity provider. The identity provider handles the management of user identities in order to free the service provider from this responsibility.

### Service Provider

A service provider provides services to the end-user. They rely on identity providers to assert the identity of a user, and typically certain attributes about the user are managed by the identity provider. Service providers may also maintain a local account for the user along with attributes that are unique to their service.

### Identity Broker

An identity broker acts as an intermediary that connects multiple service providers with various different identity providers. Using Identity Broker, we can perform single sign-on over any application without the hassle of the protocol it follows.

## SAML

Security Assertion Markup Language is an open standard that allows clients to share security information about identity, authentication, and permission across different systems. SAML is implemented with the Extensible Markup Language (XML) standard for sharing data.

SAML specifically enables identity federation, making it possible for identity providers (IdPs) to seamlessly and securely pass authenticated identities and their attributes to service providers.

## How does SSO work?

Now, let's discuss how Single Sign-On works:

![sso](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/single-sign-on/sso.png)

1. The user requests a resource from their desired application.
2. The application redirects the user to the Identity Provider (IdP) for authentication.
3. The user signs in with their credentials (usually, username and password).
4. Identity Provider (IdP) sends a Single Sign-On response back to the client application.
5. The application grants access to the user.

## SAML vs OAuth 2.0 and OpenID Connect (OIDC)

There are many differences between SAML, OAuth, and OIDC. SAML uses XML to pass messages, while OAuth and OIDC use JSON. OAuth provides a simpler experience, while SAML is geared towards enterprise security.

OAuth and OIDC use RESTful communication extensively, which is why mobile, and modern web applications find OAuth and OIDC a better experience for the user. SAML, on the other hand, drops a session cookie in a browser that allows a user to access certain web pages. This is great for short-lived workloads.

OIDC is developer-friendly and simpler to implement, which broadens the use cases for which it might be implemented. It can be implemented from scratch pretty fast, via freely available libraries in all common programming languages. SAML can be complex to install and maintain, which only enterprise-size companies can handle well.

OpenID Connect is essentially a layer on top of the OAuth framework. Therefore, it can offer a built-in layer of permission that asks a user to agree to what the service provider might access. Although SAML is also capable of allowing consent flow, it achieves this by hard-coding carried out by a developer and not as part of its protocol.

_Both of these authentication protocols are good at what they do. As always, a lot depends on our specific use cases and target audience._

## Advantages

Following are the benefits of using Single Sign-On:

- Ease of use as users only need to remember one set of credentials.
- Ease of access without having to go through a lengthy authorization process.
- Enforced security and compliance to protect sensitive data.
- Simplifying the management with reduced IT support cost and admin time.

## Disadvantages

Here are some disadvantages of Single Sign-On:

- Single Password Vulnerability, if the main SSO password gets compromised, all the supported applications get compromised.
- The authentication process using Single Sign-On is slower than traditional authentication as every application has to request the SSO provider for verification.

## Examples

These are some commonly used Identity Providers (IdP):

- [Okta](https://www.okta.com)
- [Google](https://cloud.google.com/architecture/identity/single-sign-on)
- [Auth0](https://auth0.com)
- [OneLogin](https://www.onelogin.com)

# SSL, TLS, mTLS

Let's briefly discuss some important communication security protocols such as SSL, TLS, and mTLS. I would say that from a _"big picture"_ system design perspective, this topic is not very important but still good to know about.

## SSL

SSL stands for Secure Sockets Layer, and it refers to a protocol for encrypting and securing communications that take place on the internet. It was first developed in 1995 but since has been deprecated in favor of TLS (Transport Layer Security).

### Why is it called an SSL certificate if it is deprecated?

Most major certificate providers still refer to certificates as SSL certificates, which is why the naming convention persists.

### Why was SSL so important?

Originally, data on the web was transmitted in plaintext that anyone could read if they intercepted the message. SSL was created to correct this problem and protect user privacy. By encrypting any data that goes between the user and a web server, SSL also stops certain kinds of cyber attacks by preventing attackers from tampering with data in transit.

## TLS

Transport Layer Security, or TLS, is a widely adopted security protocol designed to facilitate privacy and data security for communications over the internet. TLS evolved from a previous encryption protocol called Secure Sockets Layer (SSL). A primary use case of TLS is encrypting the communication between web applications and servers.

There are three main components to what the TLS protocol accomplishes:

- **Encryption**: hides the data being transferred from third parties.
- **Authentication**: ensures that the parties exchanging information are who they claim to be.
- **Integrity**: verifies that the data has not been forged or tampered with.

## mTLS

Mutual TLS, or mTLS, is a method for mutual authentication. mTLS ensures that the parties at each end of a network connection are who they claim to be by verifying that they both have the correct private key. The information within their respective TLS certificates provides additional verification.

### Why use mTLS?

mTLS helps ensure that the traffic is secure and trusted in both directions between a client and server. This provides an additional layer of security for users who log in to an organization's network or applications. It also verifies connections with client devices that do not follow a login process, such as Internet of Things (IoT) devices.

Nowadays, mTLS is commonly used by microservices or distributed systems in a [zero trust security model](https://en.wikipedia.org/wiki/Zero_trust_security_model) to verify each other.

# System Design Interviews

System design is a very extensive topic and system design interviews are designed to evaluate your capability to produce technical solutions to abstract problems, as such, they're not designed for a specific answer. The unique aspect of system design interviews is the two-way nature between the candidate and the interviewer.

Expectations are quite different at different engineering levels as well. This is because someone with a lot of practical experience will approach it quite differently from someone who's new in the industry. As a result, it's hard to come up with a single strategy that will help us stay organized during the interview.

Let's look at some common strategies for system design interviews:

## Requirements clarifications

System design interview questions, by nature, are vague or abstract. Asking questions about the exact scope of the problem, and clarifying functional requirements early in the interview is essential. Usually, requirements are divided into three parts:

### Functional requirements

These are the requirements that the end user specifically demands as basic functionalities that the system should offer. All these functionalities need to be necessarily incorporated into the system as part of the contract.

For example:

- "What are the features that we need to design for this system?"
- "What are the edge cases we need to consider, if any, in our design?"

### Non-functional requirements

These are the quality constraints that the system must satisfy according to the project contract. The priority or extent to which these factors are implemented varies from one project to another. They are also called non-behavioral requirements. For example, portability, maintainability, reliability, scalability, security, etc.

For example:

- "Each request should be processed with the minimum latency"
- "System should be highly available"

### Extended requirements

These are basically "nice to have" requirements that might be out of the scope of the system.

For example:

- "Our system should record metrics and analytics"
- "Service health and performance monitoring?"

## Estimation and Constraints

Estimate the scale of the system we're going to design. It is important to ask questions such as:

- "What is the desired scale that this system will need to handle?"
- "What is the read/write ratio of our system?"
- "How many requests per second?"
- "How much storage will be needed?"

These questions will help us scale our design later.

## Data model design

Once we have the estimations, we can start with defining the database schema. Doing so in the early stages of the interview would help us to understand the data flow which is the core of every system. In this step, we basically define all the entities and relationships between them.

- "What are the different entities in the system?"
- "What are the relationships between these entities?"
- "How many tables do we need?"
- "Is NoSQL a better choice here?"

## API design

Next, we can start designing APIs for the system. These APIs will help us define the expectations from the system explicitly. We don't have to write any code, just a simple interface defining the API requirements such as parameters, functions, classes, types, entities, etc.

For example:

```tsx
createUser(name: string, email: string): User
```

It is advised to keep the interface as simple as possible and come back to it later when covering extended requirements.

## High-level component design

Now we have established our data model and API design, it's time to identify system components (such as Load Balancers, API Gateway, etc.) that are needed to solve our problem and draft the first design of our system.

- "Is it best to design a monolithic or a microservices architecture?"
- "What type of database should we use?"

Once we have a basic diagram, we can start discussing with the interviewer how the system will work from the client's perspective.

## Detailed design

Now it's time to go into detail about the major components of the system we designed. As always discuss with the interviewer which component may need further improvements.

Here is a good opportunity to demonstrate your experience in the areas of your expertise. Present different approaches, advantages, and disadvantages. Explain your design decisions, and back them up with examples. This is also a good time to discuss any additional features the system might be able to support, though this is optional.

- "How should we partition our data?"
- "What about load distribution?"
- "Should we use cache?"
- "How will we handle a sudden spike in traffic?"

Also, try not to be too opinionated about certain technologies, statements like "I believe that NoSQL databases are just better, SQL databases are not scalable" reflect poorly. As someone who has interviewed a lot of people over the years, my two cents here would be to be humble about what you know and what you do not. Use your existing knowledge with examples to navigate this part of the interview.

## Identify and resolve bottlenecks

Finally, it's time to discuss bottlenecks and approaches to mitigate them. Here are some important questions to ask:

- "Do we have enough database replicas?"
- "Is there any single point of failure?"
- "Is database sharding required?"
- "How can we make our system more robust?"
- "How to improve the availability of our cache?"

Make sure to read the engineering blog of the company you're interviewing with. This will help you get a sense of what technology stack they're using and which problems are important to them.

# URL Shortener

Let's design a URL shortener, similar to services like [Bitly](https://bitly.com), [TinyURL](https://tinyurl.com/app).

## What is a URL Shortener?

A URL shortener service creates an alias or a short URL for a long URL. Users are redirected to the original URL when they visit these short links.

For example, the following long URL can be changed to a shorter URL.

**Long URL**: [https://karanpratapsingh.com/courses/system-design/url-shortener](https://karanpratapsingh.com/courses/system-design/url-shortener)

**Short URL**: [https://bit.ly/3I71d3o](https://bit.ly/3I71d3o)

## Why do we need a URL shortener?

URL shortener saves space in general when we are sharing URLs. Users are also less likely to mistype shorter URLs. Moreover, we can also optimize links across devices, this allows us to track individual links.

## Requirements

Our URL shortening system should meet the following requirements:

### Functional requirements

- Given a URL, our service should generate a _shorter and unique_ alias for it.
- Users should be redirected to the original URL when they visit the short link.
- Links should expire after a default timespan.

### Non-functional requirements

- High availability with minimal latency.
- The system should be scalable and efficient.

### Extended requirements

- Prevent abuse of services.
- Record analytics and metrics for redirections.

## Estimation and Constraints

Let's start with the estimation and constraints.

_Note: Make sure to check any scale or traffic related assumptions with your interviewer._

### Traffic

This will be a read-heavy system, so let's assume a `100:1` read/write ratio with 100 million links generated per month.

**Reads/Writes Per month**

For reads per month:

$$
100 \times 100 \space million = 10 \space billion/month
$$

Similarly for writes:

$$
1 \times 100 \space million = 100 \space million/month
$$

**What would be Requests Per Second (RPS) for our system?**

100 million requests per month translate into 40 requests per second.

$$
\frac{100 \space million}{(30 \space days \times 24 \space hrs \times 3600 \space seconds)} = \sim 40 \space URLs/second
$$

And with a `100:1` read/write ratio, the number of redirections will be:

$$
100 \times 40 \space URLs/second = 4000 \space requests/second
$$

### Bandwidth

Since we expect about 40 URLs every second, and if we assume each request is of size 500 bytes then the total incoming data for write requests would be:

$$
40 \times 500 \space bytes = 20 \space KB/second
$$

Similarly, for the read requests, since we expect about 4K redirections, the total outgoing data would be:

$$
4000 \space URLs/second \times 500 \space bytes = \sim 2 \space MB/second
$$

### Storage

For storage, we will assume we store each link or record in our database for 10 years. Since we expect around 100M new requests every month, the total number of records we will need to store would be:

$$
100 \space million \times 10\space years \times 12 \space months = 12 \space billion
$$

Like earlier, if we assume each stored record will be approximately 500 bytes. We will need around 6TB of storage:

$$
12 \space billion \times 500 \space bytes = 6 \space TB
$$

### Cache

For caching, we will follow the classic [Pareto principle](https://en.wikipedia.org/wiki/Pareto_principle) also known as the 80/20 rule. This means that 80% of the requests are for 20% of the data, so we can cache around 20% of our requests.

Since we get around 4K read or redirection requests each second, this translates into 350M requests per day.

$$
4000 \space URLs/second \times 24 \space hours \times 3600 \space seconds = \sim 350 \space million \space requests/day
$$

Hence, we will need around 35GB of memory per day.

$$
20 \space percent \times 350 \space million \times 500 \space bytes = 35 \space GB/day
$$

### High-level estimate

Here is our high-level estimate:

| Type                 | Estimate   |
| -------------------- | ---------- |
| Writes (New URLs)    | 40/s       |
| Reads (Redirection)  | 4K/s       |
| Bandwidth (Incoming) | 20 KB/s    |
| Bandwidth (Outgoing) | 2 MB/s     |
| Storage (10 years)   | 6 TB       |
| Memory (Caching)     | ~35 GB/day |

## Data model design

Next, we will focus on the data model design. Here is our database schema:

![url-shortener-datamodel](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/url-shortener/url-shortener-datamodel.png)

Initially, we can get started with just two tables:

**users**

Stores user's details such as `name`, `email`, `createdAt`, etc.

**urls**

Contains the new short URL's properties such as `expiration`, `hash`, `originalURL`, and `userID` of the user who created the short URL. We can also use the `hash` column as an [index](https://karanpratapsingh.com/courses/system-design/indexes) to improve the query performance.

### What kind of database should we use?

Since the data is not strongly relational, NoSQL databases such as [Amazon DynamoDB](https://aws.amazon.com/dynamodb), [Apache Cassandra](https://cassandra.apache.org/_/index.html), or [MongoDB](https://www.mongodb.com) will be a better choice here, if we do decide to use an SQL database then we can use something like [Azure SQL Database](https://azure.microsoft.com/en-in/products/azure-sql/database) or [Amazon RDS](https://aws.amazon.com/rds).

_For more details, refer to [SQL vs NoSQL](https://karanpratapsingh.com/courses/system-design/sql-vs-nosql-databases)._

## API design

Let us do a basic API design for our services:

### Create URL

This API should create a new short URL in our system given an original URL.

```tsx
createURL(apiKey: string, originalURL: string, expiration?: Date): string
```

**Parameters**

API Key (`string`): API key provided by the user.

Original URL (`string`): Original URL to be shortened.

Expiration (`Date`): Expiration date of the new URL _(optional)_.

**Returns**

Short URL (`string`): New shortened URL.

### Get URL

This API should retrieve the original URL from a given short URL.

```tsx
getURL(apiKey: string, shortURL: string): string
```

**Parameters**

API Key (`string`): API key provided by the user.

Short URL (`string`): Short URL mapped to the original URL.

**Returns**

Original URL (`string`): Original URL to be retrieved.

### Delete URL

This API should delete a given shortURL from our system.

```tsx
deleteURL(apiKey: string, shortURL: string): boolean
```

**Parameters**

API Key (`string`): API key provided by the user.

Short URL (`string`): Short URL to be deleted.

**Returns**

Result (`boolean`): Represents whether the operation was successful or not.

### Why do we need an API key?

As you must've noticed, we're using an API key to prevent abuse of our services. Using this API key we can limit the users to a certain number of requests per second or minute. This is quite a standard practice for developer APIs and should cover our extended requirement.

## High-level design

Now let us do a high-level design of our system.

### URL Encoding

Our system's primary goal is to shorten a given URL, let's look at different approaches:

**Base62 Approach**

In this approach, we can encode the original URL using [Base62](https://en.wikipedia.org/wiki/Base62) which consists of the capital letters A-Z, the lower case letters a-z, and the numbers 0-9.

$$
Number \space of \space URLs = 62^N
$$

Where,

`N`: Number of characters in the generated URL.

So, if we want to generate a URL that is 7 characters long, we will generate ~3.5 trillion different URLs.

$$
\begin{gather*}
62^5 = \sim 916 \space million \space URLs \\
62^6 = \sim 56.8 \space billion \space URLs \\
62^7 = \sim 3.5 \space trillion \space URLs
\end{gather*}
$$

This is the simplest solution here, but it does not guarantee non-duplicate or collision-resistant keys.

**MD5 Approach**

The [MD5 message-digest algorithm](https://en.wikipedia.org/wiki/MD5) is a widely used hash function producing a 128-bit hash value (or 32 hexadecimal digits). We can use these 32 hexadecimal digits for generating 7 characters long URL.

$$
MD5(original\_url) \rightarrow base62encode \rightarrow hash
$$

However, this creates a new issue for us, which is duplication and collision. We can try to re-compute the hash until we find a unique one but that will increase the overhead of our systems. It's better to look for more scalable approaches.

**Counter Approach**

In this approach, we will start with a single server which will maintain the count of the keys generated. Once our service receives a request, it can reach out to the counter which returns a unique number and increments the counter. When the next request comes the counter again returns the unique number and this goes on.

$$
Counter(0-3.5 \space trillion) \rightarrow base62encode \rightarrow hash
$$

The problem with this approach is that it can quickly become a single point for failure. And if we run multiple instances of the counter we can have collision as it's essentially a distributed system.

To solve this issue we can use a distributed system manager such as [Zookeeper](https://zookeeper.apache.org) which can provide distributed synchronization. Zookeeper can maintain multiple ranges for our servers.

$$
\begin{align*}
& Range \space 1: \space 1 \rightarrow 1,000,000 \\
& Range \space 2: \space 1,000,001 \rightarrow 2,000,000 \\
& Range \space 3: \space 2,000,001 \rightarrow 3,000,000 \\
& ...
\end{align*}
$$

Once a server reaches its maximum range Zookeeper will assign an unused counter range to the new server. This approach can guarantee non-duplicate and collision-resistant URLs. Also, we can run multiple instances of Zookeeper to remove the single point of failure.

### Key Generation Service (KGS)

As we discussed, generating a unique key at scale without duplication and collisions can be a bit of a challenge. To solve this problem, we can create a standalone Key Generation Service (KGS) that generates a unique key ahead of time and stores it in a separate database for later use. This approach can make things simple for us.

**How to handle concurrent access?**

Once the key is used, we can mark it in the database to make sure we don't reuse it, however, if there are multiple server instances reading data concurrently, two or more servers might try to use the same key.

The easiest way to solve this would be to store keys in two tables. As soon as a key is used, we move it to a separate table with appropriate locking in place. Also, to improve reads, we can keep some of the keys in memory.

**KGS database estimations**

As per our discussion, we can generate up to ~56.8 billion unique 6 character long keys which will result in us having to store 300 GB of keys.

$$
6 \space characters \times 56.8 \space billion = \sim 390 \space GB
$$

While 390 GB seems like a lot for this simple use case, it is important to remember this is for the entirety of our service lifetime and the size of the keys database would not increase like our main database.

### Caching

Now, let's talk about [caching](https://karanpratapsingh.com/courses/system-design/caching). As per our estimations, we will require around ~35 GB of memory per day to cache 20% of the incoming requests to our services. For this use case, we can use [Redis](https://redis.io) or [Memcached](https://memcached.org) servers alongside our API server.

_For more details, refer to [caching](https://karanpratapsingh.com/courses/system-design/caching)._

### Design

Now that we have identified some core components, let's do the first draft of our system design.

![url-shortener-basic-design](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/url-shortener/url-shortener-basic-design.png)

Here's how it works:

**Creating a new URL**

1. When a user creates a new URL, our API server requests a new unique key from the Key Generation Service (KGS).
2. Key Generation Service provides a unique key to the API server and marks the key as used.
3. API server writes the new URL entry to the database and cache.
4. Our service returns an HTTP 201 (Created) response to the user.

**Accessing a URL**

1. When a client navigates to a certain short URL, the request is sent to the API servers.
2. The request first hits the cache, and if the entry is not found there then it is retrieved from the database and an HTTP 301 (Redirect) is issued to the original URL.
3. If the key is still not found in the database, an HTTP 404 (Not found) error is sent to the user.

## Detailed design

It's time to discuss the finer details of our design.

### Data Partitioning

To scale out our databases we will need to partition our data. Horizontal partitioning (aka [Sharding](https://karanpratapsingh.com/courses/system-design/sharding)) can be a good first step. We can use partitions schemes such as:

- Hash-Based Partitioning
- List-Based Partitioning
- Range Based Partitioning
- Composite Partitioning

The above approaches can still cause uneven data and load distribution, we can solve this using [Consistent hashing](https://karanpratapsingh.com/courses/system-design/consistent-hashing).

_For more details, refer to [Sharding](https://karanpratapsingh.com/courses/system-design/sharding) and [Consistent Hashing](https://karanpratapsingh.com/courses/system-design/consistent-hashing)._

### Database cleanup

This is more of a maintenance step for our services and depends on whether we keep the expired entries or remove them. If we do decide to remove expired entries, we can approach this in two different ways:

**Active cleanup**

In active cleanup, we will run a separate cleanup service which will periodically remove expired links from our storage and cache. This will be a very lightweight service like a [cron job](https://en.wikipedia.org/wiki/Cron).

**Passive cleanup**

For passive cleanup, we can remove the entry when a user tries to access an expired link. This can ensure a lazy cleanup of our database and cache.

### Cache

Now let us talk about [caching](https://karanpratapsingh.com/courses/system-design/caching).

**Which cache eviction policy to use?**

As we discussed before, we can use solutions like [Redis](https://redis.io) or [Memcached](https://memcached.org) and cache 20% of the daily traffic but what kind of cache eviction policy would best fit our needs?

[Least Recently Used (LRU)](<https://en.wikipedia.org/wiki/Cache_replacement_policies#Least_recently_used_(LRU)>) can be a good policy for our system. In this policy, we discard the least recently used key first.

**How to handle cache miss?**

Whenever there is a cache miss, our servers can hit the database directly and update the cache with the new entries.

### Metrics and Analytics

Recording analytics and metrics is one of our extended requirements. We can store and update metadata like visitor's country, platform, the number of views, etc alongside the URL entry in our database.

### Security

For security, we can introduce private URLs and authorization. A separate table can be used to store user ids that have permission to access a specific URL. If a user does not have proper permissions, we can return an HTTP 401 (Unauthorized) error.

We can also use an [API Gateway](https://karanpratapsingh.com/courses/system-design/api-gateway) as they can support capabilities like authorization, rate limiting, and load balancing out of the box.

## Identify and resolve bottlenecks

![url-shortener-advanced-design](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/url-shortener/url-shortener-advanced-design.png)

Let us identify and resolve bottlenecks such as single points of failure in our design:

- "What if the API service or Key Generation Service crashes?"
- "How will we distribute our traffic between our components?"
- "How can we reduce the load on our database?"
- "What if the key database used by KGS fails?"
- "How to improve the availability of our cache?"

To make our system more resilient we can do the following:

- Running multiple instances of our Servers and Key Generation Service.
- Introducing [load balancers](https://karanpratapsingh.com/courses/system-design/load-balancing) between clients, servers, databases, and cache servers.
- Using multiple read replicas for our database as it's a read-heavy system.
- Standby replica for our key database in case it fails.
- Multiple instances and replicas for our distributed cache.

# WhatsApp

Let's design a [WhatsApp](https://whatsapp.com) like instant messaging service, similar to services like [Facebook Messenger](https://www.messenger.com), and [WeChat](https://www.wechat.com).

## What is WhatsApp?

WhatsApp is a chat application that provides instant messaging services to its users. It is one of the most used mobile applications on the planet, connecting over 2 billion users in 180+ countries. WhatsApp is also available on the web.

## Requirements

Our system should meet the following requirements:

### Functional requirements

- Should support one-on-one chat.
- Group chats (max 100 people).
- Should support file sharing (image, video, etc.).

### Non-functional requirements

- High availability with minimal latency.
- The system should be scalable and efficient.

### Extended requirements

- Sent, Delivered, and Read receipts of the messages.
- Show the last seen time of users.
- Push notifications.

## Estimation and Constraints

Let's start with the estimation and constraints.

_Note: Make sure to check any scale or traffic-related assumptions with your interviewer._

### Traffic

Let us assume we have 50 million daily active users (DAU) and on average each user sends at least 10 messages to 4 different people every day. This gives us 2 billion messages per day.

$$
50 \space million \times 40 \space messages = 2 \space billion/day
$$

Messages can also contain media such as images, videos, or other files. We can assume that 5 percent of messages are media files shared by the users, which gives us additional 100 million files we would need to store.

$$
5 \space percent \times 2 \space billion = 100 \space million/day
$$

**What would be Requests Per Second (RPS) for our system?**

2 billion requests per day translate into 24K requests per second.

$$
\frac{2 \space billion}{(24 \space hrs \times 3600 \space seconds)} = \sim 24K \space requests/second
$$

### Storage

If we assume each message on average is 100 bytes, we will require about 200 GB of database storage every day.

$$
2 \space billion \times 100 \space bytes = \sim 200 \space GB/day
$$

As per our requirements, we also know that around 5 percent of our daily messages (100 million) are media files. If we assume each file is 100 KB on average, we will require 10 TB of storage every day.

$$
100 \space million \times 100 \space KB = 10 \space TB/day
$$

And for 10 years, we will require about 38 PB of storage.

$$
(10 \space TB + 0.2 \space TB) \times 10 \space years \times 365 \space days = \sim 38 \space PB
$$

### Bandwidth

As our system is handling 10.2 TB of ingress every day, we will require a minimum bandwidth of around 120 MB per second.

$$
\frac{10.2 \space TB}{(24 \space hrs \times 3600 \space seconds)} = \sim 120 \space MB/second
$$

### High-level estimate

Here is our high-level estimate:

| Type                      | Estimate   |
| ------------------------- | ---------- |
| Daily active users (DAU)  | 50 million |
| Requests per second (RPS) | 24K/s      |
| Storage (per day)         | ~10.2 TB   |
| Storage (10 years)        | ~38 PB     |
| Bandwidth                 | ~120 MB/s  |

## Data model design

This is the general data model which reflects our requirements.

![whatsapp-datamodel](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/whatsapp/whatsapp-datamodel.png)

We have the following tables:

**users**

This table will contain a user's information such as `name`, `phoneNumber`, and other details.

**messages**

As the name suggests, this table will store messages with properties such as `type` (text, image, video, etc.), `content`, and timestamps for message delivery. The message will also have a corresponding `chatID` or `groupID`.

**chats**

This table basically represents a private chat between two users and can contain multiple messages.

**users_chats**

This table maps users and chats as multiple users can have multiple chats (N:M relationship) and vice versa.

**groups**

This table represents a group made up of multiple users.

**users_groups**

This table maps users and groups as multiple users can be a part of multiple groups (N:M relationship) and vice versa.

### What kind of database should we use?

While our data model seems quite relational, we don't necessarily need to store everything in a single database, as this can limit our scalability and quickly become a bottleneck.

We will split the data between different services each having ownership over a particular table. Then we can use a relational database such as [PostgreSQL](https://www.postgresql.org) or a distributed NoSQL database such as [Apache Cassandra](https://cassandra.apache.org/_/index.html) for our use case.

## API design

Let us do a basic API design for our services:

### Get all chats or groups

This API will get all chats or groups for a given `userID`.

```tsx
getAll(userID: UUID): Chat[] | Group[]
```

**Parameters**

User ID (`UUID`): ID of the current user.

**Returns**

Result (`Chat[] | Group[]`): All the chats and groups the user is a part of.

### Get messages

Get all messages for a user given the `channelID` (chat or group id).

```tsx
getMessages(userID: UUID, channelID: UUID): Message[]
```

**Parameters**

User ID (`UUID`): ID of the current user.

Channel ID (`UUID`): ID of the channel (chat or group) from which messages need to be retrieved.

**Returns**

Messages (`Message[]`): All the messages in a given chat or group.

### Send message

Send a message from a user to a channel (chat or group).

```tsx
sendMessage(userID: UUID, channelID: UUID, message: Message): boolean
```

**Parameters**

User ID (`UUID`): ID of the current user.

Channel ID (`UUID`): ID of the channel (chat or group) user wants to send a message to.

Message (`Message`): The message (text, image, video, etc.) that the user wants to send.

**Returns**

Result (`boolean`): Represents whether the operation was successful or not.

### Join or leave a channel

Allows the user to join or leave a channel (chat or group).

```tsx
joinGroup(userID: UUID, channelID: UUID): boolean
leaveGroup(userID: UUID, channelID: UUID): boolean
```

**Parameters**

User ID (`UUID`): ID of the current user.

Channel ID (`UUID`): ID of the channel (chat or group) the user wants to join or leave.

**Returns**

Result (`boolean`): Represents whether the operation was successful or not.

## High-level design

Now let us do a high-level design of our system.

### Architecture

We will be using [microservices architecture](https://karanpratapsingh.com/courses/system-design/monoliths-microservices#microservices) since it will make it easier to horizontally scale and decouple our services. Each service will have ownership of its own data model. Let's try to divide our system into some core services.

**User Service**

This is an HTTP-based service that handles user-related concerns such as authentication and user information.

**Chat Service**

The chat service will use WebSockets and establish connections with the client to handle chat and group message-related functionality. We can also use cache to keep track of all the active connections sort of like sessions which will help us determine if the user is online or not.

**Notification Service**

This service will simply send push notifications to the users. It will be discussed in detail separately.

**Presence Service**

The presence service will keep track of the _last seen_ status of all users. It will be discussed in detail separately.

**Media service**

This service will handle the media (images, videos, files, etc.) uploads. It will be discussed in detail separately.

**What about inter-service communication and service discovery?**

Since our architecture is microservices-based, services will be communicating with each other as well. Generally, REST or HTTP performs well but we can further improve the performance using [gRPC](https://karanpratapsingh.com/courses/system-design/rest-graphql-grpc#grpc) which is more lightweight and efficient.

[Service discovery](https://karanpratapsingh.com/courses/system-design/service-discovery) is another thing we will have to take into account. We can also use a service mesh that enables managed, observable, and secure communication between individual services.

_Note: Learn more about [REST, GraphQL, gRPC](https://karanpratapsingh.com/courses/system-design/rest-graphql-grpc) and how they compare with each other._

### Real-time messaging

How do we efficiently send and receive messages? We have two different options:

**Pull model**

The client can periodically send an HTTP request to servers to check if there are any new messages. This can be achieved via something like [Long polling](https://karanpratapsingh.com/courses/system-design/long-polling-websockets-server-sent-events#long-polling).

**Push model**

The client opens a long-lived connection with the server and once new data is available it will be pushed to the client. We can use [WebSockets](https://karanpratapsingh.com/courses/system-design/long-polling-websockets-server-sent-events#websockets) or [Server-Sent Events (SSE)](https://karanpratapsingh.com/courses/system-design/long-polling-websockets-server-sent-events#server-sent-events-sse) for this.

The pull model approach is not scalable as it will create unnecessary request overhead on our servers and most of the time the response will be empty, thus wasting our resources. To minimize latency, using the push model with [WebSockets](https://karanpratapsingh.com/courses/system-design/long-polling-websockets-server-sent-events#websockets) is a better choice because then we can push data to the client once it's available without any delay, given the connection is open with the client. Also, WebSockets provide full-duplex communication, unlike [Server-Sent Events (SSE)](https://karanpratapsingh.com/courses/system-design/long-polling-websockets-server-sent-events#server-sent-events-sse) which are only unidirectional.

_Note: Learn more about [Long polling, WebSockets, Server-Sent Events (SSE)](https://karanpratapsingh.com/courses/system-design/long-polling-websockets-server-sent-events)._

### Last seen

To implement the last seen functionality, we can use a [heartbeat](<https://en.wikipedia.org/wiki/Heartbeat_(computing)>) mechanism, where the client can periodically ping the servers indicating its liveness. Since this needs to be as low overhead as possible, we can store the last active timestamp in the cache as follows:

| Key    | Value               |
| ------ | ------------------- |
| User A | 2022-07-01T14:32:50 |
| User B | 2022-07-05T05:10:35 |
| User C | 2022-07-10T04:33:25 |

This will give us the last time the user was active. This functionality will be handled by the presence service combined with [Redis](https://redis.io) or [Memcached](https://memcached.org) as our cache.

Another way to implement this is to track the latest action of the user, once the last activity crosses a certain threshold, such as _"user hasn't performed any action in the last 30 seconds"_, we can show the user as offline and last seen with the last recorded timestamp. This will be more of a lazy update approach and might benefit us over heartbeat in certain cases.

### Notifications

Once a message is sent in a chat or a group, we will first check if the recipient is active or not, we can get this information by taking the user's active connection and last seen into consideration.

If the recipient is not active, the chat service will add an event to a [message queue](https://karanpratapsingh.com/courses/system-design/message-queues) with additional metadata such as the client's device platform which will be used to route the notification to the correct platform later on.

The notification service will then consume the event from the message queue and forward the request to [Firebase Cloud Messaging (FCM)](https://firebase.google.com/docs/cloud-messaging) or [Apple Push Notification Service (APNS)](https://developer.apple.com/documentation/usernotifications) based on the client's device platform (Android, iOS, web, etc). We can also add support for email and SMS.

**Why are we using a message queue?**

Since most message queues provide best-effort ordering which ensures that messages are generally delivered in the same order as they're sent and that a message is delivered at least once which is an important part of our service functionality.

While this seems like a classic [publish-subscribe](https://karanpratapsingh.com/courses/system-design/publish-subscribe) use case, it is actually not as mobile devices and browsers each have their own way of handling push notifications. Usually, notifications are handled externally via Firebase Cloud Messaging (FCM) or Apple Push Notification Service (APNS) unlike message fan-out which we commonly see in backend services. We can use something like [Amazon SQS](https://aws.amazon.com/sqs) or [RabbitMQ](https://www.rabbitmq.com) to support this functionality.

### Read receipts

Handling read receipts can be tricky, for this use case we can wait for some sort of [Acknowledgment (ACK)](<https://en.wikipedia.org/wiki/Acknowledgement_(data_networks)>) from the client to determine if the message was delivered and update the corresponding `deliveredAt` field. Similarly, we will mark the message as seen once the user opens the chat and update the corresponding `seenAt` timestamp field.

### Design

Now that we have identified some core components, let's do the first draft of our system design.

![whatsapp-basic-design](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/whatsapp/whatsapp-basic-design.png)

## Detailed design

It's time to discuss our design decisions in detail.

### Data Partitioning

To scale out our databases we will need to partition our data. Horizontal partitioning (aka [Sharding](https://karanpratapsingh.com/courses/system-design/sharding)) can be a good first step. We can use partitions schemes such as:

- Hash-Based Partitioning
- List-Based Partitioning
- Range Based Partitioning
- Composite Partitioning

The above approaches can still cause uneven data and load distribution, we can solve this using [Consistent hashing](https://karanpratapsingh.com/courses/system-design/consistent-hashing).

_For more details, refer to [Sharding](https://karanpratapsingh.com/courses/system-design/sharding) and [Consistent Hashing](https://karanpratapsingh.com/courses/system-design/consistent-hashing)._

### Caching

In a messaging application, we have to be careful about using cache as our users expect the latest data, but many users will be requesting the same messages, especially in a group chat. So, to prevent usage spikes from our resources we can cache older messages.

Some group chats can have thousands of messages and sending that over the network will be really inefficient, to improve efficiency we can add pagination to our system APIs. This decision will be helpful for users with limited network bandwidth as they won't have to retrieve old messages unless requested.

**Which cache eviction policy to use?**

We can use solutions like [Redis](https://redis.io) or [Memcached](https://memcached.org) and cache 20% of the daily traffic but what kind of cache eviction policy would best fit our needs?

[Least Recently Used (LRU)](<https://en.wikipedia.org/wiki/Cache_replacement_policies#Least_recently_used_(LRU)>) can be a good policy for our system. In this policy, we discard the least recently used key first.

**How to handle cache miss?**

Whenever there is a cache miss, our servers can hit the database directly and update the cache with the new entries.

_For more details, refer to [Caching](https://karanpratapsingh.com/courses/system-design/caching)._

### Media access and storage

As we know, most of our storage space will be used for storing media files such as images, videos, or other files. Our media service will be handling both access and storage of the user media files.

But where can we store files at scale? Well, [object storage](https://karanpratapsingh.com/courses/system-design/storage#object-storage) is what we're looking for. Object stores break data files up into pieces called objects. It then stores those objects in a single repository, which can be spread out across multiple networked systems. We can also use distributed file storage such as [HDFS](https://karanpratapsingh.com/courses/system-design/storage#hdfs) or [GlusterFS](https://www.gluster.org).

_Fun fact: WhatsApp deletes media on its servers once it has been downloaded by the user._

We can use object stores like [Amazon S3](https://aws.amazon.com/s3), [Azure Blob Storage](https://azure.microsoft.com/en-in/services/storage/blobs), or [Google Cloud Storage](https://cloud.google.com/storage) for this use case.

### Content Delivery Network (CDN)

[Content Delivery Network (CDN)](https://karanpratapsingh.com/courses/system-design/content-delivery-network) increases content availability and redundancy while reducing bandwidth costs. Generally, static files such as images, and videos are served from CDN. We can use services like [Amazon CloudFront](https://aws.amazon.com/cloudfront) or [Cloudflare CDN](https://www.cloudflare.com/cdn) for this use case.

### API gateway

Since we will be using multiple protocols like HTTP, WebSocket, TCP/IP, deploying multiple L4 (transport layer) or L7 (application layer) type load balancers separately for each protocol will be expensive. Instead, we can use an [API Gateway](https://karanpratapsingh.com/courses/system-design/api-gateway) that supports multiple protocols without any issues.

API Gateway can also offer other features such as authentication, authorization, rate limiting, throttling, and API versioning which will improve the quality of our services.

We can use services like [Amazon API Gateway](https://aws.amazon.com/api-gateway) or [Azure API Gateway](https://azure.microsoft.com/en-in/services/api-management) for this use case.

## Identify and resolve bottlenecks

![whatsapp-advanced-design](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/whatsapp/whatsapp-advanced-design.png)

Let us identify and resolve bottlenecks such as single points of failure in our design:

- "What if one of our services crashes?"
- "How will we distribute our traffic between our components?"
- "How can we reduce the load on our database?"
- "How to improve the availability of our cache?"
- "Wouldn't API Gateway be a single point of failure?"
- "How can we make our notification system more robust?"
- "How can we reduce media storage costs"?
- "Does chat service has too much responsibility?"

To make our system more resilient we can do the following:

- Running multiple instances of each of our services.
- Introducing [load balancers](https://karanpratapsingh.com/courses/system-design/load-balancing) between clients, servers, databases, and cache servers.
- Using multiple read replicas for our databases.
- Multiple instances and replicas for our distributed cache.
- We can have a standby replica of our API Gateway.
- Exactly once delivery and message ordering is challenging in a distributed system, we can use a dedicated [message broker](https://karanpratapsingh.com/courses/system-design/message-brokers) such as [Apache Kafka](https://kafka.apache.org) or [NATS](https://nats.io) to make our notification system more robust.
- We can add media processing and compression capabilities to the media service to compress large files similar to WhatsApp which will save a lot of storage space and reduce cost.
- We can create a group service separate from the chat service to further decouple our services.

# Twitter

Let's design a [Twitter](https://twitter.com) like social media service, similar to services like [Facebook](https://facebook.com), [Instagram](https://instagram.com), etc.

## What is Twitter?

Twitter is a social media service where users can read or post short messages (up to 280 characters) called tweets. It is available on the web and mobile platforms such as Android and iOS.

## Requirements

Our system should meet the following requirements:

### Functional requirements

- Should be able to post new tweets (can be text, image, video, etc.).
- Should be able to follow other users.
- Should have a newsfeed feature consisting of tweets from the people the user is following.
- Should be able to search tweets.

### Non-Functional requirements

- High availability with minimal latency.
- The system should be scalable and efficient.

### Extended requirements

- Metrics and analytics.
- Retweet functionality.
- Favorite tweets.

## Estimation and Constraints

Let's start with the estimation and constraints.

_Note: Make sure to check any scale or traffic-related assumptions with your interviewer._

### Traffic

This will be a read-heavy system, let us assume we have 1 billion total users with 200 million daily active users (DAU), and on average each user tweets 5 times a day. This gives us 1 billion tweets per day.

$$
200 \space million \times 5 \space tweets = 1 \space billion/day
$$

Tweets can also contain media such as images, or videos. We can assume that 10 percent of tweets are media files shared by the users, which gives us additional 100 million files we would need to store.

$$
10 \space percent \times 1 \space billion = 100 \space million/day
$$

**What would be Requests Per Second (RPS) for our system?**

1 billion requests per day translate into 12K requests per second.

$$
\frac{1 \space billion}{(24 \space hrs \times 3600 \space seconds)} = \sim 12K \space requests/second
$$

### Storage

If we assume each message on average is 100 bytes, we will require about 100 GB of database storage every day.

$$
1 \space billion \times 100 \space bytes = \sim 100 \space GB/day
$$

We also know that around 10 percent of our daily messages (100 million) are media files per our requirements. If we assume each file is 50 KB on average, we will require 5 TB of storage every day.

$$
100 \space million \times 50 \space KB = 5 \space TB/day
$$

And for 10 years, we will require about 19 PB of storage.

$$
(5 \space TB + 0.1 \space TB) \times 365 \space days \times 10 \space years = \sim 19 \space PB
$$

### Bandwidth

As our system is handling 5.1 TB of ingress every day, we will require a minimum bandwidth of around 60 MB per second.

$$
\frac{5.1 \space TB}{(24 \space hrs \times 3600 \space seconds)} = \sim 60 \space MB/second
$$

### High-level estimate

Here is our high-level estimate:

| Type                      | Estimate    |
| ------------------------- | ----------- |
| Daily active users (DAU)  | 100 million |
| Requests per second (RPS) | 12K/s       |
| Storage (per day)         | ~5.1 TB     |
| Storage (10 years)        | ~19 PB      |
| Bandwidth                 | ~60 MB/s    |

## Data model design

This is the general data model which reflects our requirements.

![twitter-datamodel](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/twitter/twitter-datamodel.png)

We have the following tables:

**users**

This table will contain a user's information such as `name`, `email`, `dob`, and other details.

**tweets**

As the name suggests, this table will store tweets and their properties such as `type` (text, image, video, etc.), `content`, etc. We will also store the corresponding `userID`.

**favorites**

This table maps tweets with users for the favorite tweets functionality in our application.

**followers**

This table maps the followers and [followees](https://en.wiktionary.org/wiki/followee) as users can follow each other (N:M relationship).

**feeds**

This table stores feed properties with the corresponding `userID`.

**feeds_tweets**

This table maps tweets and feed (N:M relationship).

### What kind of database should we use?

While our data model seems quite relational, we don't necessarily need to store everything in a single database, as this can limit our scalability and quickly become a bottleneck.

We will split the data between different services each having ownership over a particular table. Then we can use a relational database such as [PostgreSQL](https://www.postgresql.org) or a distributed NoSQL database such as [Apache Cassandra](https://cassandra.apache.org/_/index.html) for our use case.

## API design

Let us do a basic API design for our services:

### Post a tweet

This API will allow the user to post a tweet on the platform.

```tsx
postTweet(userID: UUID, content: string, mediaURL?: string): boolean
```

**Parameters**

User ID (`UUID`): ID of the user.

Content (`string`): Contents of the tweet.

Media URL (`string`): URL of the attached media _(optional)_.

**Returns**

Result (`boolean`): Represents whether the operation was successful or not.

### Follow or unfollow a user

This API will allow the user to follow or unfollow another user.

```tsx
follow(followerID: UUID, followeeID: UUID): boolean
unfollow(followerID: UUID, followeeID: UUID): boolean
```

**Parameters**

Follower ID (`UUID`): ID of the current user.

Followee ID (`UUID`): ID of the user we want to follow or unfollow.

Media URL (`string`): URL of the attached media _(optional)_.

**Returns**

Result (`boolean`): Represents whether the operation was successful or not.

### Get newsfeed

This API will return all the tweets to be shown within a given newsfeed.

```tsx
getNewsfeed(userID: UUID): Tweet[]
```

**Parameters**

User ID (`UUID`): ID of the user.

**Returns**

Tweets (`Tweet[]`): All the tweets to be shown within a given newsfeed.

## High-level design

Now let us do a high-level design of our system.

### Architecture

We will be using [microservices architecture](https://karanpratapsingh.com/courses/system-design/monoliths-microservices#microservices) since it will make it easier to horizontally scale and decouple our services. Each service will have ownership of its own data model. Let's try to divide our system into some core services.

**User Service**

This service handles user-related concerns such as authentication and user information.

**Newsfeed Service**

This service will handle the generation and publishing of user newsfeeds. It will be discussed in detail separately.

**Tweet Service**

The tweet service will handle tweet-related use cases such as posting a tweet, favorites, etc.

**Search Service**

The service is responsible for handling search-related functionality. It will be discussed in detail separately.

**Media service**

This service will handle the media (images, videos, files, etc.) uploads. It will be discussed in detail separately.

**Notification Service**

This service will simply send push notifications to the users.

**Analytics Service**

This service will be used for metrics and analytics use cases.

**What about inter-service communication and service discovery?**

Since our architecture is microservices-based, services will be communicating with each other as well. Generally, REST or HTTP performs well but we can further improve the performance using [gRPC](https://karanpratapsingh.com/courses/system-design/rest-graphql-grpc#grpc) which is more lightweight and efficient.

[Service discovery](https://karanpratapsingh.com/courses/system-design/service-discovery) is another thing we will have to take into account. We can also use a service mesh that enables managed, observable, and secure communication between individual services.

_Note: Learn more about [REST, GraphQL, gRPC](https://karanpratapsingh.com/courses/system-design/rest-graphql-grpc) and how they compare with each other._

### Newsfeed

When it comes to the newsfeed, it seems easy enough to implement, but there are a lot of things that can make or break this feature. So, let's divide our problem into two parts:

**Generation**

Let's assume we want to generate the feed for user A, we will perform the following steps:

1. Retrieve the IDs of all the users and entities (hashtags, topics, etc.) user A follows.
2. Fetch the relevant tweets for each of the retrieved IDs.
3. Use a ranking algorithm to rank the tweets based on parameters such as relevance, time, engagement, etc.
4. Return the ranked tweets data to the client in a paginated manner.

Feed generation is an intensive process and can take quite a lot of time, especially for users following a lot of people. To improve the performance, the feed can be pre-generated and stored in the cache, then we can have a mechanism to periodically update the feed and apply our ranking algorithm to the new tweets.

**Publishing**

Publishing is the step where the feed data is pushed according to each specific user. This can be a quite heavy operation, as a user may have millions of friends or followers. To deal with this, we have three different approaches:

- Pull Model (or Fan-out on load)

![newsfeed-pull-model](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/twitter/newsfeed-pull-model.png)

When a user creates a tweet, and a follower reloads their newsfeed, the feed is created and stored in memory. The most recent feed is only loaded when the user requests it. This approach reduces the number of write operations on our database.

The downside of this approach is that the users will not be able to view recent feeds unless they "pull" the data from the server, which will increase the number of read operations on the server.

- Push Model (or Fan-out on write)

![newsfeed-push-model](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/twitter/newsfeed-push-model.png)

In this model, once a user creates a tweet, it is "pushed" to all the follower's feeds immediately. This prevents the system from having to go through a user's entire followers list to check for updates.

However, the downside of this approach is that it would increase the number of write operations on the database.

- Hybrid Model

A third approach is a hybrid model between the pull and push model. It combines the beneficial features of the above two models and tries to provide a balanced approach between the two.

The hybrid model allows only users with a lesser number of followers to use the push model. For users with a higher number of followers such as celebrities, the pull model is used.

### Ranking Algorithm

As we discussed, we will need a ranking algorithm to rank each tweet according to its relevance to each specific user.

For example, Facebook used to utilize an [EdgeRank](https://en.wikipedia.org/wiki/EdgeRank) algorithm. Here, the rank of each feed item is described by:

$$
Rank = Affinity \times Weight \times Decay
$$

Where,

`Affinity`: is the "closeness" of the user to the creator of the edge. If a user frequently likes, comments, or messages the edge creator, then the value of affinity will be higher, resulting in a higher rank for the post.

`Weight`: is the value assigned according to each edge. A comment can have a higher weightage than likes, and thus a post with more comments is more likely to get a higher rank.

`Decay`: is the measure of the creation of the edge. The older the edge, the lesser will be the value of decay and eventually the rank.

Nowadays, algorithms are much more complex and ranking is done using machine learning models which can take thousands of factors into consideration.

### Retweets

Retweets are one of our extended requirements. To implement this feature, we can simply create a new tweet with the user id of the user retweeting the original tweet and then modify the `type` enum and `content` property of the new tweet to link it with the original tweet.

For example, the `type` enum property can be of type tweet, similar to text, video, etc and `content` can be the id of the original tweet. Here the first row indicates the original tweet while the second row is how we can represent a retweet.

| id                  | userID              | type  | content                      | createdAt     |
| ------------------- | ------------------- | ----- | ---------------------------- | ------------- |
| ad34-291a-45f6-b36c | 7a2c-62c4-4dc8-b1bb | text  | Hey, this is my first tweet… | 1658905644054 |
| f064-49ad-9aa2-84a6 | 6aa2-2bc9-4331-879f | tweet | ad34-291a-45f6-b36c          | 1658906165427 |

This is a very basic implementation. To improve this we can create a separate table itself to store retweets.

### Search

Sometimes traditional DBMS are not performant enough, we need something which allows us to store, search, and analyze huge volumes of data quickly and in near real-time and give results within milliseconds. [Elasticsearch](https://www.elastic.co) can help us with this use case.

[Elasticsearch](https://www.elastic.co) is a distributed, free and open search and analytics engine for all types of data, including textual, numerical, geospatial, structured, and unstructured. It is built on top of [Apache Lucene](https://lucene.apache.org).

**How do we identify trending topics?**

Trending functionality will be based on top of the search functionality. We can cache the most frequently searched queries, hashtags, and topics in the last `N` seconds and update them every `M` seconds using some sort of batch job mechanism. Our ranking algorithm can also be applied to the trending topics to give them more weight and personalize them for the user.

### Notifications

Push notifications are an integral part of any social media platform. We can use a message queue or a message broker such as [Apache Kafka](https://kafka.apache.org) with the notification service to dispatch requests to [Firebase Cloud Messaging (FCM)](https://firebase.google.com/docs/cloud-messaging) or [Apple Push Notification Service (APNS)](https://developer.apple.com/documentation/usernotifications) which will handle the delivery of the push notifications to user devices.

_For more details, refer to the [WhatsApp](https://karanpratapsingh.com/courses/system-design/whatsapp#notifications) system design where we discuss push notifications in detail._

## Detailed design

It's time to discuss our design decisions in detail.

### Data Partitioning

To scale out our databases we will need to partition our data. Horizontal partitioning (aka [Sharding](https://karanpratapsingh.com/courses/system-design/sharding)) can be a good first step. We can use partitions schemes such as:

- Hash-Based Partitioning
- List-Based Partitioning
- Range Based Partitioning
- Composite Partitioning

The above approaches can still cause uneven data and load distribution, we can solve this using [Consistent hashing](https://karanpratapsingh.com/courses/system-design/consistent-hashing).

_For more details, refer to [Sharding](https://karanpratapsingh.com/courses/system-design/sharding) and [Consistent Hashing](https://karanpratapsingh.com/courses/system-design/consistent-hashing)._

### Mutual friends

For mutual friends, we can build a social graph for every user. Each node in the graph will represent a user and a directional edge will represent followers and followees. After that, we can traverse the followers of a user to find and suggest a mutual friend. This would require a graph database such as [Neo4j](https://neo4j.com) and [ArangoDB](https://www.arangodb.com).

This is a pretty simple algorithm, to improve our suggestion accuracy, we will need to incorporate a recommendation model which uses machine learning as part of our algorithm.

### Metrics and Analytics

Recording analytics and metrics is one of our extended requirements. As we will be using [Apache Kafka](https://kafka.apache.org) to publish all sorts of events, we can process these events and run analytics on the data using [Apache Spark](https://spark.apache.org) which is an open-source unified analytics engine for large-scale data processing.

### Caching

In a social media application, we have to be careful about using cache as our users expect the latest data. So, to prevent usage spikes from our resources we can cache the top 20% of the tweets.

To further improve efficiency we can add pagination to our system APIs. This decision will be helpful for users with limited network bandwidth as they won't have to retrieve old messages unless requested.

**Which cache eviction policy to use?**

We can use solutions like [Redis](https://redis.io) or [Memcached](https://memcached.org) and cache 20% of the daily traffic but what kind of cache eviction policy would best fit our needs?

[Least Recently Used (LRU)](<https://en.wikipedia.org/wiki/Cache_replacement_policies#Least_recently_used_(LRU)>) can be a good policy for our system. In this policy, we discard the least recently used key first.

**How to handle cache miss?**

Whenever there is a cache miss, our servers can hit the database directly and update the cache with the new entries.

_For more details, refer to [Caching](https://karanpratapsingh.com/courses/system-design/caching)._

### Media access and storage

As we know, most of our storage space will be used for storing media files such as images, videos, or other files. Our media service will be handling both access and storage of the user media files.

But where can we store files at scale? Well, [object storage](https://karanpratapsingh.com/courses/system-design/storage#object-storage) is what we're looking for. Object stores break data files up into pieces called objects. It then stores those objects in a single repository, which can be spread out across multiple networked systems. We can also use distributed file storage such as [HDFS](https://karanpratapsingh.com/courses/system-design/storage#hdfs) or [GlusterFS](https://www.gluster.org).

### Content Delivery Network (CDN)

[Content Delivery Network (CDN)](https://karanpratapsingh.com/courses/system-design/content-delivery-network) increases content availability and redundancy while reducing bandwidth costs. Generally, static files such as images, and videos are served from CDN. We can use services like [Amazon CloudFront](https://aws.amazon.com/cloudfront) or [Cloudflare CDN](https://www.cloudflare.com/cdn) for this use case.

## Identify and resolve bottlenecks

![twitter-advanced-design](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/twitter/twitter-advanced-design.png)

Let us identify and resolve bottlenecks such as single points of failure in our design:

- "What if one of our services crashes?"
- "How will we distribute our traffic between our components?"
- "How can we reduce the load on our database?"
- "How to improve the availability of our cache?"
- "How can we make our notification system more robust?"
- "How can we reduce media storage costs"?

To make our system more resilient we can do the following:

- Running multiple instances of each of our services.
- Introducing [load balancers](https://karanpratapsingh.com/courses/system-design/load-balancing) between clients, servers, databases, and cache servers.
- Using multiple read replicas for our databases.
- Multiple instances and replicas for our distributed cache.
- Exactly once delivery and message ordering is challenging in a distributed system, we can use a dedicated [message broker](https://karanpratapsingh.com/courses/system-design/message-brokers) such as [Apache Kafka](https://kafka.apache.org) or [NATS](https://nats.io) to make our notification system more robust.
- We can add media processing and compression capabilities to the media service to compress large files which will save a lot of storage space and reduce cost.

# Netflix

Let's design a [Netflix](https://netflix.com) like video streaming service, similar to services like [Amazon Prime Video](https://www.primevideo.com), [Disney Plus](https://www.disneyplus.com), [Hulu](https://www.hulu.com), [Youtube](https://youtube.com), [Vimeo](https://vimeo.com), etc.

## What is Netflix?

Netflix is a subscription-based streaming service that allows its members to watch TV shows and movies on an internet-connected device. It is available on platforms such as the Web, iOS, Android, TV, etc.

## Requirements

Our system should meet the following requirements:

### Functional requirements

- Users should be able to stream and share videos.
- The content team (or users in YouTube's case) should be able to upload new videos (movies, tv shows episodes, and other content).
- Users should be able to search for videos using titles or tags.
- Users should be able to comment on a video similar to YouTube.

### Non-Functional requirements

- High availability with minimal latency.
- High reliability, no uploads should be lost.
- The system should be scalable and efficient.

### Extended requirements

- Certain content should be [geo-blocked](https://en.wikipedia.org/wiki/Geo-blocking).
- Resume video playback from the point user left off.
- Record metrics and analytics of videos.

## Estimation and Constraints

Let's start with the estimation and constraints.

_Note: Make sure to check any scale or traffic-related assumptions with your interviewer._

### Traffic

This will be a read-heavy system, let us assume we have 1 billion total users with 200 million daily active users (DAU), and on average each user watches 5 videos a day. This gives us 1 billion videos watched per day.

$$
200 \space million \times 5 \space videos = 1 \space billion/day
$$

Assuming a `200:1` read/write ratio, about 5 million videos will be uploaded every day.

$$
\frac{1}{200} \times 1 \space billion = 5 \space million/day
$$

**What would be Requests Per Second (RPS) for our system?**

1 billion requests per day translate into 12K requests per second.

$$
\frac{1 \space billion}{(24 \space hrs \times 3600 \space seconds)} = \sim 12K \space requests/second
$$

### Storage

If we assume each video is 100 MB on average, we will require about 500 TB of storage every day.

$$
5 \space million \times 100 \space MB = 500 \space TB/day
$$

And for 10 years, we will require an astounding 1,825 PB of storage.

$$
500 \space TB \times 365 \space days \times 10 \space years = \sim 1,825 \space PB
$$

### Bandwidth

As our system is handling 500 TB of ingress every day, we will require a minimum bandwidth of around 5.8 GB per second.

$$
\frac{500 \space TB}{(24 \space hrs \times 3600 \space seconds)} = \sim 5.8 \space GB/second
$$

### High-level estimate

Here is our high-level estimate:

| Type                      | Estimate    |
| ------------------------- | ----------- |
| Daily active users (DAU)  | 200 million |
| Requests per second (RPS) | 12K/s       |
| Storage (per day)         | ~500 TB     |
| Storage (10 years)        | ~1,825 PB   |
| Bandwidth                 | ~5.8 GB/s   |

## Data model design

This is the general data model which reflects our requirements.

![netflix-datamodel](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/netflix/netflix-datamodel.png)

We have the following tables:

**users**

This table will contain a user's information such as `name`, `email`, `dob`, and other details.

**videos**

As the name suggests, this table will store videos and their properties such as `title`, `streamURL`, `tags`, etc. We will also store the corresponding `userID`.

**tags**

This table will simply store tags associated with a video.

**views**

This table helps us to store all the views received on a video.

**comments**

This table stores all the comments received on a video (like YouTube).

### What kind of database should we use?

While our data model seems quite relational, we don't necessarily need to store everything in a single database, as this can limit our scalability and quickly become a bottleneck.

We will split the data between different services each having ownership over a particular table. Then we can use a relational database such as [PostgreSQL](https://www.postgresql.org) or a distributed NoSQL database such as [Apache Cassandra](https://cassandra.apache.org/_/index.html) for our use case.

## API design

Let us do a basic API design for our services:

### Upload a video

Given a byte stream, this API enables video to be uploaded to our service.

```tsx
uploadVideo(title: string, description: string, data: Stream<byte>, tags?: string[]): boolean
```

**Parameters**

Title (`string`): Title of the new video.

Description (`string`): Description of the new video.

Data (`Byte[]`): Byte stream of the video data.

Tags (`string[]`): Tags for the video _(optional)_.

**Returns**

Result (`boolean`): Represents whether the operation was successful or not.

### Streaming a video

This API allows our users to stream a video with the preferred codec and resolution.

```tsx
streamVideo(videoID: UUID, codec: Enum<string>, resolution: Tuple<int>, offset?: int): VideoStream
```

**Parameters**

Video ID (`UUID`): ID of the video that needs to be streamed.

Codec (`Enum<string>`): Required [codec](https://en.wikipedia.org/wiki/Video_codec) of the requested video, such as `h.265`, `h.264`, `VP9`, etc.

Resolution (`Tuple<int>`): [Resolution](https://en.wikipedia.org/wiki/Display_resolution) of the requested video.

Offset (`int`): Offset of the video stream in seconds to stream data from any point in the video _(optional)_.

**Returns**

Stream (`VideoStream`): Data stream of the requested video.

### Search for a video

This API will enable our users to search for a video based on its title or tags.

```tsx
searchVideo(query: string, nextPage?: string): Video[]
```

**Parameters**

Query (`string`): Search query from the user.

Next Page (`string`): Token for the next page, this can be used for pagination _(optional)_.

**Returns**

Videos (`Video[]`): All the videos available for a particular search query.

### Add a comment

This API will allow our users to post a comment on a video (like YouTube).

```tsx
comment(videoID: UUID, comment: string): boolean
```

**Parameters**

VideoID (`UUID`): ID of the video user wants to comment on.

Comment (`string`): The text content of the comment.

**Returns**

Result (`boolean`): Represents whether the operation was successful or not.

## High-level design

Now let us do a high-level design of our system.

### Architecture

We will be using [microservices architecture](https://karanpratapsingh.com/courses/system-design/monoliths-microservices#microservices) since it will make it easier to horizontally scale and decouple our services. Each service will have ownership of its own data model. Let's try to divide our system into some core services.

**User Service**

This service handles user-related concerns such as authentication and user information.

**Stream Service**

The stream service will handle video streaming-related functionality.

**Search Service**

The service is responsible for handling search-related functionality. It will be discussed in detail separately.

**Media service**

This service will handle the video uploads and processing. It will be discussed in detail separately.

**Analytics Service**

This service will be used for metrics and analytics use cases.

**What about inter-service communication and service discovery?**

Since our architecture is microservices-based, services will be communicating with each other as well. Generally, REST or HTTP performs well but we can further improve the performance using [gRPC](https://karanpratapsingh.com/courses/system-design/rest-graphql-grpc#grpc) which is more lightweight and efficient.

[Service discovery](https://karanpratapsingh.com/courses/system-design/service-discovery) is another thing we will have to take into account. We can also use a service mesh that enables managed, observable, and secure communication between individual services.

_Note: Learn more about [REST, GraphQL, gRPC](https://karanpratapsingh.com/courses/system-design/rest-graphql-grpc) and how they compare with each other._

### Video processing

![video-processing-pipeline](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/netflix/video-processing-pipeline.png)

There are so many variables in play when it comes to processing a video. For example, an average data size of two-hour raw 8K footage from a high-end camera can easily be up to 4 TB, thus we need to have some kind of processing to reduce both storage and delivery costs.

Here's how we can process videos once they're uploaded by the content team (or users in YouTube's case) and are queued for processing in our [message queue](https://karanpratapsingh.com/courses/system-design/message-queues).

Let's discuss how this works:

- **File Chunker**

![file-chunking](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/netflix/file-chunking.png)

This is the first step of our processing pipeline. File chunking is the process of splitting a file into smaller pieces called chunks. It can help us eliminate duplicate copies of repeating data on storage, and reduces the amount of data sent over the network by only selecting changed chunks.

Usually, a video file can be split into equal size chunks based on timestamps but Netflix instead splits chunks based on scenes. This slight variation becomes a huge factor for a better user experience since whenever the client requests a chunk from the server, there is a lower chance of interruption as a complete scene will be retrieved.

- **Content Filter**

This step checks if the video adheres to the content policy of the platform. This can be pre-approved as in the case of Netflix according to [content rating](https://en.wikipedia.org/wiki/Motion_picture_content_rating_system) of the media or can be strictly enforced like by YouTube.

This entire process is done by a machine learning model which performs copyright, piracy, and NSFW checks. If issues are found, we can push the task to a [dead-letter queue (DLQ)](https://karanpratapsingh.com/courses/system-design/message-queues#dead-letter-queues) and someone from the moderation team can do further inspection.

- **Transcoder**

[Transcoding](https://en.wikipedia.org/wiki/Transcoding) is a process in which the original data is decoded to an intermediate uncompressed format, which is then encoded into the target format. This process uses different [codecs](https://en.wikipedia.org/wiki/Video_codec) to perform bitrate adjustment, image downsampling, or re-encoding the media.

This results in a smaller size file and a much more optimized format for the target devices. Standalone solutions such as [FFmpeg](https://ffmpeg.org) or cloud-based solutions like [AWS Elemental MediaConvert](https://aws.amazon.com/mediaconvert) can be used to implement this step of the pipeline.

- **Quality Conversion**

This is the last step of the processing pipeline and as the name suggests, this step handles the conversion of the transcoded media from the previous step into different resolutions such as 4K, 1440p, 1080p, 720p, etc.

It allows us to fetch the desired quality of the video as per the user's request, and once the media file finishes processing, it gets uploaded to a distributed file storage such as [HDFS](https://karanpratapsingh.com/courses/system-design/storage#hdfs), [GlusterFS](https://www.gluster.org), or an [object storage](https://karanpratapsingh.com/courses/system-design/storage#object-storage) such as [Amazon S3](https://aws.amazon.com/s3) for later retrieval during streaming.

_Note: We can add additional steps such as subtitles and thumbnails generation as part of our pipeline._

**Why are we using a message queue?**

Processing videos as a long-running task and using a [message queue](https://karanpratapsingh.com/courses/system-design/message-queues) makes much more sense. It also decouples our video processing pipeline from the upload functionality. We can use something like [Amazon SQS](https://aws.amazon.com/sqs) or [RabbitMQ](https://www.rabbitmq.com) to support this.

### Video streaming

Video streaming is a challenging task from both the client and server perspectives. Moreover, internet connection speeds vary quite a lot between different users. To make sure users don't re-fetch the same content, we can use a [Content Delivery Network (CDN)](https://karanpratapsingh.com/courses/system-design/content-delivery-network).

Netflix takes this a step further with its [Open Connect](https://openconnect.netflix.com) program. In this approach, they partner with thousands of Internet Service Providers (ISPs) to localize their traffic and deliver their content more efficiently.

**What is the difference between Netflix's Open Connect and a traditional Content Delivery Network (CDN)?**

Netflix Open Connect is a purpose-built [Content Delivery Network (CDN)](https://karanpratapsingh.com/courses/system-design/content-delivery-network) responsible for serving Netflix's video traffic. Around 95% of the traffic globally is delivered via direct connections between Open Connect and the ISPs their customers use to access the internet.

Currently, they have Open Connect Appliances (OCAs) in over 1000 separate locations around the world. In case of issues, Open Connect Appliances (OCAs) can failover, and the traffic can be re-routed to Netflix servers.

Additionally, we can use [Adaptive bitrate streaming](https://en.wikipedia.org/wiki/Adaptive_bitrate_streaming) protocols such as [HTTP Live Streaming (HLS)](https://en.wikipedia.org/wiki/HTTP_Live_Streaming) which is designed for reliability and it dynamically adapts to network conditions by optimizing playback for the available speed of the connections.

Lastly, for playing the video from where the user left off (part of our extended requirements), we can simply use the `offset` property we stored in the `views` table to retrieve the scene chunk at that particular timestamp and resume the playback for the user.

### Searching

Sometimes traditional DBMS are not performant enough, we need something which allows us to store, search, and analyze huge volumes of data quickly and in near real-time and give results within milliseconds. [Elasticsearch](https://www.elastic.co) can help us with this use case.

[Elasticsearch](https://www.elastic.co) is a distributed, free and open search and analytics engine for all types of data, including textual, numerical, geospatial, structured, and unstructured. It is built on top of [Apache Lucene](https://lucene.apache.org).

**How do we identify trending content?**

Trending functionality will be based on top of the search functionality. We can cache the most frequently searched queries in the last `N` seconds and update them every `M` seconds using some sort of batch job mechanism.

### Sharing

Sharing content is an important part of any platform, for this, we can have some sort of URL shortener service in place that can generate short URLs for the users to share.

_For more details, refer to the [URL Shortener](https://karanpratapsingh.com/courses/system-design/url-shortener) system design._

## Detailed design

It's time to discuss our design decisions in detail.

### Data Partitioning

To scale out our databases we will need to partition our data. Horizontal partitioning (aka [Sharding](https://karanpratapsingh.com/courses/system-design/sharding)) can be a good first step. We can use partitions schemes such as:

- Hash-Based Partitioning
- List-Based Partitioning
- Range Based Partitioning
- Composite Partitioning

The above approaches can still cause uneven data and load distribution, we can solve this using [Consistent hashing](https://karanpratapsingh.com/courses/system-design/consistent-hashing).

_For more details, refer to [Sharding](https://karanpratapsingh.com/courses/system-design/sharding) and [Consistent Hashing](https://karanpratapsingh.com/courses/system-design/consistent-hashing)._

### Geo-blocking

Platforms like Netflix and YouTube use [Geo-blocking](https://en.wikipedia.org/wiki/Geo-blocking) to restrict content in certain geographical areas or countries. This is primarily done due to legal distribution laws that Netflix has to adhere to when they make a deal with the production and distribution companies. In the case of YouTube, this will be controlled by the user during the publishing of the content.

We can determine the user's location either using their [IP](https://karanpratapsingh.com/courses/system-design/ip) or region settings in their profile then use services like [Amazon CloudFront](https://aws.amazon.com/cloudfront) which supports a geographic restrictions feature or a [geolocation routing policy](https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy-geo.html) with [Amazon Route53](https://aws.amazon.com/route53) to restrict the content and re-route the user to an error page if the content is not available in that particular region or country.

### Recommendations

Netflix uses a machine learning model which uses the user's viewing history to predict what the user might like to watch next, an algorithm like [Collaborative Filtering](https://en.wikipedia.org/wiki/Collaborative_filtering) can be used.

However, Netflix (like YouTube) uses its own algorithm called Netflix Recommendation Engine which can track several data points such as:

- User profile information like age, gender, and location.
- Browsing and scrolling behavior of the user.
- Time and date a user watched a title.
- The device which was used to stream the content.
- The number of searches and what terms were searched.

_For more detail, refer to [Netflix recommendation research](https://research.netflix.com/research-area/recommendations)._

### Metrics and Analytics

Recording analytics and metrics is one of our extended requirements. We can capture the data from different services and run analytics on the data using [Apache Spark](https://spark.apache.org) which is an open-source unified analytics engine for large-scale data processing. Additionally, we can store critical metadata in the views table to increase data points within our data.

### Caching

In a streaming platform, caching is important. We have to be able to cache as much static media content as possible to improve user experience. We can use solutions like [Redis](https://redis.io) or [Memcached](https://memcached.org) but what kind of cache eviction policy would best fit our needs?

**Which cache eviction policy to use?**

[Least Recently Used (LRU)](<https://en.wikipedia.org/wiki/Cache_replacement_policies#Least_recently_used_(LRU)>) can be a good policy for our system. In this policy, we discard the least recently used key first.

**How to handle cache miss?**

Whenever there is a cache miss, our servers can hit the database directly and update the cache with the new entries.

_For more details, refer to [Caching](https://karanpratapsingh.com/courses/system-design/caching)._

### Media streaming and storage

As most of our storage space will be used for storing media files such as thumbnails and videos. Per our discussion earlier, the media service will be handling both the upload and processing of media files.

We will use distributed file storage such as [HDFS](https://karanpratapsingh.com/courses/system-design/storage#hdfs), [GlusterFS](https://www.gluster.org), or an [object storage](https://karanpratapsingh.com/courses/system-design/storage#object-storage) such as [Amazon S3](https://aws.amazon.com/s3) for storage and streaming of the content.

### Content Delivery Network (CDN)

[Content Delivery Network (CDN)](https://karanpratapsingh.com/courses/system-design/content-delivery-network) increases content availability and redundancy while reducing bandwidth costs. Generally, static files such as images, and videos are served from CDN. We can use services like [Amazon CloudFront](https://aws.amazon.com/cloudfront) or [Cloudflare CDN](https://www.cloudflare.com/cdn) for this use case.

## Identify and resolve bottlenecks

![netflix-advanced-design](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/netflix/netflix-advanced-design.png)

Let us identify and resolve bottlenecks such as single points of failure in our design:

- "What if one of our services crashes?"
- "How will we distribute our traffic between our components?"
- "How can we reduce the load on our database?"
- "How to improve the availability of our cache?"

To make our system more resilient we can do the following:

- Running multiple instances of each of our services.
- Introducing [load balancers](https://karanpratapsingh.com/courses/system-design/load-balancing) between clients, servers, databases, and cache servers.
- Using multiple read replicas for our databases.
- Multiple instances and replicas for our distributed cache.

# Uber

Let's design an [Uber](https://uber.com) like ride-hailing service, similar to services like [Lyft](https://www.lyft.com), [OLA Cabs](https://www.olacabs.com), etc.

## What is Uber?

Uber is a mobility service provider, allowing users to book rides and a driver to transport them in a way similar to a taxi. It is available on the web and mobile platforms such as Android and iOS.

## Requirements

Our system should meet the following requirements:

### Functional requirements

We will design our system for two types of users: Customers and Drivers.

**Customers**

- Customers should be able to see all the cabs in the vicinity with an ETA and pricing information.
- Customers should be able to book a cab to a destination.
- Customers should be able to see the location of the driver.

**Drivers**

- Drivers should be able to accept or deny the customer-requested ride.
- Once a driver accepts the ride, they should see the pickup location of the customer.
- Drivers should be able to mark the trip as complete on reaching the destination.

### Non-Functional requirements

- High reliability.
- High availability with minimal latency.
- The system should be scalable and efficient.

### Extended requirements

- Customers can rate the trip after it's completed.
- Payment processing.
- Metrics and analytics.

## Estimation and Constraints

Let's start with the estimation and constraints.

_Note: Make sure to check any scale or traffic-related assumptions with your interviewer._

### Traffic

Let us assume we have 100 million daily active users (DAU) with 1 million drivers and on average our platform enables 10 million rides daily.

If on average each user performs 10 actions (such as request a check available rides, fares, book rides, etc.) we will have to handle 1 billion requests daily.

$$
100 \space million \times 10 \space actions = 1 \space billion/day
$$

**What would be Requests Per Second (RPS) for our system?**

1 billion requests per day translate into 12K requests per second.

$$
\frac{1 \space billion}{(24 \space hrs \times 3600 \space seconds)} = \sim 12K \space requests/second
$$

### Storage

If we assume each message on average is 400 bytes, we will require about 400 GB of database storage every day.

$$
1 \space billion \times 400 \space bytes = \sim 400 \space GB/day
$$

And for 10 years, we will require about 1.4 PB of storage.

$$
400 \space GB \times 10 \space years \times 365 \space days = \sim 1.4 \space PB
$$

### Bandwidth

As our system is handling 400 GB of ingress every day, we will require a minimum bandwidth of around 4 MB per second.

$$
\frac{400 \space GB}{(24 \space hrs \times 3600 \space seconds)} = \sim 5 \space MB/second
$$

### High-level estimate

Here is our high-level estimate:

| Type                      | Estimate    |
| ------------------------- | ----------- |
| Daily active users (DAU)  | 100 million |
| Requests per second (RPS) | 12K/s       |
| Storage (per day)         | ~400 GB     |
| Storage (10 years)        | ~1.4 PB     |
| Bandwidth                 | ~5 MB/s     |

## Data model design

This is the general data model which reflects our requirements.

![uber-datamodel](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/uber/uber-datamodel.png)

We have the following tables:

**customers**

This table will contain a customer's information such as `name`, `email`, and other details.

**drivers**

This table will contain a driver's information such as `name`, `email`, `dob` and other details.

**trips**

This table represents the trip taken by the customer and stores data such as `source`, `destination`, and `status` of the trip.

**cabs**

This table stores data such as the registration number, and type (like Uber Go, Uber XL, etc.) of the cab that the driver will be driving.

**ratings**

As the name suggests, this table stores the `rating` and `feedback` for the trip.

**payments**

The payments table contains the payment-related data with the corresponding `tripID`.

### What kind of database should we use?

While our data model seems quite relational, we don't necessarily need to store everything in a single database, as this can limit our scalability and quickly become a bottleneck.

We will split the data between different services each having ownership over a particular table. Then we can use a relational database such as [PostgreSQL](https://www.postgresql.org) or a distributed NoSQL database such as [Apache Cassandra](https://cassandra.apache.org/_/index.html) for our use case.

## API design

Let us do a basic API design for our services:

### Request a Ride

Through this API, customers will be able to request a ride.

```tsx
requestRide(customerID: UUID, source: Tuple<float>, destination: Tuple<float>, cabType: Enum<string>, paymentMethod: Enum<string>): Ride
```

**Parameters**

Customer ID (`UUID`): ID of the customer.

Source (`Tuple<float>`): Tuple containing the latitude and longitude of the trip's starting location.

Destination (`Tuple<float>`): Tuple containing the latitude and longitude of the trip's destination.

**Returns**

Result (`Ride`): Associated ride information of the trip.

### Cancel the Ride

This API will allow customers to cancel the ride.

```tsx
cancelRide(customerID: UUID, reason?: string): boolean
```

**Parameters**

Customer ID (`UUID`): ID of the customer.

Reason (`UUID`): Reason for canceling the ride _(optional)_.

**Returns**

Result (`boolean`): Represents whether the operation was successful or not.

### Accept or Deny the Ride

This API will allow the driver to accept or deny the trip.

```tsx
acceptRide(driverID: UUID, rideID: UUID): boolean
denyRide(driverID: UUID, rideID: UUID): boolean
```

**Parameters**

Driver ID (`UUID`): ID of the driver.

Ride ID (`UUID`): ID of the customer requested ride.

**Returns**

Result (`boolean`): Represents whether the operation was successful or not.

### Start or End the Trip

Using this API, a driver will be able to start and end the trip.

```tsx
startTrip(driverID: UUID, tripID: UUID): boolean
endTrip(driverID: UUID, tripID: UUID): boolean
```

**Parameters**

Driver ID (`UUID`): ID of the driver.

Trip ID (`UUID`): ID of the requested trip.

**Returns**

Result (`boolean`): Represents whether the operation was successful or not.

### Rate the Trip

This API will enable customers to rate the trip.

```tsx
rateTrip(customerID: UUID, tripID: UUID, rating: int, feedback?: string): boolean
```

**Parameters**

Customer ID (`UUID`): ID of the customer.

Trip ID (`UUID`): ID of the completed trip.

Rating (`int`): Rating of the trip.

Feedback (`string`): Feedback about the trip by the customer _(optional)_.

**Returns**

Result (`boolean`): Represents whether the operation was successful or not.

## High-level design

Now let us do a high-level design of our system.

### Architecture

We will be using [microservices architecture](https://karanpratapsingh.com/courses/system-design/monoliths-microservices#microservices) since it will make it easier to horizontally scale and decouple our services. Each service will have ownership of its own data model. Let's try to divide our system into some core services.

**Customer Service**

This service handles customer-related concerns such as authentication and customer information.

**Driver Service**

This service handles driver-related concerns such as authentication and driver information.

**Ride Service**

This service will be responsible for ride matching and quadtree aggregation. It will be discussed in detail separately.

**Trip Service**

This service handles trip-related functionality in our system.

**Payment Service**

This service will be responsible for handling payments in our system.

**Notification Service**

This service will simply send push notifications to the users. It will be discussed in detail separately.

**Analytics Service**

This service will be used for metrics and analytics use cases.

**What about inter-service communication and service discovery?**

Since our architecture is microservices-based, services will be communicating with each other as well. Generally, REST or HTTP performs well but we can further improve the performance using [gRPC](https://karanpratapsingh.com/courses/system-design/rest-graphql-grpc#grpc) which is more lightweight and efficient.

[Service discovery](https://karanpratapsingh.com/courses/system-design/service-discovery) is another thing we will have to take into account. We can also use a service mesh that enables managed, observable, and secure communication between individual services.

_Note: Learn more about [REST, GraphQL, gRPC](https://karanpratapsingh.com/courses/system-design/rest-graphql-grpc) and how they compare with each other._

### How is the service expected to work?

Here's how our service is expected to work:

![uber-working](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/uber/uber-working.png)

1. Customer requests a ride by specifying the source, destination, cab type, payment method, etc.
2. Ride service registers this request, finds nearby drivers, and calculates the estimated time of arrival (ETA).
3. The request is then broadcasted to the nearby drivers for them to accept or deny.
4. If the driver accepts, the customer is notified about the live location of the driver with the estimated time of arrival (ETA) while they wait for pickup.
5. The customer is picked up and the driver can start the trip.
6. Once the destination is reached, the driver will mark the ride as complete and collect payment.
7. After the payment is complete, the customer can leave a rating and feedback for the trip if they like.

### Location Tracking

How do we efficiently send and receive live location data from the client (customers and drivers) to our backend? We have two different options:

**Pull model**

The client can periodically send an HTTP request to servers to report its current location and receive ETA and pricing information. This can be achieved via something like [Long polling](https://karanpratapsingh.com/courses/system-design/long-polling-websockets-server-sent-events#long-polling).

**Push model**

The client opens a long-lived connection with the server and once new data is available it will be pushed to the client. We can use [WebSockets](https://karanpratapsingh.com/courses/system-design/long-polling-websockets-server-sent-events#websockets) or [Server-Sent Events (SSE)](https://karanpratapsingh.com/courses/system-design/long-polling-websockets-server-sent-events#server-sent-events-sse) for this.

The pull model approach is not scalable as it will create unnecessary request overhead on our servers and most of the time the response will be empty, thus wasting our resources. To minimize latency, using the push model with [WebSockets](https://karanpratapsingh.com/courses/system-design/long-polling-websockets-server-sent-events#websockets) is a better choice because then we can push data to the client once it's available without any delay, given the connection is open with the client. Also, WebSockets provide full-duplex communication, unlike [Server-Sent Events (SSE)](https://karanpratapsingh.com/courses/system-design/long-polling-websockets-server-sent-events#server-sent-events-sse) which are only unidirectional.

Additionally, the client application should have some sort of background job mechanism to ping GPS location while the application is in the background.

_Note: Learn more about [Long polling, WebSockets, Server-Sent Events (SSE)](https://karanpratapsingh.com/courses/system-design/long-polling-websockets-server-sent-events)._

### Ride Matching

We need a way to efficiently store and query nearby drivers. Let's explore different solutions we can incorporate into our design.

**SQL**

We already have access to the latitude and longitude of our customers, and with databases like [PostgreSQL](https://www.postgresql.org) and [MySQL](https://www.mysql.com) we can perform a query to find nearby driver locations given a latitude and longitude (X, Y) within a radius (R).

```sql
SELECT * FROM locations WHERE lat BETWEEN X-R AND X+R AND long BETWEEN Y-R AND Y+R
```

However, this is not scalable, and performing this query on large datasets will be quite slow.

**Geohashing**

[Geohashing](/courses/sytem-design/geohashing-and-quadtrees#geohashing) is a [geocoding](https://en.wikipedia.org/wiki/Address_geocoding) method used to encode geographic coordinates such as latitude and longitude into short alphanumeric strings. It was created by [Gustavo Niemeyer](https://twitter.com/gniemeyer) in 2008.

Geohash is a hierarchical spatial index that uses Base-32 alphabet encoding, the first character in a geohash identifies the initial location as one of the 32 cells. This cell will also contain 32 cells. This means that to represent a point, the world is recursively divided into smaller and smaller cells with each additional bit until the desired precision is attained. The precision factor also determines the size of the cell.

![geohashing](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/geohashing-and-quadtrees/geohashing.png)

For example, San Francisco with coordinates `37.7564, -122.4016` can be represented in geohash as `9q8yy9mf`.

Now, using the customer's geohash we can determine the nearest available driver by simply comparing it with the driver's geohash. For better performance, we will index and store the geohash of the driver in memory for faster retrieval.

**Quadtrees**

A [Quadtree](/courses/sytem-design/geohashing-and-quadtrees#quadtrees) is a tree data structure in which each internal node has exactly four children. They are often used to partition a two-dimensional space by recursively subdividing it into four quadrants or regions. Each child or leaf node stores spatial information. Quadtrees are the two-dimensional analog of [Octrees](https://en.wikipedia.org/wiki/Octree) which are used to partition three-dimensional space.

![quadtree](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/geohashing-and-quadtrees/quadtree.png)

Quadtrees enable us to search points within a two-dimensional range efficiently, where those points are defined as latitude/longitude coordinates or as cartesian (x, y) coordinates.

We can save further computation by only subdividing a node after a certain threshold.

![quadtree-subdivision](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/geohashing-and-quadtrees/quadtree-subdivision.png)

[Quadtree](/courses/sytem-design/geohashing-and-quadtrees#quadtrees) seems perfect for our use case, we can update the Quadtree every time we receive a new location update from the driver. To reduce the load on the quadtree servers we can use an in-memory datastore such as [Redis](https://redis.io) to cache the latest updates. And with the application of mapping algorithms such as the [Hilbert curve](https://en.wikipedia.org/wiki/Hilbert_curve), we can perform efficient range queries to find nearby drivers for the customer.

**What about race conditions?**

Race conditions can easily occur when a large number of customers will be requesting rides simultaneously. To avoid this, we can wrap our ride matching logic in a [Mutex](<https://en.wikipedia.org/wiki/Lock_(computer_science)>) to avoid any race conditions. Furthermore, every action should be transactional in nature.

_For more details, refer to [Transactions](https://karanpratapsingh.com/courses/system-design/transactions) and [Distributed Transactions](https://karanpratapsingh.com/courses/system-design/distributed-transactions)._

**How to find the best drivers nearby?**

Once we have a list of nearby drivers from the Quadtree servers, we can perform some sort of ranking based on parameters like average ratings, relevance, past customer feedback, etc. This will allow us to broadcast notifications to the best available drivers first.

**Dealing with high demand**

In cases of high demand, we can use the concept of Surge Pricing. Surge pricing is a dynamic pricing method where prices are temporarily increased as a reaction to increased demand and mostly limited supply. This surge price can be added to the base price of the trip.

_For more details, learn how [surge pricing works](https://www.uber.com/us/en/drive/driver-app/how-surge-works) with Uber._

### Payments

Handling payments at scale is challenging, to simplify our system we can use a third-party payment processor like [Stripe](https://stripe.com) or [PayPal](https://www.paypal.com). Once the payment is complete, the payment processor will redirect the user back to our application and we can set up a [webhook](https://en.wikipedia.org/wiki/Webhook) to capture all the payment-related data.

### Notifications

Push notifications will be an integral part of our platform. We can use a message queue or a message broker such as [Apache Kafka](https://kafka.apache.org) with the notification service to dispatch requests to [Firebase Cloud Messaging (FCM)](https://firebase.google.com/docs/cloud-messaging) or [Apple Push Notification Service (APNS)](https://developer.apple.com/documentation/usernotifications) which will handle the delivery of the push notifications to user devices.

_For more details, refer to the [WhatsApp](https://karanpratapsingh.com/courses/system-design/whatsapp#notifications) system design where we discuss push notifications in detail._

## Detailed design

It's time to discuss our design decisions in detail.

### Data Partitioning

To scale out our databases we will need to partition our data. Horizontal partitioning (aka [Sharding](https://karanpratapsingh.com/courses/system-design/sharding)) can be a good first step. We can shard our database either based on existing [partition schemes](https://karanpratapsingh.com/courses/system-design/sharding#partitioning-criteria) or regions. If we divide the locations into regions using let's say zip codes, we can effectively store all the data in a given region on a fixed node. But this can still cause uneven data and load distribution, we can solve this using [Consistent hashing](https://karanpratapsingh.com/courses/system-design/consistent-hashing).

_For more details, refer to [Sharding](https://karanpratapsingh.com/courses/system-design/sharding) and [Consistent Hashing](https://karanpratapsingh.com/courses/system-design/consistent-hashing)._

### Metrics and Analytics

Recording analytics and metrics is one of our extended requirements. We can capture the data from different services and run analytics on the data using [Apache Spark](https://spark.apache.org) which is an open-source unified analytics engine for large-scale data processing. Additionally, we can store critical metadata in the views table to increase data points within our data.

### Caching

In a location services-based platform, caching is important. We have to be able to cache the recent locations of the customers and drivers for fast retrieval. We can use solutions like [Redis](https://redis.io) or [Memcached](https://memcached.org) but what kind of cache eviction policy would best fit our needs?

**Which cache eviction policy to use?**

[Least Recently Used (LRU)](<https://en.wikipedia.org/wiki/Cache_replacement_policies#Least_recently_used_(LRU)>) can be a good policy for our system. In this policy, we discard the least recently used key first.

**How to handle cache miss?**

Whenever there is a cache miss, our servers can hit the database directly and update the cache with the new entries.

_For more details, refer to [Caching](https://karanpratapsingh.com/courses/system-design/caching)._

## Identify and resolve bottlenecks

![uber-advanced-design](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/uber/uber-advanced-design.png)

Let us identify and resolve bottlenecks such as single points of failure in our design:

- "What if one of our services crashes?"
- "How will we distribute our traffic between our components?"
- "How can we reduce the load on our database?"
- "How to improve the availability of our cache?"
- "How can we make our notification system more robust?"

To make our system more resilient we can do the following:

- Running multiple instances of each of our services.
- Introducing [load balancers](https://karanpratapsingh.com/courses/system-design/load-balancing) between clients, servers, databases, and cache servers.
- Using multiple read replicas for our databases.
- Multiple instances and replicas for our distributed cache.
- Exactly once delivery and message ordering is challenging in a distributed system, we can use a dedicated [message broker](https://karanpratapsingh.com/courses/system-design/message-brokers) such as [Apache Kafka](https://kafka.apache.org) or [NATS](https://nats.io) to make our notification system more robust.

# Next Steps

Congratulations, you've finished the course!

Now that you know the fundamentals of System Design, here are some additional resources:

- [Distributed Systems](https://www.youtube.com/watch?v=UEAMfLPZZhE&list=PLeKd45zvjcDFUEv_ohr_HdUFe97RItdiB) (by Dr. Martin Kleppmann)
- [System Design Interview: An Insider's Guide](https://www.amazon.in/System-Design-Interview-insiders-Second/dp/B08CMF2CQF)
- [Microservices](https://microservices.io) (by Chris Richardson)
- [Serverless computing](https://en.wikipedia.org/wiki/Serverless_computing)
- [Kubernetes](https://kubernetes.io)

It is also recommended to actively follow engineering blogs of companies putting what we learned in the course into practice at scale:

- [Microsoft Engineering](https://engineering.microsoft.com)
- [Google Research Blog](http://googleresearch.blogspot.com)
- [Netflix Tech Blog](http://techblog.netflix.com)
- [AWS Blog](https://aws.amazon.com/blogs/aws)
- [Facebook Engineering](https://www.facebook.com/Engineering)
- [Uber Engineering Blog](http://eng.uber.com)
- [Airbnb Engineering](http://nerds.airbnb.com)
- [GitHub Engineering Blog](https://github.blog/category/engineering)
- [Intel Software Blog](https://software.intel.com/en-us/blogs)
- [LinkedIn Engineering](http://engineering.linkedin.com/blog)
- [Paypal Developer Blog](https://medium.com/paypal-engineering)
- [Twitter Engineering](https://blog.twitter.com/engineering)

Last but not least, volunteer for new projects at your company, and learn from senior engineers and architects to further improve your system design skills.

I hope this course was a great learning experience. I would love to hear feedback from you.

Wishing you all the best for further learning!

# References

Here are the resources that were referenced while creating this course.

- [Cloudflare learning center](https://www.cloudflare.com/learning)
- [IBM Blogs](https://www.ibm.com/blogs)
- [Fastly Blogs](https://www.fastly.com/blog)
- [NS1 Blogs](https://ns1.com/blog)
- [Grokking the System Design Interview](https://www.educative.io/courses/grokking-the-system-design-interview)
- [System Design Primer](https://github.com/donnemartin/system-design-primer)
- [AWS Blogs](https://aws.amazon.com/blogs)
- [Martin Fowler](https://martinfowler.com)
- [PagerDuty resources](https://www.pagerduty.com/resources)
- [VMWare Blogs](https://blogs.vmware.com/learning)

_All the diagrams were made using [Excalidraw](https://excalidraw.com) and are available [here](https://github.com/karanpratapsingh/system-design/tree/main/diagrams)._
